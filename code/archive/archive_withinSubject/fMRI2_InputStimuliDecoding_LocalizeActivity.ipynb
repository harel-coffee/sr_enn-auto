{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI1 -- Compute the baseline decodability (within-subject!) of input stimuli features (COLOR, ORIENTATION, PITCH, CONSTANT)\n",
    "\n",
    "## Use classifications\n",
    "## Using Ciric-style postprocessing\n",
    "\n",
    "## Takuya Ito\n",
    "#### 01/17/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nib\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.api as sm\n",
    "import sklearn.svm as svm\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import sklearn\n",
    "from sklearn.feature_selection import f_classif\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "os.sys.path.append('glmScripts/')\n",
    "import taskGLMPipeline as tgp\n",
    "os.sys.path.append('utils/')\n",
    "import loadExperimentalData as led\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "## TEMPORARY - WAITING FOR REST OF CODE TO FINISH RUNNING\n",
    "subjNums = subjNums[:83]\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Define functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrialData(subj):\n",
    "#     x = tgp.loadTaskTiming(subj,'betaSeries')\n",
    "#     stimIndex = np.asarray(x['stimIndex'])\n",
    "#     ind = np.where(stimIndex=='motorResponse')[0]\n",
    "    \n",
    "    datadir = basedir + 'data/postProcessing/hcpPostProcCiric/'\n",
    "    h5f = h5py.File(datadir + subj + '_glmOutput_data.h5','r')\n",
    "    data = h5f['taskRegression/betaSeries_24pXaCompCorXVolterra_taskReg_betas_canonical'][:].copy()\n",
    "    # Probe activations are starting from index 128 (first 128 are encoding activations)\n",
    "    data = data[:,128:].copy()\n",
    "#     data = np.loadtxt(datadir + subj + '_motorResponse_taskBetas_Surface64k_GSR.csv',delimiter=',')\n",
    "#     data = data[:,-4:]\n",
    "    h5f.close()\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subject 0 / 83\n",
      "Loading subject 4 / 83\n",
      "Loading subject 8 / 83\n",
      "Loading subject 12 / 83\n",
      "Loading subject 16 / 83\n",
      "Loading subject 20 / 83\n",
      "Loading subject 24 / 83\n",
      "Loading subject 28 / 83\n",
      "Loading subject 32 / 83\n",
      "Loading subject 36 / 83\n",
      "Loading subject 40 / 83\n",
      "Loading subject 44 / 83\n",
      "Loading subject 48 / 83\n",
      "Loading subject 52 / 83\n",
      "Loading subject 56 / 83\n",
      "Loading subject 60 / 83\n",
      "Loading subject 64 / 83\n",
      "Loading subject 68 / 83\n",
      "Loading subject 72 / 83\n",
      "Loading subject 76 / 83\n",
      "Loading subject 80 / 83\n"
     ]
    }
   ],
   "source": [
    "# gsr = True\n",
    "nTrials = 384\n",
    "data_task = np.zeros((len(glasser2),nTrials,len(subjNums)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    if scount%4==0: print 'Loading subject', scount, '/', len(subjNums)\n",
    "    data_task[:,:,scount] = loadTrialData(subj)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Define functions for motor response decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def inputStimuliDecodings((data, subj, stimkey, ncvs)):\n",
    "    \"\"\"\n",
    "    Run a within-subject classification\n",
    "    Assumes data is a space X feature matrix\n",
    "    Decode responses on each hand separately from CPRO data\n",
    "    \"\"\"\n",
    "    \n",
    "    df_task = led.loadExperimentalData(subj) \n",
    "    stim1_values = df_task['Stim1_' + stimkey].values\n",
    "    stim2_values = df_task['Stim2_' + stimkey].values\n",
    "    stim_ind = {}\n",
    "    labels = []\n",
    "    stimcount = 0\n",
    "    for stim1 in np.unique(stim1_values):\n",
    "        for stim2 in np.unique(stim2_values):\n",
    "            stim_combo = stim1 + stim2\n",
    "            # Identify trials in which stim1 and stim2 were presented\n",
    "            stim_ind[stim_combo] = np.intersect1d(np.where(stim1_values==stim1)[0],np.where(stim2_values==stim2)[0])\n",
    "            labels.extend(np.repeat(stimcount,len(stim_ind[stim_combo])))\n",
    "            stimcount += 1\n",
    "    \n",
    "    svm_mat = []\n",
    "    for stim_combo in stim_ind:\n",
    "        svm_mat.extend(data[:,stim_ind[stim_combo]].T)\n",
    "    svm_mat = np.asarray(svm_mat)\n",
    "        \n",
    "    # Spatially demean matrix across features\n",
    "    samplemean = np.mean(svm_mat,axis=1)\n",
    "    samplemean.shape = (len(samplemean),1)\n",
    "    svm_mat = svm_mat - samplemean\n",
    "\n",
    "    scores = randomSplitLOOBaselineCV(ncvs, svm_mat, labels)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def randomSplitLOOBaselineCV(ncvs, svm_mat, labels):\n",
    "    \"\"\"\n",
    "    Runs cross validation for a within-subject SVM analysis\n",
    "    Using boot-strapped CV\n",
    "    Approx. 80% train set, 20% test set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data set might be unbalanced, so find minimium number of unique samples\n",
    "    maxpossible = len(labels)\n",
    "    for i in np.unique(labels):\n",
    "        if np.sum(labels==i)<maxpossible:\n",
    "            maxpossible = np.sum(labels==i)\n",
    "    min_unique_samples = maxpossible\n",
    "    # Train set is approximately 80%\n",
    "    n_trainset_per_cond = np.floor(min_unique_samples*.8)\n",
    "    # Test set is the remaining samples\n",
    "    n_testset_per_cond = min_unique_samples - n_trainset_per_cond\n",
    "    \n",
    "    accuracies = []\n",
    "    for cv in range(ncvs):\n",
    "        # Define training and test set labels\n",
    "        train_ind = []\n",
    "        trainlabels = []\n",
    "        for i in np.unique(labels):\n",
    "            ind = np.where(labels==i)[0]\n",
    "            train_ind.extend(np.random.choice(ind,int(n_trainset_per_cond),replace=False))\n",
    "            trainlabels.extend(np.repeat(i,n_trainset_per_cond))\n",
    "        train_ind = np.asarray(train_ind)\n",
    "        test_ind = np.delete(np.arange(len(labels)),train_ind)\n",
    "        testlabels = np.delete(labels,train_ind)\n",
    "        \n",
    "        # Define train set and test set matrices\n",
    "        trainset = svm_mat[train_ind,:]\n",
    "        testset = svm_mat[test_ind,:]\n",
    "        \n",
    "        # Normalize trainset and testset using trainset stats\n",
    "        mean = np.mean(svm_mat[train_ind,:],axis=0)\n",
    "        mean.shape = (1,len(mean))\n",
    "        std = np.std(svm_mat[train_ind,:],axis=0)\n",
    "        std.shape = (1,len(std))\n",
    "\n",
    "        trainset = np.divide((trainset - mean),std)\n",
    "        testset = np.divide((testset - mean),std)\n",
    "\n",
    "#         ## Feature selection and downsampling\n",
    "#         unique_labels = np.unique(labels)\n",
    "#         feat1_labs = np.where(trainlabels==unique_labels[0])[0]\n",
    "#         feat2_labs = np.where(trainlabels==unique_labels[1])[0]\n",
    "#         # Perform t-test\n",
    "#         t, p = stats.ttest_rel(trainset[feat1_labs,:],trainset[feat2_labs,:],axis=0)\n",
    "#         h0, qs = mc.fdrcorrection0(p)\n",
    "# #         h0 = p<0.1\n",
    "# #         # Construct feature masks\n",
    "# #         feat1_mask = np.multiply(t>0,h0).astype(bool)\n",
    "# #         feat2_mask = np.multiply(t<0,h0).astype(bool)\n",
    "#         feat1_mask = t>0\n",
    "#         feat2_mask = t<0\n",
    "#         # Downsample training set into original vertices into 2 ROI signals\n",
    "#         trainset_downsampled = np.zeros((trainset.shape[0],2))\n",
    "#         trainset_downsampled[:,0] = np.nanmean(trainset[:,feat1_mask],axis=1)\n",
    "#         trainset_downsampled[:,1] = np.nanmean(trainset[:,feat2_mask],axis=1)\n",
    "#         trainset_downsampled = trainset[:,h0]\n",
    "#         # Downsample test set into original vertices\n",
    "#         testset_downsampled = np.zeros((testset.shape[0],2))\n",
    "#         testset_downsampled[:,0] = np.nanmean(testset[:,feat1_mask],axis=1)\n",
    "#         testset_downsampled[:,1] = np.nanmean(testset[:,feat2_mask],axis=1)\n",
    "#         testset_downsampled = testset[:,h0]\n",
    "\n",
    "#         if np.sum(feat1_mask)==0 or np.sum(feat2_mask==0):\n",
    "#             accuracies.append(_decoding((trainset,testset,trainlabels,testlabels)))\n",
    "#         else:\n",
    "#             accuracies.append(_decoding((trainset_downsampled,testset_downsampled,trainlabels,testlabels)))\n",
    "        \n",
    "        accuracies.append(_decoding((trainset,testset,trainlabels,testlabels)))\n",
    "        \n",
    "    return np.mean(accuracies)\n",
    "\n",
    "def _decoding((trainset,testset,trainlabels,testlabels)):\n",
    "\n",
    "# #     clf = sklearn.linear_model.LogisticRegression()\n",
    "#     clf = svm.SVC(C=1.0, kernel='linear')\n",
    "\n",
    "#     clf.fit(trainset,trainlabels)\n",
    "#     predictions = clf.predict(testset)\n",
    "#     acc = predictions==testlabels\n",
    "#     acc = np.mean(acc)\n",
    "\n",
    "    unique_cond = np.unique(trainlabels)\n",
    "    rdm = np.zeros((len(unique_cond),len(unique_cond)))\n",
    "    acc = []\n",
    "    for cond1 in unique_cond:\n",
    "        mismatches = []\n",
    "        prototype_ind = np.where(trainlabels==cond1)[0]\n",
    "        prototype = np.mean(trainset[prototype_ind,:],axis=0)\n",
    "        for cond2 in unique_cond:\n",
    "            test_ind = np.where(testlabels==cond2)[0]\n",
    "            test = np.mean(testset[test_ind,:],axis=0)\n",
    "            if cond1 == cond2: \n",
    "                correct = stats.spearmanr(prototype,test)[0]\n",
    "            else:\n",
    "                mismatches.append(stats.spearmanr(prototype,test)[0])\n",
    "        \n",
    "        if correct > np.max(mismatches): \n",
    "            acc.append(1.0)\n",
    "        else:\n",
    "            acc.append(0.0)\n",
    "    \n",
    "#     # Mahalanobis distance\n",
    "#     unique_cond = np.unique(trainlabels)\n",
    "#     rdm = np.zeros((len(unique_cond),len(unique_cond)))\n",
    "#     acc = []\n",
    "#     for cond1 in unique_cond:\n",
    "#         mismatches = []\n",
    "#         prototype_ind = np.where(trainlabels==cond1)[0]\n",
    "#         prototype = trainset[prototype_ind,:]\n",
    "#         for cond2 in unique_cond:\n",
    "#             test_ind = np.where(testlabels==cond2)[0]\n",
    "#             test = testset[test_ind,:]\n",
    "#             if cond1 == cond2: \n",
    "# #                 correct = np.linalg.norm(prototype-test)\n",
    "#                 correct = np.mean(cdist(prototype,test,'mahalanobis',VI=np.linalg.pinv(np.cov(np.vstack((prototype,test))))))\n",
    "#             else:\n",
    "# #                 mismatches.append(np.linalg.norm(prototype-test))\n",
    "#                 mismatches.append(np.mean(cdist(prototype,test,'mahalanobis',VI=np.linalg.pinv(np.cov(np.vstack((prototype,test)))))))\n",
    "        \n",
    "#         if correct > np.max(mismatches): \n",
    "#             acc.append(1.0)\n",
    "#         else:\n",
    "#             acc.append(0.0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on color input stimuli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running within-subject decoding of Color inputs on ROI 0\n",
      "Running within-subject decoding of Color inputs on ROI 120\n",
      "Running within-subject decoding of Color inputs on ROI 141\n",
      "Running within-subject decoding of Color inputs on ROI 180\n",
      "Running within-subject decoding of Color inputs on ROI 300\n",
      "Running within-subject decoding of Color inputs on ROI 321\n",
      "Running within-subject decoding of Color inputs on ROI 1\n",
      "Running within-subject decoding of Color inputs on ROI 2\n",
      "Running within-subject decoding of Color inputs on ROI 3\n",
      "Running within-subject decoding of Color inputs on ROI 4\n",
      "Running within-subject decoding of Color inputs on ROI 5\n",
      "Running within-subject decoding of Color inputs on ROI 6\n",
      "Running within-subject decoding of Color inputs on ROI 12\n",
      "Running within-subject decoding of Color inputs on ROI 15\n",
      "Running within-subject decoding of Color inputs on ROI 16\n",
      "Running within-subject decoding of Color inputs on ROI 17\n",
      "Running within-subject decoding of Color inputs on ROI 18\n",
      "Running within-subject decoding of Color inputs on ROI 19\n",
      "Running within-subject decoding of Color inputs on ROI 20\n",
      "Running within-subject decoding of Color inputs on ROI 21\n",
      "Running within-subject decoding of Color inputs on ROI 22\n",
      "Running within-subject decoding of Color inputs on ROI 47\n",
      "Running within-subject decoding of Color inputs on ROI 48\n",
      "Running within-subject decoding of Color inputs on ROI 137\n",
      "Running within-subject decoding of Color inputs on ROI 151\n",
      "Running within-subject decoding of Color inputs on ROI 152\n",
      "Running within-subject decoding of Color inputs on ROI 153\n",
      "Running within-subject decoding of Color inputs on ROI 155\n",
      "Running within-subject decoding of Color inputs on ROI 156\n",
      "Running within-subject decoding of Color inputs on ROI 157\n",
      "Running within-subject decoding of Color inputs on ROI 158\n",
      "Running within-subject decoding of Color inputs on ROI 159\n",
      "Running within-subject decoding of Color inputs on ROI 162\n",
      "Running within-subject decoding of Color inputs on ROI 181\n",
      "Running within-subject decoding of Color inputs on ROI 182\n",
      "Running within-subject decoding of Color inputs on ROI 183\n",
      "Running within-subject decoding of Color inputs on ROI 184\n",
      "Running within-subject decoding of Color inputs on ROI 185\n",
      "Running within-subject decoding of Color inputs on ROI 186\n",
      "Running within-subject decoding of Color inputs on ROI 192\n",
      "Running within-subject decoding of Color inputs on ROI 195\n",
      "Running within-subject decoding of Color inputs on ROI 196\n",
      "Running within-subject decoding of Color inputs on ROI 197\n",
      "Running within-subject decoding of Color inputs on ROI 198\n",
      "Running within-subject decoding of Color inputs on ROI 199\n",
      "Running within-subject decoding of Color inputs on ROI 200\n",
      "Running within-subject decoding of Color inputs on ROI 201\n",
      "Running within-subject decoding of Color inputs on ROI 202\n",
      "Running within-subject decoding of Color inputs on ROI 227\n",
      "Running within-subject decoding of Color inputs on ROI 228\n",
      "Running within-subject decoding of Color inputs on ROI 317\n",
      "Running within-subject decoding of Color inputs on ROI 331\n",
      "Running within-subject decoding of Color inputs on ROI 332\n",
      "Running within-subject decoding of Color inputs on ROI 333\n",
      "Running within-subject decoding of Color inputs on ROI 335\n",
      "Running within-subject decoding of Color inputs on ROI 336\n",
      "Running within-subject decoding of Color inputs on ROI 337\n",
      "Running within-subject decoding of Color inputs on ROI 338\n",
      "Running within-subject decoding of Color inputs on ROI 339\n",
      "Running within-subject decoding of Color inputs on ROI 342\n"
     ]
    }
   ],
   "source": [
    "nproc = 10\n",
    "rois = []\n",
    "rois.extend(np.where(networkdef==networkmappings['vis1'])[0])\n",
    "rois.extend(np.where(networkdef==networkmappings['vis2'])[0])\n",
    "statistics_color = np.zeros((len(rois),len(subjNums)))\n",
    "stim = 'Color'\n",
    "nCVs = 10 # These are bootstrapped CVs\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    print 'Running within-subject decoding of', stim, 'inputs on ROI', roi\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    scount = 0\n",
    "    inputs = []\n",
    "    for subj in subjNums:\n",
    "        roi_data = data_task[roi_ind,:,scount]\n",
    "        inputs.append((roi_data,subj,stim,nCVs))\n",
    "        scount += 1\n",
    "    \n",
    "    # Run in parallel\n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    results = pool.map_async(inputStimuliDecodings,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # Store in array\n",
    "    statistics_color[roicount,:] = np.asarray(results).copy()\n",
    "    \n",
    "    roicount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI 16 Accuracy: 0.286746987952 | p = 0.0474430535698\n",
      "ROI 47 Accuracy: 0.296385542169 | p = 0.0392707806335\n",
      "ROI 162 Accuracy: 0.293674698795 | p = 0.0392707806335\n",
      "ROI 183 Accuracy: 0.295180722892 | p = 0.0420285007347\n",
      "ROI 195 Accuracy: 0.292771084337 | p = 0.0293376879543\n",
      "ROI 335 Accuracy: 0.291265060241 | p = 0.0392707806335\n",
      "ROI 342 Accuracy: 0.286445783133 | p = 0.0474430535698\n"
     ]
    }
   ],
   "source": [
    "ts, ps = stats.ttest_1samp(statistics_color,0.25,axis=1)\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if ts[i] > 0:\n",
    "        ps[i] = ps[i]/2.0\n",
    "    else:\n",
    "        ps[i] = 1.0 - ps[i]/2.0\n",
    "        \n",
    "qs = mc.fdrcorrection0(ps)[1]\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if qs[i] < 0.05:\n",
    "        print 'ROI', rois[i], 'Accuracy:', np.mean(statistics_color[i,:]), '| p =', qs[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on ORIENTATION input stimuli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running within-subject decoding of Ori inputs on ROI 0\n",
      "Running within-subject decoding of Ori inputs on ROI 120\n",
      "Running within-subject decoding of Ori inputs on ROI 141\n",
      "Running within-subject decoding of Ori inputs on ROI 180\n",
      "Running within-subject decoding of Ori inputs on ROI 300\n",
      "Running within-subject decoding of Ori inputs on ROI 321\n",
      "Running within-subject decoding of Ori inputs on ROI 1\n",
      "Running within-subject decoding of Ori inputs on ROI 2\n",
      "Running within-subject decoding of Ori inputs on ROI 3\n",
      "Running within-subject decoding of Ori inputs on ROI 4\n",
      "Running within-subject decoding of Ori inputs on ROI 5\n",
      "Running within-subject decoding of Ori inputs on ROI 6\n",
      "Running within-subject decoding of Ori inputs on ROI 12\n",
      "Running within-subject decoding of Ori inputs on ROI 15\n",
      "Running within-subject decoding of Ori inputs on ROI 16\n",
      "Running within-subject decoding of Ori inputs on ROI 17\n",
      "Running within-subject decoding of Ori inputs on ROI 18\n",
      "Running within-subject decoding of Ori inputs on ROI 19\n",
      "Running within-subject decoding of Ori inputs on ROI 20\n",
      "Running within-subject decoding of Ori inputs on ROI 21\n",
      "Running within-subject decoding of Ori inputs on ROI 22\n",
      "Running within-subject decoding of Ori inputs on ROI 47\n",
      "Running within-subject decoding of Ori inputs on ROI 48\n",
      "Running within-subject decoding of Ori inputs on ROI 137\n",
      "Running within-subject decoding of Ori inputs on ROI 151\n",
      "Running within-subject decoding of Ori inputs on ROI 152\n",
      "Running within-subject decoding of Ori inputs on ROI 153\n",
      "Running within-subject decoding of Ori inputs on ROI 155\n",
      "Running within-subject decoding of Ori inputs on ROI 156\n",
      "Running within-subject decoding of Ori inputs on ROI 157\n",
      "Running within-subject decoding of Ori inputs on ROI 158\n",
      "Running within-subject decoding of Ori inputs on ROI 159\n",
      "Running within-subject decoding of Ori inputs on ROI 162\n",
      "Running within-subject decoding of Ori inputs on ROI 181\n",
      "Running within-subject decoding of Ori inputs on ROI 182\n",
      "Running within-subject decoding of Ori inputs on ROI 183\n",
      "Running within-subject decoding of Ori inputs on ROI 184\n",
      "Running within-subject decoding of Ori inputs on ROI 185\n",
      "Running within-subject decoding of Ori inputs on ROI 186\n",
      "Running within-subject decoding of Ori inputs on ROI 192\n",
      "Running within-subject decoding of Ori inputs on ROI 195\n",
      "Running within-subject decoding of Ori inputs on ROI 196\n",
      "Running within-subject decoding of Ori inputs on ROI 197\n",
      "Running within-subject decoding of Ori inputs on ROI 198\n",
      "Running within-subject decoding of Ori inputs on ROI 199\n",
      "Running within-subject decoding of Ori inputs on ROI 200\n",
      "Running within-subject decoding of Ori inputs on ROI 201\n",
      "Running within-subject decoding of Ori inputs on ROI 202\n",
      "Running within-subject decoding of Ori inputs on ROI 227\n",
      "Running within-subject decoding of Ori inputs on ROI 228\n",
      "Running within-subject decoding of Ori inputs on ROI 317\n",
      "Running within-subject decoding of Ori inputs on ROI 331\n",
      "Running within-subject decoding of Ori inputs on ROI 332\n",
      "Running within-subject decoding of Ori inputs on ROI 333\n",
      "Running within-subject decoding of Ori inputs on ROI 335\n",
      "Running within-subject decoding of Ori inputs on ROI 336\n",
      "Running within-subject decoding of Ori inputs on ROI 337\n",
      "Running within-subject decoding of Ori inputs on ROI 338\n",
      "Running within-subject decoding of Ori inputs on ROI 339\n",
      "Running within-subject decoding of Ori inputs on ROI 342\n"
     ]
    }
   ],
   "source": [
    "nproc = 10\n",
    "rois = []\n",
    "rois.extend(np.where(networkdef==networkmappings['vis1'])[0])\n",
    "rois.extend(np.where(networkdef==networkmappings['vis2'])[0])\n",
    "statistics_ori = np.zeros((len(rois),len(subjNums)))\n",
    "stim = 'Ori'\n",
    "nCVs = 10 # These are bootstrapped CVs\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    print 'Running within-subject decoding of', stim, 'inputs on ROI', roi\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    scount = 0\n",
    "    inputs = []\n",
    "    for subj in subjNums:\n",
    "        roi_data = data_task[roi_ind,:,scount]\n",
    "        inputs.append((roi_data,subj,stim,nCVs))\n",
    "        scount += 1\n",
    "    \n",
    "    # Run in parallel\n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    results = pool.map_async(inputStimuliDecodings,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # Store in array\n",
    "    statistics_ori[roicount,:] = np.asarray(results).copy()\n",
    "    \n",
    "    roicount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI 0 Accuracy: 0.447891566265 | p = 5.98366541108e-17\n",
      "ROI 141 Accuracy: 0.279518072289 | p = 0.0257902645086\n",
      "ROI 180 Accuracy: 0.432530120482 | p = 5.0661869133e-16\n",
      "ROI 3 Accuracy: 0.500301204819 | p = 7.45637552833e-25\n",
      "ROI 4 Accuracy: 0.474096385542 | p = 4.59075972478e-20\n",
      "ROI 5 Accuracy: 0.465662650602 | p = 2.81215676811e-22\n",
      "ROI 6 Accuracy: 0.296084337349 | p = 0.00668176455702\n",
      "ROI 18 Accuracy: 0.282831325301 | p = 0.0122699384092\n",
      "ROI 19 Accuracy: 0.332228915663 | p = 4.44407527731e-07\n",
      "ROI 20 Accuracy: 0.329518072289 | p = 4.80335042161e-06\n",
      "ROI 21 Accuracy: 0.298192771084 | p = 0.00318214559654\n",
      "ROI 151 Accuracy: 0.285843373494 | p = 0.00947364323958\n",
      "ROI 157 Accuracy: 0.32921686747 | p = 1.65150173016e-05\n",
      "ROI 158 Accuracy: 0.278012048193 | p = 0.0456733386495\n",
      "ROI 181 Accuracy: 0.294879518072 | p = 0.00780533425494\n",
      "ROI 183 Accuracy: 0.491265060241 | p = 1.92410862484e-22\n",
      "ROI 184 Accuracy: 0.493975903614 | p = 1.25159981758e-21\n",
      "ROI 185 Accuracy: 0.467771084337 | p = 3.00461010377e-20\n",
      "ROI 186 Accuracy: 0.325602409639 | p = 5.03667169574e-05\n",
      "ROI 195 Accuracy: 0.28343373494 | p = 0.0257902645086\n",
      "ROI 196 Accuracy: 0.284638554217 | p = 0.0210640761426\n",
      "ROI 198 Accuracy: 0.294879518072 | p = 0.0110159596722\n",
      "ROI 199 Accuracy: 0.35843373494 | p = 5.54214318658e-07\n",
      "ROI 200 Accuracy: 0.328915662651 | p = 5.54214318658e-07\n",
      "ROI 201 Accuracy: 0.33765060241 | p = 1.53542086515e-07\n",
      "ROI 202 Accuracy: 0.30843373494 | p = 0.00108128368425\n",
      "ROI 227 Accuracy: 0.300602409639 | p = 0.000504733990833\n",
      "ROI 317 Accuracy: 0.303012048193 | p = 0.000856083272364\n",
      "ROI 335 Accuracy: 0.313554216867 | p = 0.000294413283641\n",
      "ROI 336 Accuracy: 0.280722891566 | p = 0.0483865831572\n",
      "ROI 337 Accuracy: 0.334337349398 | p = 4.63170044449e-07\n",
      "ROI 338 Accuracy: 0.301807228916 | p = 0.00076294573704\n"
     ]
    }
   ],
   "source": [
    "ts, ps = stats.ttest_1samp(statistics_ori,0.25,axis=1)\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if ts[i] > 0:\n",
    "        ps[i] = ps[i]/2.0\n",
    "    else:\n",
    "        ps[i] = 1.0 - ps[i]/2.0\n",
    "        \n",
    "qs = mc.fdrcorrection0(ps)[1]\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if qs[i] < 0.05:\n",
    "        print 'ROI', rois[i], 'Accuracy:', np.mean(statistics_ori[i,:]), '| p =', qs[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on PITCH input stimuli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running within-subject decoding of Pitch inputs on ROI 23\n",
      "Running within-subject decoding of Pitch inputs on ROI 102\n",
      "Running within-subject decoding of Pitch inputs on ROI 103\n",
      "Running within-subject decoding of Pitch inputs on ROI 106\n",
      "Running within-subject decoding of Pitch inputs on ROI 123\n",
      "Running within-subject decoding of Pitch inputs on ROI 172\n",
      "Running within-subject decoding of Pitch inputs on ROI 173\n",
      "Running within-subject decoding of Pitch inputs on ROI 174\n",
      "Running within-subject decoding of Pitch inputs on ROI 203\n",
      "Running within-subject decoding of Pitch inputs on ROI 282\n",
      "Running within-subject decoding of Pitch inputs on ROI 286\n",
      "Running within-subject decoding of Pitch inputs on ROI 303\n",
      "Running within-subject decoding of Pitch inputs on ROI 352\n",
      "Running within-subject decoding of Pitch inputs on ROI 353\n",
      "Running within-subject decoding of Pitch inputs on ROI 354\n"
     ]
    }
   ],
   "source": [
    "nproc = 10\n",
    "rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "statistics_pitch = np.zeros((len(rois),len(subjNums)))\n",
    "stim = 'Pitch'\n",
    "nCVs = 10 # These are bootstrapped CVs\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    print 'Running within-subject decoding of', stim, 'inputs on ROI', roi\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    scount = 0\n",
    "    inputs = []\n",
    "    for subj in subjNums:\n",
    "        roi_data = data_task[roi_ind,:,scount]\n",
    "        inputs.append((roi_data,subj,stim,nCVs))\n",
    "        scount += 1\n",
    "    \n",
    "    # Run in parallel\n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    results = pool.map_async(inputStimuliDecodings,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # Store in array\n",
    "    statistics_pitch[roicount,:] = np.asarray(results).copy()\n",
    "    \n",
    "    roicount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI 23 Accuracy: 0.490662650602 | p = 6.38094684199e-23\n",
      "ROI 102 Accuracy: 0.335843373494 | p = 6.03508795164e-07\n",
      "ROI 103 Accuracy: 0.407530120482 | p = 4.47172242895e-13\n",
      "ROI 106 Accuracy: 0.363253012048 | p = 5.09042487137e-09\n",
      "ROI 123 Accuracy: 0.556024096386 | p = 3.73323217061e-43\n",
      "ROI 172 Accuracy: 0.519578313253 | p = 7.47886447453e-29\n",
      "ROI 173 Accuracy: 0.550903614458 | p = 1.11218233976e-41\n",
      "ROI 174 Accuracy: 0.536144578313 | p = 1.23318943555e-28\n",
      "ROI 203 Accuracy: 0.458734939759 | p = 1.33295693468e-23\n",
      "ROI 282 Accuracy: 0.309939759036 | p = 9.43365908384e-05\n",
      "ROI 286 Accuracy: 0.418373493976 | p = 1.95190473318e-17\n",
      "ROI 303 Accuracy: 0.538554216867 | p = 5.48198116446e-34\n",
      "ROI 352 Accuracy: 0.474096385542 | p = 3.48174608584e-21\n",
      "ROI 353 Accuracy: 0.521385542169 | p = 2.96493335498e-32\n",
      "ROI 354 Accuracy: 0.570481927711 | p = 7.43584508404e-37\n"
     ]
    }
   ],
   "source": [
    "ts, ps = stats.ttest_1samp(statistics_pitch,0.25,axis=1)\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if ts[i] > 0:\n",
    "        ps[i] = ps[i]/2.0\n",
    "    else:\n",
    "        ps[i] = 1.0 - ps[i]/2.0\n",
    "        \n",
    "qs = mc.fdrcorrection0(ps)[1]\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if qs[i] < 0.05:\n",
    "        print 'ROI', rois[i], 'Accuracy:', np.mean(statistics_pitch[i,:]), '| p =', qs[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on CONSTANT input stimuli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running within-subject decoding of Constant inputs on ROI 23\n",
      "Running within-subject decoding of Constant inputs on ROI 102\n",
      "Running within-subject decoding of Constant inputs on ROI 103\n",
      "Running within-subject decoding of Constant inputs on ROI 106\n",
      "Running within-subject decoding of Constant inputs on ROI 123\n",
      "Running within-subject decoding of Constant inputs on ROI 172\n",
      "Running within-subject decoding of Constant inputs on ROI 173\n",
      "Running within-subject decoding of Constant inputs on ROI 174\n",
      "Running within-subject decoding of Constant inputs on ROI 203\n",
      "Running within-subject decoding of Constant inputs on ROI 282\n",
      "Running within-subject decoding of Constant inputs on ROI 286\n",
      "Running within-subject decoding of Constant inputs on ROI 303\n",
      "Running within-subject decoding of Constant inputs on ROI 352\n",
      "Running within-subject decoding of Constant inputs on ROI 353\n",
      "Running within-subject decoding of Constant inputs on ROI 354\n"
     ]
    }
   ],
   "source": [
    "nproc = 10\n",
    "rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "statistics_constant = np.zeros((len(rois),len(subjNums)))\n",
    "stim = 'Constant'\n",
    "nCVs = 10 # These are bootstrapped CVs\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    print 'Running within-subject decoding of', stim, 'inputs on ROI', roi\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    scount = 0\n",
    "    inputs = []\n",
    "    for subj in subjNums:\n",
    "        roi_data = data_task[roi_ind,:,scount]\n",
    "        inputs.append((roi_data,subj,stim,nCVs))\n",
    "        scount += 1\n",
    "    \n",
    "    # Run in parallel\n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    results = pool.map_async(inputStimuliDecodings,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # Store in array\n",
    "    statistics_constant[roicount,:] = np.asarray(results).copy()\n",
    "    \n",
    "    roicount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI 23 Accuracy: 0.371385542169 | p = 6.76177099685e-12\n",
      "ROI 102 Accuracy: 0.301506024096 | p = 0.000548737927107\n",
      "ROI 103 Accuracy: 0.342168674699 | p = 1.12474783728e-08\n",
      "ROI 106 Accuracy: 0.357831325301 | p = 2.83728244847e-09\n",
      "ROI 123 Accuracy: 0.433734939759 | p = 3.75293301282e-16\n",
      "ROI 172 Accuracy: 0.397891566265 | p = 2.89309621772e-14\n",
      "ROI 173 Accuracy: 0.378012048193 | p = 1.20418319216e-13\n",
      "ROI 174 Accuracy: 0.385240963855 | p = 2.91345772426e-11\n",
      "ROI 203 Accuracy: 0.335240963855 | p = 7.87698904668e-07\n",
      "ROI 282 Accuracy: 0.282228915663 | p = 0.0185211012877\n",
      "ROI 286 Accuracy: 0.338554216867 | p = 2.32445671677e-07\n",
      "ROI 303 Accuracy: 0.42078313253 | p = 2.6450131089e-16\n",
      "ROI 352 Accuracy: 0.34578313253 | p = 3.90922961187e-08\n",
      "ROI 353 Accuracy: 0.349698795181 | p = 2.39199189901e-09\n",
      "ROI 354 Accuracy: 0.432831325301 | p = 2.51863014232e-14\n"
     ]
    }
   ],
   "source": [
    "ts, ps = stats.ttest_1samp(statistics_constant,0.25,axis=1)\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if ts[i] > 0:\n",
    "        ps[i] = ps[i]/2.0\n",
    "    else:\n",
    "        ps[i] = 1.0 - ps[i]/2.0\n",
    "        \n",
    "qs = mc.fdrcorrection0(ps)[1]\n",
    "\n",
    "for i in range(len(rois)):\n",
    "    if qs[i] < 0.05:\n",
    "        print 'ROI', rois[i], 'Accuracy:', np.mean(statistics_constant[i,:]), '| p =', qs[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Map accuracies back to cortical surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Put all data into a single matrix (since we only run a single classification)\n",
    "# lefthand = np.zeros((glasser2.shape[0],3))\n",
    "# righthand = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "# roicount = 0\n",
    "# for roi in rois:\n",
    "#     # Print significant parcel number\n",
    "#     vertex_ind = np.where(glasser2==roi)[0]\n",
    "#     lefthand[vertex_ind,0] = statistics_lh[roicount,0]\n",
    "#     lefthand[vertex_ind,1] = statistics_lh[roicount,1]\n",
    "#     lefthand[vertex_ind,2] = statistics_lh[roicount,2]\n",
    "\n",
    "#     righthand[vertex_ind,0] = statistics_rh[roicount,0]\n",
    "#     righthand[vertex_ind,1] = statistics_rh[roicount,1]\n",
    "#     righthand[vertex_ind,2] = statistics_rh[roicount,2]\n",
    "\n",
    "#     roicount += 1\n",
    "\n",
    "    \n",
    "# #### \n",
    "# # Write file to csv and run wb_command\n",
    "# outdir = '/projects3/SRActFlow/data/results/WithinSubject_MotorDecoding/'\n",
    "# filename = 'smnDecodingsLH_v2'\n",
    "# np.savetxt(outdir + filename + '.csv', lefthand,fmt='%s')\n",
    "# wb_file = filename + '.dscalar.nii'\n",
    "# wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "# os.system(wb_command)\n",
    "\n",
    "# outdir = '/projects3/SRActFlow/data/results/WithinSubject_MotorDecoding/'\n",
    "# filename = 'smnDecodingsRH_v2'\n",
    "# np.savetxt(outdir + filename + '.csv', righthand,fmt='%s')\n",
    "# wb_file = filename + '.dscalar.nii'\n",
    "# wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "# os.system(wb_command)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
