{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupfMRI6a - Use motor rule regions to predict Motor response regions\n",
    "#### Using ActFlow\n",
    "\n",
    "#### Takuya Ito\n",
    "#### 03/01/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tito/miniconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import tools_group\n",
    "import nibabel as nib\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Define functions for motor response decodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in FC mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.01 Load data for RH and LH responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running compositional analysis on subject 1 / 96\n",
      "Running compositional analysis on subject 2 / 96\n",
      "Running compositional analysis on subject 3 / 96\n",
      "Running compositional analysis on subject 4 / 96\n",
      "Running compositional analysis on subject 5 / 96\n",
      "Running compositional analysis on subject 6 / 96\n",
      "Running compositional analysis on subject 7 / 96\n",
      "Running compositional analysis on subject 8 / 96\n",
      "Running compositional analysis on subject 9 / 96\n",
      "Running compositional analysis on subject 10 / 96\n",
      "Running compositional analysis on subject 11 / 96\n",
      "Running compositional analysis on subject 12 / 96\n",
      "Running compositional analysis on subject 13 / 96\n",
      "Running compositional analysis on subject 14 / 96\n",
      "Running compositional analysis on subject 15 / 96\n",
      "Running compositional analysis on subject 16 / 96\n",
      "Running compositional analysis on subject 17 / 96\n",
      "Running compositional analysis on subject 18 / 96\n",
      "Running compositional analysis on subject 19 / 96\n",
      "Running compositional analysis on subject 20 / 96\n",
      "Running compositional analysis on subject 21 / 96\n",
      "Running compositional analysis on subject 22 / 96\n",
      "Running compositional analysis on subject 23 / 96\n",
      "Running compositional analysis on subject 24 / 96\n",
      "Running compositional analysis on subject 25 / 96\n",
      "Running compositional analysis on subject 26 / 96\n",
      "Running compositional analysis on subject 27 / 96\n",
      "Running compositional analysis on subject 28 / 96\n",
      "Running compositional analysis on subject 29 / 96\n",
      "Running compositional analysis on subject 30 / 96\n",
      "Running compositional analysis on subject 31 / 96\n",
      "Running compositional analysis on subject 32 / 96\n",
      "Running compositional analysis on subject 33 / 96\n",
      "Running compositional analysis on subject 34 / 96\n",
      "Running compositional analysis on subject 35 / 96\n",
      "Running compositional analysis on subject 36 / 96\n",
      "Running compositional analysis on subject 37 / 96\n",
      "Running compositional analysis on subject 38 / 96\n",
      "Running compositional analysis on subject 39 / 96\n",
      "Running compositional analysis on subject 40 / 96\n",
      "Running compositional analysis on subject 41 / 96\n",
      "Running compositional analysis on subject 42 / 96\n",
      "Running compositional analysis on subject 43 / 96\n",
      "Running compositional analysis on subject 44 / 96\n",
      "Running compositional analysis on subject 45 / 96\n",
      "Running compositional analysis on subject 46 / 96\n",
      "Running compositional analysis on subject 47 / 96\n",
      "Running compositional analysis on subject 48 / 96\n",
      "Running compositional analysis on subject 49 / 96\n",
      "Running compositional analysis on subject 50 / 96\n",
      "Running compositional analysis on subject 51 / 96\n",
      "Running compositional analysis on subject 52 / 96\n",
      "Running compositional analysis on subject 53 / 96\n",
      "Running compositional analysis on subject 54 / 96\n",
      "Running compositional analysis on subject 55 / 96\n",
      "Running compositional analysis on subject 56 / 96\n",
      "Running compositional analysis on subject 57 / 96\n",
      "Running compositional analysis on subject 58 / 96\n",
      "Running compositional analysis on subject 59 / 96\n",
      "Running compositional analysis on subject 60 / 96\n",
      "Running compositional analysis on subject 61 / 96\n",
      "Running compositional analysis on subject 62 / 96\n",
      "Running compositional analysis on subject 63 / 96\n",
      "Running compositional analysis on subject 64 / 96\n",
      "Running compositional analysis on subject 65 / 96\n",
      "Running compositional analysis on subject 66 / 96\n",
      "Running compositional analysis on subject 67 / 96\n",
      "Running compositional analysis on subject 68 / 96\n",
      "Running compositional analysis on subject 69 / 96\n",
      "Running compositional analysis on subject 70 / 96\n",
      "Running compositional analysis on subject 71 / 96\n",
      "Running compositional analysis on subject 72 / 96\n",
      "Running compositional analysis on subject 73 / 96\n",
      "Running compositional analysis on subject 74 / 96\n",
      "Running compositional analysis on subject 75 / 96\n",
      "Running compositional analysis on subject 76 / 96\n",
      "Running compositional analysis on subject 77 / 96\n",
      "Running compositional analysis on subject 78 / 96\n",
      "Running compositional analysis on subject 79 / 96\n",
      "Running compositional analysis on subject 80 / 96\n",
      "Running compositional analysis on subject 81 / 96\n",
      "Running compositional analysis on subject 82 / 96\n",
      "Running compositional analysis on subject 83 / 96\n",
      "Running compositional analysis on subject 84 / 96\n",
      "Running compositional analysis on subject 85 / 96\n",
      "Running compositional analysis on subject 86 / 96\n",
      "Running compositional analysis on subject 87 / 96\n",
      "Running compositional analysis on subject 88 / 96\n",
      "Running compositional analysis on subject 89 / 96\n",
      "Running compositional analysis on subject 90 / 96\n",
      "Running compositional analysis on subject 91 / 96\n",
      "Running compositional analysis on subject 92 / 96\n",
      "Running compositional analysis on subject 93 / 96\n",
      "Running compositional analysis on subject 94 / 96\n",
      "Running compositional analysis on subject 95 / 96\n",
      "Running compositional analysis on subject 96 / 96\n"
     ]
    }
   ],
   "source": [
    "tools_group = reload(tools_group)\n",
    "inputtype = 'pitch'\n",
    "data_task_rh = np.zeros((len(glasser2),2,len(subjNums)))\n",
    "data_task_lh = np.zeros((len(glasser2),2,len(subjNums)))\n",
    "actflow_rh = np.zeros(data_task_rh.shape)\n",
    "actflow_lh = np.zeros(data_task_lh.shape)\n",
    "\n",
    "# Create arrays for visualization\n",
    "layerByLayerActivityPredictions_rmid = np.zeros((len(glasser2),7))\n",
    "layerByLayerActivityPredictions_rind = np.zeros((len(glasser2),7))\n",
    "\n",
    "# Identify target indices\n",
    "targetdir = '/projects3/SRActFlow/data/results/GroupfMRI/MotorResponseDecoding/'\n",
    "motor_resp_regions_LH = np.loadtxt(targetdir + 'MotorResponseRegions_LH.csv',delimiter=',')\n",
    "motor_resp_regions_RH = np.loadtxt(targetdir + 'MotorResponseRegions_RH.csv',delimiter=',')\n",
    "targetROIs = np.hstack((motor_resp_regions_LH,motor_resp_regions_RH))\n",
    "        \n",
    "target_ind = []\n",
    "for roi in targetROIs:\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    target_ind.extend(roi_ind)\n",
    "target_ind = np.asarray(target_ind)\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    print 'Running compositional analysis on subject', scount+1, '/', len(subjNums)\n",
    "    tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, input_ind, sr_ind, motorrule_ind = tools_group.compositionalActFlow(subj, inputtype)\n",
    "    data_input = tmp1\n",
    "    data_sr = tmp2\n",
    "    data_motorrule = tmp3\n",
    "    fc_input2sr = tmp4\n",
    "    fc_sr2motorrule = tmp5\n",
    "    fc_motorrule2motorresp = tmp6\n",
    "    \n",
    "    data_task_rh[:,:,scount] = tools_group.loadMotorResponses(subj,hand='Right')\n",
    "    data_task_lh[:,:,scount] = tools_group.loadMotorResponses(subj,hand='Left')\n",
    "    \n",
    "    #####################\n",
    "    # Run composition activity flow\n",
    "    \n",
    "    ## Run for RH\n",
    "    #### Input to SR regions\n",
    "    # first identify non-overlapping indices\n",
    "    unique_input_ind = np.where(np.in1d(input_ind,sr_ind)==False)[0]\n",
    "    actflow_sr_rmid = np.dot(data_input[unique_input_ind,0],fc_input2sr) # rmid - high high stim\n",
    "    actflow_sr_rind = np.dot(data_input[unique_input_ind,3],fc_input2sr) # rind - low low stim\n",
    "    # Construct composition sr representations\n",
    "    unique_sr_ind = np.where(np.in1d(sr_ind,motorrule_ind)==False)[0]\n",
    "    sr_composition_rmid = np.multiply(actflow_sr_rmid, data_sr[:,3]) # Neither \n",
    "    sr_composition_rind = np.multiply(actflow_sr_rind, data_sr[:,3]) # Neither \n",
    "    actflow_motorrule_rmid = np.dot(sr_composition_rmid[unique_sr_ind],fc_sr2motorrule)\n",
    "    actflow_motorrule_rind = np.dot(sr_composition_rind[unique_sr_ind],fc_sr2motorrule)\n",
    "    # Construct motor rule compositions\n",
    "    unique_motor_ind = np.where(np.in1d(motorrule_ind,target_ind)==False)[0]\n",
    "    motorrule_composition_rmid = np.multiply(actflow_motorrule_rmid, data_motorrule[:,3]) # This is rind - logic gates force rmid\n",
    "    motorrule_composition_rind = np.multiply(actflow_motorrule_rind, data_motorrule[:,3]) # This is rind\n",
    "    actflow_rh[target_ind,0,scount] = np.dot(motorrule_composition_rmid[unique_motor_ind],fc_motorrule2motorresp)\n",
    "    actflow_rh[target_ind,1,scount] = np.dot(motorrule_composition_rind[unique_motor_ind],fc_motorrule2motorresp)\n",
    "    ## Create arrays for visualization purposes\n",
    "    # input\n",
    "    layerByLayerActivityPredictions_rmid[input_ind,0] = layerByLayerActivityPredictions_rmid[input_ind,0] + data_input[:,0]\n",
    "    layerByLayerActivityPredictions_rind[input_ind,0] = layerByLayerActivityPredictions_rind[input_ind,0] + data_input[:,3]\n",
    "    # sr prediction\n",
    "    layerByLayerActivityPredictions_rmid[sr_ind,1] = layerByLayerActivityPredictions_rmid[sr_ind,1] + actflow_sr_rmid\n",
    "    layerByLayerActivityPredictions_rind[sr_ind,1] = layerByLayerActivityPredictions_rind[sr_ind,1] + actflow_sr_rind\n",
    "    # sr composition\n",
    "    layerByLayerActivityPredictions_rmid[sr_ind,2] = layerByLayerActivityPredictions_rmid[sr_ind,2] + sr_composition_rmid\n",
    "    layerByLayerActivityPredictions_rind[sr_ind,2] = layerByLayerActivityPredictions_rind[sr_ind,2] + sr_composition_rind\n",
    "    # motor rule prediction\n",
    "    layerByLayerActivityPredictions_rmid[motorrule_ind,3] = layerByLayerActivityPredictions_rmid[motorrule_ind,3] + actflow_motorrule_rmid\n",
    "    layerByLayerActivityPredictions_rind[motorrule_ind,3] = layerByLayerActivityPredictions_rind[motorrule_ind,3] + actflow_motorrule_rind\n",
    "    # motor rule composition\n",
    "    layerByLayerActivityPredictions_rmid[motorrule_ind,4] = layerByLayerActivityPredictions_rmid[motorrule_ind,4] + motorrule_composition_rmid\n",
    "    layerByLayerActivityPredictions_rind[motorrule_ind,4] = layerByLayerActivityPredictions_rind[motorrule_ind,4] + motorrule_composition_rind\n",
    "    # motor resp actflow\n",
    "    layerByLayerActivityPredictions_rmid[target_ind,5] = layerByLayerActivityPredictions_rmid[target_ind,5] + actflow_rh[target_ind,0,scount]\n",
    "    layerByLayerActivityPredictions_rind[target_ind,5] = layerByLayerActivityPredictions_rind[target_ind,5] + actflow_rh[target_ind,1,scount]\n",
    "    # motor resp real\n",
    "    layerByLayerActivityPredictions_rmid[target_ind,6] = layerByLayerActivityPredictions_rmid[target_ind,6] + data_task_rh[target_ind,0,scount]\n",
    "    layerByLayerActivityPredictions_rind[target_ind,6] = layerByLayerActivityPredictions_rind[target_ind,6] + data_task_rh[target_ind,1,scount]\n",
    "    \n",
    "    \n",
    "    ## Run for LH\n",
    "    #### Input to SR regions\n",
    "    # first identify non-overlapping indices\n",
    "    unique_input_ind = np.where(np.in1d(input_ind,sr_ind)==False)[0]\n",
    "    actflow_sr_lmid = np.dot(data_input[unique_input_ind,0],fc_input2sr) # lmid - vert vert stim\n",
    "    actflow_sr_lind = np.dot(data_input[unique_input_ind,3],fc_input2sr) # lind - horiz horiz stim\n",
    "    # Construct composition sr representations\n",
    "    unique_sr_ind = np.where(np.in1d(sr_ind,motorrule_ind)==False)[0]\n",
    "    sr_composition_lmid = np.multiply(actflow_sr_lmid, data_sr[:,3]) # Neither \n",
    "    sr_composition_lind = np.multiply(actflow_sr_lind, data_sr[:,3]) # Neither \n",
    "    actflow_motorrule_lmid = np.dot(sr_composition_lmid[unique_sr_ind],fc_sr2motorrule)\n",
    "    actflow_motorrule_lind = np.dot(sr_composition_lind[unique_sr_ind],fc_sr2motorrule)\n",
    "    # Construct motor rule compositions\n",
    "    unique_motor_ind = np.where(np.in1d(motorrule_ind,target_ind)==False)[0]\n",
    "    motorrule_composition_lmid = np.multiply(actflow_motorrule_lmid, data_motorrule[:,1])\n",
    "    motorrule_composition_lind = np.multiply(actflow_motorrule_lind, data_motorrule[:,1])\n",
    "    actflow_lh[target_ind,0,scount] = np.dot(motorrule_composition_lmid[unique_motor_ind],fc_motorrule2motorresp)\n",
    "    actflow_lh[target_ind,1,scount] = np.dot(motorrule_composition_lind[unique_motor_ind],fc_motorrule2motorresp)\n",
    "    #####################\n",
    "    \n",
    "    scount += 1\n",
    "    \n",
    "# Print out to file\n",
    "layerByLayerActivityPredictions_rmid = np.divide(layerByLayerActivityPredictions_rmid,float(len(subjNums)))\n",
    "layerByLayerActivityPredictions_rind = np.divide(layerByLayerActivityPredictions_rind,float(len(subjNums)))\n",
    "tools_group.mapBackToSurface(layerByLayerActivityPredictions_rmid,'10bLayerByLayerPredictions_stimHIGHHIGH_NEITHER_HIGH_RIND_RespRMID')\n",
    "tools_group.mapBackToSurface(layerByLayerActivityPredictions_rind,'10bLayerByLayerPredictions_stimLOWLOW_NEITHER_HIGH_RMID_RespRIND')\n",
    "del fc_input2sr, fc_motorrule2motorresp, fc_sr2motorrule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on right-hand motor responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 20\n",
    "ncvs = 1\n",
    "nResponses = 2\n",
    "\n",
    "# realdata = stats.zscore(data_task_rh[target_ind,:,:],axis=0).copy()\n",
    "# flowata = stats.zscore(actflow_data[target_ind,:,:],axis=0).copy()\n",
    "realdata = data_task_rh[target_ind,:,:].copy()\n",
    "flowdata = actflow_rh[target_ind,:,:].copy()\n",
    "\n",
    "\n",
    "distances_baseline_rh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_rh[0,:] = tools_group.actflowDecodings(realdata,\n",
    "                                                          flowdata,\n",
    "                                                          ncvs=ncvs, nproc=nproc)\n",
    "\n",
    "# distances_baseline_rh[0,:] = tools_group.actflowDecodings(realdata,\n",
    "#                                                           data_composition_rh[target_ind,:,:],\n",
    "#                                                           ncvs=ncvs, nproc=nproc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.739583333333\n",
      "p = 1.05300690701e-11\n"
     ]
    }
   ],
   "source": [
    "statistics_rh = np.zeros((distances_baseline_rh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_rh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_rh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_rh[0,0] = np.mean(distances_baseline_rh[0,:])\n",
    "statistics_rh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_rh[0,0]\n",
    "print 'p =', statistics_rh[0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Run across subject decoding on left-hand motor responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "# realdata = stats.zscore(data_task_lh[target_ind,:,:],axis=0).copy()\n",
    "# flowdata = stats.zscore(actflow_lh[target_ind,:,:],axis=0).copy()\n",
    "realdata = data_task_lh[target_ind,:,:].copy()\n",
    "flowdata = actflow_lh[target_ind,:,:].copy()\n",
    "\n",
    "\n",
    "distances_baseline_lh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_lh[0,:] = tools_group.actflowDecodings(realdata,\n",
    "                                                          flowdata,\n",
    "                                                          ncvs=ncvs, nproc=nproc)\n",
    "\n",
    "# distances_baseline_lh[0,:] = tools_group.actflowDecodings(realdata,\n",
    "#                                                           data_composition_lh[target_ind,:,:],\n",
    "#                                                           ncvs=ncvs, nproc=nproc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.625\n",
      "p = 0.000327515174901\n"
     ]
    }
   ],
   "source": [
    "statistics_lh = np.zeros((distances_baseline_lh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_lh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_lh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_lh[0,0] = np.mean(distances_baseline_lh[0,:])\n",
    "statistics_lh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_lh[0,0]\n",
    "print 'p =', statistics_lh[0,1]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
