{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1 - RNN model of CPRO task using PyTorch\n",
    "\n",
    "#### Taku Ito\n",
    "#### 09/30/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "import bct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network inputs (sensory inputs + task rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSensoryInputs(nStims=2):\n",
    "    stimdata = {}\n",
    "    # Stim 1 empty columns\n",
    "    stimdata['Color1'] = []\n",
    "    stimdata['Orientation1'] = []\n",
    "    stimdata['Pitch1'] = []\n",
    "    stimdata['Constant1'] = []\n",
    "    # Stim 2 empty columns\n",
    "    stimdata['Color2'] = []\n",
    "    stimdata['Orientation2'] = []\n",
    "    stimdata['Pitch2'] = []\n",
    "    stimdata['Constant2'] = []\n",
    "    # Code for RNN training\n",
    "    stimdata['Code'] = []\n",
    "\n",
    "    # Property index tells us which columns ID the property in question\n",
    "    color = {0:'red',\n",
    "             1:'blue'}\n",
    "    orientation = {2:'vertical',\n",
    "                   3:'horizontal'}\n",
    "    pitch = {4:'high',\n",
    "             5:'low'}\n",
    "    constant = {6:'constant',\n",
    "                7:'beeping'}\n",
    "    \n",
    "    for col1 in color:\n",
    "        for col2 in color:\n",
    "            for ori1 in orientation:\n",
    "                for ori2 in orientation:\n",
    "                    for pit1 in pitch:\n",
    "                        for pit2 in pitch:\n",
    "                            for con1 in constant:\n",
    "                                for con2 in constant:\n",
    "                                    code = np.zeros((8*nStims,))\n",
    "                                    # Stim 1\n",
    "                                    code[col1] = 1\n",
    "                                    stimdata['Color1'].append(color[col1])\n",
    "                                    code[ori1] = 1\n",
    "                                    stimdata['Orientation1'].append(orientation[ori1])\n",
    "                                    code[pit1] = 1\n",
    "                                    stimdata['Pitch1'].append(pitch[pit1])\n",
    "                                    code[con1] = 1\n",
    "                                    stimdata['Constant1'].append(constant[con1])\n",
    "                                    # Stim 2 -- need to add 8, since this is the second stimuli\n",
    "                                    code[col2+8] = 1\n",
    "                                    stimdata['Color2'].append(color[col2])\n",
    "                                    code[ori2+8] = 1\n",
    "                                    stimdata['Orientation2'].append(orientation[ori2])\n",
    "                                    code[pit2+8] = 1\n",
    "                                    stimdata['Pitch2'].append(pitch[pit2])\n",
    "                                    code[con2+8] = 1\n",
    "                                    stimdata['Constant2'].append(constant[con2])\n",
    "                                    \n",
    "                                    # Code\n",
    "                                    stimdata['Code'].append(code)\n",
    "                    \n",
    "    return pd.DataFrame(stimdata) \n",
    "\n",
    "def createRulePermutations():\n",
    "    # May need to change this - both and not both are negations of each other, as are either and neither\n",
    "    logicRules = {0: 'both',\n",
    "                  1: 'notboth',\n",
    "                  2: 'either',\n",
    "                  3: 'neither'}\n",
    "    sensoryRules = {4: 'red',\n",
    "                    5: 'vertical',\n",
    "                    6: 'high',\n",
    "                    7: 'constant'}\n",
    "    motorRules = {8: 'l_mid',\n",
    "                  9: 'l_ind',\n",
    "                  10: 'r_ind',\n",
    "                  11: 'r_mid'}\n",
    "    \n",
    "    \n",
    "    taskrules = {}\n",
    "    taskrules['Logic'] = []\n",
    "    taskrules['Sensory'] = []\n",
    "    taskrules['Motor'] = []\n",
    "    # Create another field for the sensory category (to select stimuli from)\n",
    "    taskrules['SensoryCategory'] = []\n",
    "    # For RNN training\n",
    "    taskrules['Code'] = []\n",
    "    \n",
    "    for lo in logicRules:\n",
    "        for se in sensoryRules:\n",
    "            for mo in motorRules:\n",
    "                code = np.zeros((12,))\n",
    "                # Logic rule\n",
    "                taskrules['Logic'].append(logicRules[lo])\n",
    "                code[lo] = 1\n",
    "                \n",
    "                # Sensory rule\n",
    "                taskrules['Sensory'].append(sensoryRules[se])\n",
    "                code[se] = 1\n",
    "                # Define sensory category\n",
    "                if sensoryRules[se]=='red': category = 'Color'\n",
    "                if sensoryRules[se]=='vertical': category = 'Orientation'\n",
    "                if sensoryRules[se]=='high': category = 'Pitch'\n",
    "                if sensoryRules[se]=='constant': category = 'Constant'\n",
    "                taskrules['SensoryCategory'].append(category)\n",
    "                \n",
    "                # Motor rule\n",
    "                taskrules['Motor'].append(motorRules[mo])\n",
    "                code[mo] = 1\n",
    "                \n",
    "                taskrules['Code'].append(code)\n",
    "                \n",
    "    return pd.DataFrame(taskrules)\n",
    "\n",
    "def createTrainTestTaskRules(taskRuleSet,nTrainSet=32,nTestSet=32):\n",
    "    \"\"\"\n",
    "    Ensure that when we split the task rules, that each set has equal proportions of each task rule\n",
    "    For example, if there are 32 training tasks, then we should have 8 examples of each rule\n",
    "    \"\"\"\n",
    "    nRulesPerTrainSet = nTrainSet/4.0\n",
    "    nRulesPerTestSet = nTestSet/4.0\n",
    "    if nRulesPerTrainSet%4.0!=0:\n",
    "        raise Exception('ERROR: Number of rules per train/test set needs to be divisible by 4!')\n",
    "    \n",
    "    df_test = pd.DataFrame()\n",
    "    df_train = pd.DataFrame()\n",
    "    # Make sure all columns exist \n",
    "    df_train = df_train.append(taskRuleSet.iloc[0])\n",
    "    \n",
    "    # Iterate through tasks in a random manner\n",
    "    ind = np.arange(len(taskRuleSet))\n",
    "    np.random.shuffle(ind)\n",
    "    for i in ind:\n",
    "        # Identify the rules in this task set\n",
    "        logic = taskRuleSet.Logic[i]\n",
    "        sensory = taskRuleSet.Sensory[i]\n",
    "        motor = taskRuleSet.Motor[i]\n",
    "        \n",
    "        # Count number of logic rules for this task set\n",
    "        nLogic = np.sum(df_train.Logic==logic)\n",
    "        nSensory = np.sum(df_train.Sensory==sensory)\n",
    "        nMotor = np.sum(df_train.Motor==motor)\n",
    "        if nLogic<nRulesPerTrainSet and nSensory<nRulesPerTrainSet and nMotor<nRulesPerTrainSet:\n",
    "            df_train = df_train.append(taskRuleSet.iloc[i])\n",
    "        else:\n",
    "            df_test = df_test.append(taskRuleSet.iloc[i])\n",
    "                \n",
    "    return df_train, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate motor outputs for each set of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorCode = {0:'l_mid',\n",
    "             1:'l_ind',\n",
    "             2:'r_ind',\n",
    "             3:'r_mid'}\n",
    "\n",
    "def solveInputs(task_rules, stimuli, printTask=False):\n",
    "    \"\"\"\n",
    "    Solves CPRO task given a set of inputs and a task rule\n",
    "    \"\"\"\n",
    "    logicRule = task_rules.Logic\n",
    "    sensoryRule = task_rules.Sensory\n",
    "    motorRule = task_rules.Motor\n",
    "    \n",
    "    sensoryCategory = task_rules.SensoryCategory\n",
    "   \n",
    "    # Isolate the property for each stimulus relevant to the sensory rule\n",
    "    stim1 = stimuli[sensoryCategory + '1']\n",
    "    stim2 = stimuli[sensoryCategory + '2']\n",
    "    \n",
    "    # Run through logic rule gates\n",
    "    if logicRule == 'both':\n",
    "        if stim1==sensoryRule and stim2==sensoryRule:\n",
    "            gate = True\n",
    "        else:\n",
    "            gate = False\n",
    "            \n",
    "    if logicRule == 'notboth':\n",
    "        if stim1!=sensoryRule or stim2!=sensoryRule:\n",
    "            gate = True\n",
    "        else:\n",
    "            gate = False\n",
    "    \n",
    "    if logicRule == 'either':\n",
    "        if stim1==sensoryRule or stim2==sensoryRule:\n",
    "            gate = True\n",
    "        else:\n",
    "            gate = False\n",
    "            \n",
    "    if logicRule == 'neither':\n",
    "        if stim1!=sensoryRule and stim2!=sensoryRule:\n",
    "            gate = True\n",
    "        else:\n",
    "            gate = False\n",
    "            \n",
    "    \n",
    "    ## Print task first\n",
    "    if printTask:\n",
    "        print 'Logic rule:', logicRule\n",
    "        print 'Sensory rule:', sensoryRule\n",
    "        print 'Motor rule:', motorRule\n",
    "        print '**Stimuli**'\n",
    "        print stim1, stim2\n",
    "    \n",
    "    # Apply logic gating to motor rules\n",
    "    if motorRule=='l_mid':\n",
    "        if gate==True:\n",
    "            motorOutput = 'l_mid'\n",
    "        else:\n",
    "            motorOutput = 'l_ind'\n",
    "        \n",
    "    if motorRule=='l_ind':\n",
    "        if gate==True:\n",
    "            motorOutput = 'l_ind'\n",
    "        else:\n",
    "            motorOutput = 'l_mid'\n",
    "        \n",
    "    if motorRule=='r_mid':\n",
    "        if gate==True:\n",
    "            motorOutput = 'r_mid'\n",
    "        else:\n",
    "            motorOutput = 'r_ind'\n",
    "        \n",
    "    if motorRule=='r_ind':\n",
    "        if gate==True:\n",
    "            motorOutput = 'r_ind'\n",
    "        else:\n",
    "            motorOutput = 'r_mid'\n",
    "        \n",
    "    outputcode = np.zeros((4,))\n",
    "    if motorOutput=='l_mid': outputcode[0] = 1\n",
    "    if motorOutput=='l_ind': outputcode[1] = 1\n",
    "    if motorOutput=='r_ind': outputcode[2] = 1\n",
    "    if motorOutput=='r_mid': outputcode[3] = 1\n",
    "        \n",
    "    return motorOutput, outputcode\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainingSet(taskRuleSet,nStimuli=100,nTasks=64,delay=False,shuffle=True):\n",
    "    \"\"\"\n",
    "    Randomly generates a set of stimuli (nStimuli) for each task rule\n",
    "    Will end up with 64 (task rules) * nStimuli total number of input stimuli\n",
    "    \n",
    "    If shuffle keyword is True, will randomly shuffle the training set\n",
    "    Otherwise will start with taskrule1 (nStimuli), taskrule2 (nStimuli), etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    stimuliSet = createSensoryInputs()\n",
    "\n",
    "    networkIO_DataFrame = {}\n",
    "    networkIO_DataFrame['LogicRule'] = []\n",
    "    networkIO_DataFrame['SensoryRule'] = []\n",
    "    networkIO_DataFrame['MotorRule'] = []\n",
    "    networkIO_DataFrame['Color1'] = []\n",
    "    networkIO_DataFrame['Color2'] = []\n",
    "    networkIO_DataFrame['Orientation1'] = []\n",
    "    networkIO_DataFrame['Orientation2'] = []\n",
    "    networkIO_DataFrame['Pitch1'] = []\n",
    "    networkIO_DataFrame['Pitch2'] = []\n",
    "    networkIO_DataFrame['Constant1'] = []\n",
    "    networkIO_DataFrame['Constant2'] = []\n",
    "    networkIO_DataFrame['MotorResponse'] = []\n",
    "\n",
    "    # Create 1d array to randomly sample indices from\n",
    "    stimIndices = np.arange(len(stimuliSet))\n",
    "    taskIndices = np.arange(len(taskRuleSet))\n",
    "    \n",
    "    randomTaskIndices = np.random.choice(taskIndices,nTasks,replace=False)\n",
    "    taskRuleSet2 = taskRuleSet.iloc[randomTaskIndices].copy(deep=True)\n",
    "    taskRuleSet2 = taskRuleSet2.reset_index(drop=True)\n",
    "    taskRuleSet = taskRuleSet2.copy(deep=True)\n",
    "\n",
    "    networkInputCode = []\n",
    "    networkOutputCode = []\n",
    "    for taskrule in taskRuleSet.index:\n",
    "        \n",
    "        randomStimuliIndices = np.random.choice(stimIndices,nStimuli,replace=False)\n",
    "        stimuliSet2 = stimuliSet.iloc[randomStimuliIndices].copy(deep=True)\n",
    "        stimuliSet2 = stimuliSet2.reset_index(drop=True)\n",
    "        \n",
    "        for stim in stimuliSet2.index:\n",
    "\n",
    "            networkInputCode.append(np.hstack((taskRuleSet.Code[taskrule], stimuliSet2.Code[stim])))\n",
    "            tmpresp, tmpcode = solveInputs(taskRuleSet.iloc[taskrule], stimuliSet2.iloc[stim])\n",
    "            networkOutputCode.append(tmpcode)\n",
    "\n",
    "            # Task rule info\n",
    "            networkIO_DataFrame['LogicRule'].append(taskRuleSet.Logic[taskrule])\n",
    "            networkIO_DataFrame['SensoryRule'].append(taskRuleSet.Sensory[taskrule])\n",
    "            networkIO_DataFrame['MotorRule'].append(taskRuleSet.Motor[taskrule])\n",
    "            # Stimuli info['\n",
    "            networkIO_DataFrame['Color1'].append(stimuliSet2.Color1[stim])\n",
    "            networkIO_DataFrame['Color2'].append(stimuliSet2.Color2[stim])\n",
    "            networkIO_DataFrame['Orientation1'].append(stimuliSet2.Orientation1[stim])\n",
    "            networkIO_DataFrame['Orientation2'].append(stimuliSet2.Orientation2[stim])\n",
    "            networkIO_DataFrame['Pitch1'].append(stimuliSet2.Pitch1[stim])\n",
    "            networkIO_DataFrame['Pitch2'].append(stimuliSet2.Pitch2[stim])\n",
    "            networkIO_DataFrame['Constant1'].append(stimuliSet2.Constant1[stim])\n",
    "            networkIO_DataFrame['Constant2'].append(stimuliSet2.Constant2[stim])\n",
    "            # Motor info\n",
    "            networkIO_DataFrame['MotorResponse'].append(tmpresp)\n",
    "            \n",
    "\n",
    "    tmpdf = pd.DataFrame(networkIO_DataFrame)\n",
    "    \n",
    "    if shuffle:\n",
    "        ind = np.arange(len(tmpdf),dtype=int)\n",
    "        np.random.shuffle(ind)\n",
    "        networkIO_DataFrame = tmpdf.iloc[ind]\n",
    "        networkInputCode = np.asarray(networkInputCode)[ind]\n",
    "        networkOutputCode = np.asarray(networkOutputCode)[ind]\n",
    "\n",
    "    # Add delay (i.e., 0 inputs & 0 outputs just incase)\n",
    "    if delay:\n",
    "        networkInputCode2 = []\n",
    "        networkOutputCode2 = []\n",
    "        nDelays = 1\n",
    "        \n",
    "        for index in range(len(networkIO_DataFrame)):\n",
    "            networkInputCode2.append(networkInputCode[index])\n",
    "            networkOutputCode2.append(networkOutputCode[index])\n",
    "            \n",
    "            for delay in range(nDelays):\n",
    "                networkInputCode2.append(np.zeros((len(networkInputCode[index]),)))\n",
    "                networkOutputCode2.append(np.zeros((len(networkOutputCode[index]),)))\n",
    "            \n",
    "            \n",
    "        networkInputCode = networkInputCode2\n",
    "        networkOutputCode = networkOutputCode2\n",
    "            \n",
    "        \n",
    "        \n",
    "    return networkIO_DataFrame, networkInputCode, networkOutputCode\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RNN first on a subset of tasks (half the tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train \n",
    "nTrainSet = 32\n",
    "nTestSet = 32\n",
    "taskRuleSet = createRulePermutations()\n",
    "trainRuleSet, testRuleSet = createTrainTestTaskRules(taskRuleSet,nTrainSet=nTrainSet,nTestSet=nTestSet)\n",
    "stimuliSet = createSensoryInputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "loss: 5.82825946808\n",
      "Accuray: 33.3333%\n",
      "Iteration: 1000\n",
      "loss: 2.801435709\n",
      "Accuray: 80.0%\n",
      "Iteration: 2000\n",
      "loss: 4.25791597366\n",
      "Accuray: 35.0%\n",
      "Iteration: 3000\n",
      "loss: 3.45396256447\n",
      "Accuray: 65.0%\n",
      "Iteration: 4000\n",
      "loss: 4.63083982468\n",
      "Accuray: 52.0%\n",
      "Iteration: 5000\n",
      "loss: 4.27380228043\n",
      "Accuray: 52.0%\n",
      "Iteration: 6000\n",
      "loss: 5.13337373734\n",
      "Accuray: 46.6667%\n",
      "Iteration: 7000\n",
      "loss: 4.94724845886\n",
      "Accuray: 53.3333%\n",
      "Iteration: 8000\n",
      "loss: 4.93768358231\n",
      "Accuray: 80.0%\n",
      "Iteration: 9000\n",
      "loss: 4.99279499054\n",
      "Accuray: 68.5714%\n",
      "Iteration: 10000\n",
      "loss: 5.77327394485\n",
      "Accuray: 57.5%\n",
      "Iteration: 11000\n",
      "loss: 5.89307260513\n",
      "Accuray: 60.0%\n",
      "Iteration: 12000\n",
      "loss: 6.81980705261\n",
      "Accuray: 60.0%\n",
      "Iteration: 13000\n",
      "loss: 6.18894147873\n",
      "Accuray: 51.1111%\n",
      "Iteration: 14000\n",
      "loss: 6.02897453308\n",
      "Accuray: 80.0%\n",
      "Iteration: 15000\n",
      "loss: 6.76697015762\n",
      "Accuray: 58.0%\n",
      "Iteration: 16000\n",
      "loss: 6.54108428955\n",
      "Accuray: 60.0%\n",
      "Iteration: 17000\n",
      "loss: 6.57316303253\n",
      "Accuray: 62.0%\n",
      "Iteration: 18000\n",
      "loss: 6.33108139038\n",
      "Accuray: 70.0%\n",
      "Iteration: 19000\n",
      "loss: 6.09958028793\n",
      "Accuray: 72.0%\n",
      "Iteration: 20000\n",
      "loss: 6.43967294693\n",
      "Accuray: 62.0%\n",
      "Iteration: 21000\n",
      "loss: 5.71361017227\n",
      "Accuray: 84.0%\n",
      "Iteration: 22000\n",
      "loss: 5.60176420212\n",
      "Accuray: 74.0%\n",
      "Iteration: 23000\n",
      "loss: 5.09302282333\n",
      "Accuray: 78.0%\n",
      "Iteration: 24000\n",
      "loss: 5.70360708237\n",
      "Accuray: 72.0%\n",
      "Iteration: 25000\n",
      "loss: 5.75547599792\n",
      "Accuray: 64.0%\n",
      "Iteration: 26000\n",
      "loss: 5.62399339676\n",
      "Accuray: 72.0%\n",
      "Iteration: 27000\n",
      "loss: 5.91387653351\n",
      "Accuray: 68.0%\n",
      "Iteration: 28000\n",
      "loss: 5.05867624283\n",
      "Accuray: 78.0%\n",
      "Iteration: 29000\n",
      "loss: 4.75225925446\n",
      "Accuray: 80.0%\n",
      "Iteration: 30000\n",
      "loss: 4.61385059357\n",
      "Accuray: 84.0%\n",
      "Iteration: 31000\n",
      "loss: 4.62023305893\n",
      "Accuray: 84.0%\n",
      "Iteration: 32000\n",
      "loss: 5.08492994308\n",
      "Accuray: 80.0%\n",
      "Iteration: 33000\n",
      "loss: 5.12983989716\n",
      "Accuray: 74.0%\n",
      "Iteration: 34000\n",
      "loss: 4.81193161011\n",
      "Accuray: 84.0%\n",
      "Iteration: 35000\n",
      "loss: 5.41308736801\n",
      "Accuray: 70.0%\n",
      "Iteration: 36000\n",
      "loss: 4.56290912628\n",
      "Accuray: 78.0%\n",
      "Iteration: 37000\n",
      "loss: 4.81343364716\n",
      "Accuray: 80.0%\n",
      "Iteration: 38000\n",
      "loss: 4.20393228531\n",
      "Accuray: 82.0%\n",
      "Iteration: 39000\n",
      "loss: 3.60216426849\n",
      "Accuray: 88.0%\n",
      "Iteration: 40000\n",
      "loss: 4.15605783463\n",
      "Accuray: 82.0%\n",
      "Iteration: 41000\n",
      "loss: 6.07189702988\n",
      "Accuray: 68.0%\n",
      "Iteration: 42000\n",
      "loss: 3.42327523232\n",
      "Accuray: 88.0%\n",
      "Iteration: 43000\n",
      "loss: 2.80320549011\n",
      "Accuray: 90.0%\n",
      "Iteration: 44000\n",
      "loss: 4.57726287842\n",
      "Accuray: 82.0%\n",
      "Iteration: 45000\n",
      "loss: 3.03871679306\n",
      "Accuray: 92.0%\n",
      "Iteration: 46000\n",
      "loss: 3.28659796715\n",
      "Accuray: 86.0%\n",
      "Iteration: 47000\n",
      "loss: 3.35658669472\n",
      "Accuray: 86.0%\n",
      "Iteration: 48000\n",
      "loss: 4.36247682571\n",
      "Accuray: 80.0%\n",
      "Iteration: 49000\n",
      "loss: 3.16007637978\n",
      "Accuray: 92.0%\n",
      "Iteration: 50000\n",
      "loss: 3.27610707283\n",
      "Accuray: 86.0%\n",
      "Iteration: 51000\n",
      "loss: 2.70401144028\n",
      "Accuray: 94.0%\n",
      "Iteration: 52000\n",
      "loss: 2.31745958328\n",
      "Accuray: 92.0%\n",
      "Iteration: 53000\n",
      "loss: 2.93317556381\n",
      "Accuray: 84.0%\n",
      "Iteration: 54000\n",
      "loss: 2.27759432793\n",
      "Accuray: 94.0%\n",
      "Iteration: 55000\n",
      "loss: 2.70971441269\n",
      "Accuray: 90.0%\n",
      "Iteration: 56000\n",
      "loss: 2.65018200874\n",
      "Accuray: 94.0%\n",
      "Iteration: 57000\n",
      "loss: 2.83410048485\n",
      "Accuray: 86.0%\n",
      "Iteration: 58000\n",
      "loss: 2.60325264931\n",
      "Accuray: 90.0%\n",
      "Iteration: 59000\n",
      "loss: 2.11250638962\n",
      "Accuray: 90.0%\n",
      "Iteration: 60000\n",
      "loss: 2.85193037987\n",
      "Accuray: 92.0%\n",
      "Iteration: 61000\n",
      "loss: 1.85846590996\n",
      "Accuray: 98.0%\n",
      "Iteration: 62000\n",
      "loss: 1.63328683376\n",
      "Accuray: 100.0%\n",
      "Iteration: 63000\n",
      "loss: 2.02809667587\n",
      "Accuray: 96.0%\n",
      "Iteration: 64000\n",
      "loss: 2.38258671761\n",
      "Accuray: 96.0%\n",
      "Iteration: 65000\n",
      "loss: 2.55976915359\n",
      "Accuray: 96.0%\n",
      "Iteration: 66000\n",
      "loss: 1.44778037071\n",
      "Accuray: 100.0%\n",
      "Iteration: 67000\n",
      "loss: 1.75278460979\n",
      "Accuray: 98.0%\n",
      "Iteration: 68000\n",
      "loss: 2.48698449135\n",
      "Accuray: 92.0%\n",
      "Iteration: 69000\n",
      "loss: 1.4074729681\n",
      "Accuray: 100.0%\n",
      "Iteration: 70000\n",
      "loss: 1.86222743988\n",
      "Accuray: 98.0%\n",
      "Iteration: 71000\n",
      "loss: 1.81660938263\n",
      "Accuray: 98.0%\n",
      "Iteration: 72000\n",
      "loss: 2.53898215294\n",
      "Accuray: 90.0%\n",
      "Iteration: 73000\n",
      "loss: 1.56245684624\n",
      "Accuray: 100.0%\n",
      "Iteration: 74000\n",
      "loss: 1.66174983978\n",
      "Accuray: 96.0%\n",
      "Iteration: 75000\n",
      "loss: 1.14094674587\n",
      "Accuray: 100.0%\n",
      "Iteration: 76000\n",
      "loss: 1.28919112682\n",
      "Accuray: 98.0%\n",
      "Iteration: 77000\n",
      "loss: 1.68507885933\n",
      "Accuray: 96.0%\n",
      "Iteration: 78000\n",
      "loss: 1.6821398735\n",
      "Accuray: 98.0%\n",
      "Iteration: 79000\n",
      "loss: 1.64376425743\n",
      "Accuray: 100.0%\n",
      "Iteration: 80000\n",
      "loss: 1.26975286007\n",
      "Accuray: 98.0%\n",
      "Iteration: 81000\n",
      "loss: 1.5840845108\n",
      "Accuray: 98.0%\n",
      "Iteration: 82000\n",
      "loss: 1.35064733028\n",
      "Accuray: 96.0%\n",
      "Iteration: 83000\n",
      "loss: 1.39680683613\n",
      "Accuray: 98.0%\n",
      "Iteration: 84000\n",
      "loss: 1.54276549816\n",
      "Accuray: 98.0%\n",
      "Iteration: 85000\n",
      "loss: 1.15940701962\n",
      "Accuray: 100.0%\n",
      "Iteration: 86000\n",
      "loss: 0.846100986004\n",
      "Accuray: 100.0%\n",
      "Iteration: 87000\n",
      "loss: 1.2743986845\n",
      "Accuray: 98.0%\n",
      "Iteration: 88000\n",
      "loss: 1.16608989239\n",
      "Accuray: 100.0%\n",
      "Iteration: 89000\n",
      "loss: 1.13193440437\n",
      "Accuray: 100.0%\n",
      "Iteration: 90000\n",
      "loss: 0.907853126526\n",
      "Accuray: 100.0%\n",
      "Iteration: 91000\n",
      "loss: 1.27295923233\n",
      "Accuray: 98.0%\n",
      "Iteration: 92000\n",
      "loss: 0.864353835583\n",
      "Accuray: 100.0%\n",
      "Iteration: 93000\n",
      "loss: 0.840053915977\n",
      "Accuray: 100.0%\n",
      "Iteration: 94000\n",
      "loss: 0.86457067728\n",
      "Accuray: 100.0%\n",
      "Iteration: 95000\n",
      "loss: 0.817588269711\n",
      "Accuray: 100.0%\n",
      "Iteration: 96000\n",
      "loss: 1.17432427406\n",
      "Accuray: 100.0%\n",
      "Iteration: 97000\n",
      "loss: 1.02684593201\n",
      "Accuray: 100.0%\n",
      "Iteration: 98000\n",
      "loss: 0.851458072662\n",
      "Accuray: 100.0%\n",
      "Iteration: 99000\n",
      "loss: 0.814104020596\n",
      "Accuray: 100.0%\n"
     ]
    }
   ],
   "source": [
    "NUM_RULE_INPUTS = len(taskRuleSet.Code[0])\n",
    "NUM_SENSORY_INPUTS = len(stimuliSet.Code[0])\n",
    "NUM_HIDDEN = 100\n",
    "NUM_MOTOR_DECISION_OUTPUTS = 4\n",
    "NUM_TRAINING_ITERATIONS = 100000 # Maybe 20000 is better\n",
    "NUM_TRAINING_RULES_PER_EPOCH = 2\n",
    "NUM_TRAINING_STIMULI_PER_RULE = 5\n",
    "\n",
    "w_in = Variable(torch.Tensor(NUM_RULE_INPUTS + NUM_SENSORY_INPUTS, NUM_HIDDEN).uniform_(-0.5,0.5), requires_grad=True)\n",
    "w_rec = Variable(torch.Tensor(NUM_HIDDEN, NUM_HIDDEN).uniform_(-0.5,0.5), requires_grad=True)\n",
    "w_out = Variable(torch.Tensor(NUM_HIDDEN, NUM_MOTOR_DECISION_OUTPUTS).uniform_(-0.5,0.5), requires_grad=True)\n",
    "bias = Variable(torch.Tensor(1, NUM_HIDDEN).uniform_(-0.5, 0), requires_grad=False)\n",
    "drdt = 0.05\n",
    "\n",
    "#outputs = networkOutputCode\n",
    "#randomInputs = np.random.randint(0,len(networkInputCode),10)\n",
    "#inputs = np.asarray(networkInputCode)[randomInputs]\n",
    "\n",
    "accuracyPerEpoch = []\n",
    "\n",
    "learning_rate = 0.01\n",
    "for iteration_num in range(NUM_TRAINING_ITERATIONS):\n",
    "    previous_r = Variable(torch.Tensor(1, NUM_HIDDEN).zero_(), requires_grad=False)\n",
    "    error = 0\n",
    "    \n",
    "    # Increase number of presented tasks with number of increased iterations\n",
    "    # Don't allow more than 10 task rules per epoch, since it will just slow training down\n",
    "    if iteration_num % 2000 == 0:\n",
    "        if NUM_TRAINING_RULES_PER_EPOCH < 10:\n",
    "            NUM_TRAINING_RULES_PER_EPOCH += 1\n",
    "    \n",
    "    df, inputs, outputs = createTrainingSet(trainRuleSet, nStimuli=NUM_TRAINING_STIMULI_PER_RULE, nTasks=NUM_TRAINING_RULES_PER_EPOCH, delay=True) # 64 * 20 stimuli\n",
    "    \n",
    "    acc = []\n",
    "    for timestep in range(len(inputs)):\n",
    "        u = Variable(torch.Tensor([inputs[timestep]]))\n",
    "        target = Variable(torch.Tensor([outputs[timestep]]))\n",
    "\n",
    "        # The neural network\n",
    "        r = previous_r - drdt*previous_r + drdt* F.relu(previous_r.mm(w_rec) + u.mm(w_in) + bias)\n",
    "        output = r.mm(w_out)\n",
    "\n",
    "        error += torch.mean((output - target).pow(2))  # Mean squared error loss\n",
    "        previous_r = r  # Recurrence\n",
    "\n",
    "   #     if iteration_num % 1000 == 0:\n",
    "   #         print(output.data.numpy())\n",
    "\n",
    "        if np.sum(np.asarray(target.data))!=0:\n",
    "            distance = np.abs(1.0-output.data)\n",
    "            if np.where(distance == distance.min())[1][0] == np.where(np.asarray(target.data))[1][0]:\n",
    "                acc.append(1.0)\n",
    "            else:\n",
    "                acc.append(0.0)\n",
    "        \n",
    "    if iteration_num % 1000 == 0:\n",
    "        print 'Iteration:', iteration_num\n",
    "        print '\\tloss:', error.data[0]\n",
    "        print '\\tAccuracy: ' + str(round(np.mean(acc)*100.0,4)) +'%'\n",
    "    \n",
    "    accuracyPerEpoch.append(np.mean(acc)*100.0)\n",
    "    if iteration_num>10:\n",
    "        if np.sum(accuracyPerEpoch[-10:]>.9)==5:\n",
    "            print 'Last 5 epochs had above 90% accuracy... stopping training'\n",
    "            break\n",
    "            \n",
    "    \n",
    "        \n",
    "    # Learning\n",
    "    error.backward()\n",
    "    w_in.data -= learning_rate*w_in.grad.data; w_in.grad.data.zero_()\n",
    "    w_rec.data -= learning_rate*w_rec.grad.data; w_rec.grad.data.zero_()\n",
    "    w_out.data -= learning_rate*w_out.grad.data; w_out.grad.data.zero_()\n",
    "\n",
    "torch.save(w_in,'../../models/Model2a_Win')\n",
    "torch.save(w_rec,'../../models/Model2a_Wrec')\n",
    "torch.save(w_out,'../../models/Model2a_Wout')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on entire stimulus set and practiced task rule set: 99.899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "previous_r = Variable(torch.Tensor(1, NUM_HIDDEN).zero_(), requires_grad=False)\n",
    "error = 0\n",
    "\n",
    "df, inputs, outputs = createTrainingSet(trainRuleSet, nStimuli=len(stimuliSet), nTasks=len(trainRuleSet), delay=True) # 64 * 20 stimuli\n",
    "\n",
    "acc = []\n",
    "for timestep in range(len(inputs)):\n",
    "    u = Variable(torch.Tensor([inputs[timestep]]))\n",
    "    target = Variable(torch.Tensor([outputs[timestep]]))\n",
    "\n",
    "    # The neural network\n",
    "    r = previous_r - drdt*previous_r + drdt* F.relu(previous_r.mm(w_rec) + u.mm(w_in) + bias)\n",
    "    output = r.mm(w_out)\n",
    "\n",
    "    error += torch.mean((output - target).pow(2))  # Mean squared error loss\n",
    "    previous_r = r  # Recurrence\n",
    "\n",
    "#     if iteration_num % 1000 == 0:\n",
    "#         print(output.data.numpy())\n",
    "\n",
    "    if np.sum(np.asarray(target.data))!=0:\n",
    "        distance = np.abs(1.0-output.data)\n",
    "        if np.where(distance == distance.min())[1][0] == np.where(np.asarray(target.data))[1][0]:\n",
    "            acc.append(1.0)\n",
    "        else:\n",
    "            acc.append(0.0)\n",
    "            \n",
    "            \n",
    "print 'Accuracy on entire stimulus set and practiced task rule set:', round(np.mean(acc)*100.0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on entire stimulus set and unseen task rule set: 63.294\n"
     ]
    }
   ],
   "source": [
    "previous_r = Variable(torch.Tensor(1, NUM_HIDDEN).zero_(), requires_grad=False)\n",
    "error = 0\n",
    "\n",
    "df, inputs, outputs = createTrainingSet(taskRuleSet, nStimuli=len(stimuliSet), nTasks=len(trainRuleSet), delay=True) # 64 * 20 stimuli\n",
    "\n",
    "acc = []\n",
    "for timestep in range(len(inputs)):\n",
    "    u = Variable(torch.Tensor([inputs[timestep]]))\n",
    "    target = Variable(torch.Tensor([outputs[timestep]]))\n",
    "\n",
    "    # The neural network\n",
    "    r = previous_r - drdt*previous_r + drdt* F.relu(previous_r.mm(w_rec) + u.mm(w_in) + bias)\n",
    "    output = r.mm(w_out)\n",
    "\n",
    "    error += torch.mean((output - target).pow(2))  # Mean squared error loss\n",
    "    previous_r = r  # Recurrence\n",
    "\n",
    "#     if iteration_num % 1000 == 0:\n",
    "#         print(output.data.numpy())\n",
    "\n",
    "    if np.sum(np.asarray(target.data))!=0:\n",
    "        distance = np.abs(1.0-output.data)\n",
    "        if np.where(distance == distance.min())[1][0] == np.where(np.asarray(target.data))[1][0]:\n",
    "            acc.append(1.0)\n",
    "        else:\n",
    "            acc.append(0.0)\n",
    "            \n",
    "            \n",
    "print 'Accuracy on entire stimulus set and unseen task rule set:', round(np.mean(acc)*100.0,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
