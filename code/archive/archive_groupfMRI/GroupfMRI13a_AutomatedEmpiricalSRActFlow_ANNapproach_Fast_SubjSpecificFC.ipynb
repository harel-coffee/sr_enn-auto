{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupfMRI13a - Automated SRActFlow using ANN-inspired representations\n",
    "#### Using subject-specific FC\n",
    "#### Using ActFlow\n",
    "\n",
    "#### Takuya Ito\n",
    "#### 05/29/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import tools_group_rsa as tools_group\n",
    "import nibabel as nib\n",
    "import EmpiricalSRActFlow_ANN_RSA_v2 as esr\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load real motor response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tools_group_rsa.py:95: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,0] = data[:,2]\n",
      "tools_group_rsa.py:96: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,1] = data[:,3]\n",
      "tools_group_rsa.py:98: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,0] = data[:,0] #lmid\n",
      "tools_group_rsa.py:99: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,1] = data[:,1] #lind\n"
     ]
    }
   ],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nResponses = 2\n",
    "data_task_rh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "data_task_lh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task_rh[:,:,scount] = np.real(tools_group.loadMotorResponses(subj,hand='Right'))\n",
    "    data_task_lh[:,:,scount] = np.real(tools_group.loadMotorResponses(subj,hand='Left'))\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define wrapper function for SRActFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 013\n",
      "Subject 031\n",
      "Subject 032\n",
      "Subject 014\n",
      "Subject 033\n",
      "Subject 016\n",
      "Subject 034\n",
      "Subject 017\n",
      "Subject 035\n",
      "Subject 018\n",
      "Subject 037\n",
      "Subject 021\n",
      "Subject 038\n",
      "Subject 023\n",
      "Subject 039\n",
      "Subject 024\n",
      "Subject 040\n",
      "Subject 026\n",
      "Subject 041\n",
      "Subject 027\n",
      "Subject 042\n",
      "Subject 028\n",
      "Subject 043\n",
      "Subject 030\n",
      "Subject 045\n",
      "Subject 063\n",
      "Subject 046\n",
      "Subject 066\n",
      "Subject 047\n",
      "Subject 067\n",
      "Subject 048\n",
      "Subject 068\n",
      "Subject 049\n",
      "Subject 069\n",
      "Subject 050\n",
      "Subject 070\n",
      "Subject 053\n",
      "Subject 072\n",
      "Subject 055\n",
      "Subject 074\n",
      "Subject 056\n",
      "Subject 075\n",
      "Subject 057\n",
      "Subject 076\n",
      "Subject 058\n",
      "Subject 077\n",
      "Subject 062\n",
      "Subject 081\n",
      "Subject 085\n",
      "Subject 101\n",
      "Subject 086\n",
      "Subject 102\n",
      "Subject 087\n",
      "Subject 103\n",
      "Subject 088\n",
      "Subject 104\n",
      "Subject 090\n",
      "Subject 105\n",
      "Subject 092\n",
      "Subject 106\n",
      "Subject 093\n",
      "Subject 108\n",
      "Subject 094\n",
      "Subject 109\n",
      "Subject 095\n",
      "Subject 110\n",
      "Subject 097\n",
      "Subject 111\n",
      "Subject 098\n",
      "Subject 112\n",
      "Subject 099\n",
      "Subject 114\n",
      "Subject 115\n",
      "Subject 129\n",
      "Subject 117\n",
      "Subject 130\n",
      "Subject 119\n",
      "Subject 131\n",
      "Subject 120\n",
      "Subject 132\n",
      "Subject 121\n",
      "Subject 134\n",
      "Subject 122\n",
      "Subject 135\n",
      "Subject 123\n",
      "Subject 136\n",
      "Subject 124\n",
      "Subject 137\n",
      "Subject 125\n",
      "Subject 138\n",
      "Subject 126\n",
      "Subject 139\n",
      "Subject 127\n",
      "Subject 140\n",
      "Subject 128\n",
      "Subject 141\n",
      "time elapsed: 120.902812004\n"
     ]
    }
   ],
   "source": [
    "esr = reload(esr)\n",
    "tools_group = reload(tools_group)\n",
    "def subjSRActFlow_PCFC((subj,seed)):\n",
    "    print 'Subject', subj\n",
    "    \n",
    "    #### LoadFC\n",
    "    inputtypes = ['color','ori','pitch','constant']\n",
    "    inputkeys = ['RED','VERTICAL','HIGH','CONSTANT']\n",
    "    fc_input2hidden = {}\n",
    "    eig_input2hidden = {}\n",
    "    i = 0\n",
    "    for inputtype in inputtypes:\n",
    "        fc_input2hidden[inputkeys[i]], fc_hidden2motorresp, eig_input2hidden[inputkeys[i]], eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,inputtype,pc_space=True)\n",
    "        i += 1\n",
    "\n",
    "    # Load rules to hidden FC mappings\n",
    "    fc_logic2hidden, fc_hidden2motorresp, eig_logic2hidden, eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,'Logic',pc_space=True)\n",
    "    fc_sensory2hidden, fc_hidden2motorresp, eig_sensory2hidden, eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,'Sensory',pc_space=True)\n",
    "    fc_motor2hidden, fc_hidden2motorresp, eig_motor2hidden, eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,'Motor',pc_space=True)\n",
    "    \n",
    "    #### Run Empirical SRActFlow\n",
    "    obj = esr.EmpiricalActFlow(subj)\n",
    "    # Input\n",
    "    obj.fc_input2hidden = fc_input2hidden\n",
    "    obj.eig_input2hidden = eig_input2hidden\n",
    "    # Rules\n",
    "    obj.fc_logic2hidden = fc_logic2hidden\n",
    "    obj.eig_logic2hidden = eig_logic2hidden\n",
    "    obj.fc_sensory2hidden = fc_sensory2hidden\n",
    "    obj.eig_sensory2hidden = eig_sensory2hidden\n",
    "    obj.fc_motor2hidden = fc_motor2hidden\n",
    "    obj.eig_motor2hidden = eig_motor2hidden\n",
    "    # hidden 2 motor\n",
    "    obj.fc_hidden2motorresp = fc_hidden2motorresp\n",
    "    obj.eig_hidden2motorresp = eig_hidden2motorresp\n",
    "    \n",
    "    obj.extractAllActivations(seed,n_inputs=1)\n",
    "    \n",
    "\n",
    "    actflow = obj.generateActFlowPredictions_PCFC(thresh=0,verbose=False)\n",
    "    del obj\n",
    "    return actflow\n",
    "\n",
    "global fc_input2hidden\n",
    "global fc_logic2hidden\n",
    "global fc_sensory2hidden\n",
    "global fc_motor2hidden\n",
    "\n",
    "inputs = []\n",
    "for i in range(len(subjNums)):\n",
    "    inputs.append((subjNums[i],np.random.randint(1000000)))\n",
    "\n",
    "timestart = time.time()\n",
    "pool = mp.Pool(processes=2)\n",
    "results = pool.map_async(subjSRActFlow_PCFC,inputs).get()\n",
    "pool.close()\n",
    "pool.join()\n",
    "timeend = time.time()\n",
    "print \"time elapsed:\", timeend-timestart\n",
    "\n",
    "actflow_predictions = np.asarray(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify target vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set indices for layer-by-layer vertices\n",
    "targetdir = '/projects3/SRActFlow/data/results/GroupfMRI/MotorResponseDecoding/'\n",
    "motor_resp_regions_LH = np.loadtxt(targetdir + 'MotorResponseRegions_LH.csv',delimiter=',')\n",
    "motor_resp_regions_RH = np.loadtxt(targetdir + 'MotorResponseRegions_RH.csv',delimiter=',')\n",
    "targetROIs = np.hstack((motor_resp_regions_LH,motor_resp_regions_RH))\n",
    "\n",
    "target_ind = []\n",
    "for roi in targetROIs:\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    target_ind.extend(roi_ind)\n",
    "target_ind = np.asarray(target_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute average activity for each response, for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scount = 0\n",
    "actflow_rh = np.zeros(data_task_rh.shape)\n",
    "actflow_lh = np.zeros(data_task_lh.shape)\n",
    "for scount in range(len(subjNums)):\n",
    "    # RMID\n",
    "    actflow_rh[target_ind,0,scount] = actflow_predictions[scount,:,2]\n",
    "    # RIND\n",
    "    actflow_rh[target_ind,1,scount] = actflow_predictions[scount,:,3]\n",
    "    # LMID\n",
    "    actflow_lh[target_ind,0,scount] = actflow_predictions[scount,:,0]\n",
    "    # LIND\n",
    "    actflow_lh[target_ind,1,scount] = actflow_predictions[scount,:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run across subject decoding on right-hand motor responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nproc = 20\n",
    "nResponses = 2\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.asarray([8,52,9])-1\n",
    "# rois = np.asarray([52])-1\n",
    "# rois = np.where(networkdef==networkmappings['smn'])[0]\n",
    "roi_ind = []\n",
    "for roi in rois:\n",
    "    roi_ind.extend(np.where(glasser2==roi+1)[0])\n",
    "\n",
    "# realdata = stats.zscore(data_task_rh[target_ind,:,:],axis=0).copy()\n",
    "# flowdata = stats.zscore(actflow_rh[target_ind,:,:],axis=0).copy()\n",
    "realdata = data_task_rh[roi_ind,:,:].copy()\n",
    "flowdata = actflow_rh[roi_ind,:,:].copy()\n",
    "\n",
    "\n",
    "distances_baseline_rh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_rh[0,:],rmatch,rmismatch = tools_group.actflowDecodings(realdata,\n",
    "                                                          flowdata,effects=True,\n",
    "                                                          ncvs=ncvs, nproc=nproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.427083333333\n",
      "p = 0.974467622661\n",
      "Matched spatial correlation: -0.00816645604295\n",
      "Mismatched spatial correlation: 0.00816645604295\n"
     ]
    }
   ],
   "source": [
    "statistics_rh = np.zeros((distances_baseline_rh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_rh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_rh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_rh[0,0] = np.mean(distances_baseline_rh[0,:])\n",
    "statistics_rh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_rh[0,0]\n",
    "print 'p =', statistics_rh[0,1]\n",
    "print 'Matched spatial correlation:', np.mean(rmatch)\n",
    "print 'Mismatched spatial correlation:', np.mean(rmismatch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run across subject decoding on left-hand motor responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.asarray([188,189,232]) - 1\n",
    "# rois = np.asarray([189]) - 1\n",
    "# rois = np.where(networkdef==networkmappings['smn'])[0]\n",
    "roi_ind = []\n",
    "for roi in rois:\n",
    "    roi_ind.extend(np.where(glasser2==roi+1)[0])\n",
    "    \n",
    "# realdata = stats.zscore(data_task_lh[roi_ind,:,:],axis=0).copy()\n",
    "# flowdata = stats.zscore(actflow_lh[roi_ind,:,:],axis=0).copy()\n",
    "realdata = data_task_lh[roi_ind,:,:].copy()\n",
    "flowdata = actflow_lh[roi_ind,:,:].copy()\n",
    "\n",
    "\n",
    "distances_baseline_lh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_lh[0,:],rmatch,rmismatch = tools_group.actflowDecodings(realdata,\n",
    "                                                          flowdata,effects=True,\n",
    "                                                          ncvs=ncvs, nproc=nproc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.458333333333\n",
      "p = 0.860509115482\n",
      "Matched spatial correlation: -0.0107879767516\n",
      "Mismatched spatial correlation: 0.0107879767516\n"
     ]
    }
   ],
   "source": [
    "statistics_lh = np.zeros((distances_baseline_lh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_lh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_lh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_lh[0,0] = np.mean(distances_baseline_lh[0,:])\n",
    "statistics_lh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_lh[0,0]\n",
    "print 'p =', statistics_lh[0,1]\n",
    "print 'Matched spatial correlation:', np.mean(rmatch)\n",
    "print 'Mismatched spatial correlation:', np.mean(rmismatch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control -- Don't apply a threshold in the hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define wrapper function for Control - SRActFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 013\n",
      "Subject 031\n",
      "Subject 032\n",
      "Subject 014\n",
      "Subject 033\n",
      "Subject 016\n",
      "Subject 034\n",
      "Subject 017\n",
      "Subject 035\n",
      "Subject 018\n",
      "Subject 037\n",
      "Subject 021\n",
      "Subject 038\n",
      "Subject 023\n",
      "Subject 039\n",
      "Subject 024\n",
      "Subject 040\n",
      "Subject 026\n",
      "Subject 041\n",
      "Subject 027\n",
      "Subject 042\n",
      "Subject 028\n",
      "Subject 043\n",
      "Subject 030\n",
      "Subject 045\n",
      "Subject 063\n",
      "Subject 046\n",
      "Subject 066\n",
      "Subject 047\n",
      "Subject 067\n",
      "Subject 048\n",
      "Subject 068\n",
      "Subject 049\n",
      "Subject 069\n",
      "Subject 050\n",
      "Subject 070\n",
      "Subject 053\n",
      "Subject 072\n",
      "Subject 055\n",
      "Subject 074\n",
      "Subject 056\n",
      "Subject 075\n",
      "Subject 057\n",
      "Subject 076\n",
      "Subject 058\n",
      "Subject 077\n",
      "Subject 062\n",
      "Subject 081\n",
      "Subject 085\n",
      "Subject 101\n",
      "Subject 086\n",
      "Subject 102\n",
      "Subject 087\n",
      "Subject 103\n",
      "Subject 088\n",
      "Subject 104\n",
      "Subject 090\n",
      "Subject 105\n",
      "Subject 092\n",
      "Subject 106\n",
      "Subject 093\n",
      "Subject 108\n",
      "Subject 094\n",
      "Subject 109\n",
      "Subject 095\n",
      "Subject 110\n",
      "Subject 097\n",
      "Subject 111\n",
      "Subject 098\n",
      "Subject 112\n",
      "Subject 099\n",
      "Subject 114\n",
      "Subject 115\n",
      "Subject 129\n",
      "Subject 117\n",
      "Subject 130\n",
      "Subject 119\n",
      "Subject 131\n",
      "Subject 120\n",
      "Subject 132\n",
      "Subject 121\n",
      "Subject 134\n",
      "Subject 122\n",
      "Subject 135\n",
      "Subject 123\n",
      "Subject 136\n",
      "Subject 124\n",
      "Subject 137\n",
      "Subject 125\n",
      "Subject 138\n",
      "Subject 126\n",
      "Subject 139\n",
      "Subject 127\n",
      "Subject 140\n",
      "Subject 128\n",
      "Subject 141\n",
      "time elapsed: 972.416703939\n"
     ]
    }
   ],
   "source": [
    "esr = reload(esr)\n",
    "tools_group = reload(tools_group)\n",
    "def subjSRActFlow_PCFC_ControlNoThresh((subj,seed)):\n",
    "    print 'Subject', subj\n",
    "    \n",
    "    #### LoadFC\n",
    "    inputtypes = ['color','ori','pitch','constant']\n",
    "    inputkeys = ['RED','VERTICAL','HIGH','CONSTANT']\n",
    "    fc_input2hidden = {}\n",
    "    eig_input2hidden = {}\n",
    "    i = 0\n",
    "    for inputtype in inputtypes:\n",
    "        fc_input2hidden[inputkeys[i]], fc_hidden2motorresp, eig_input2hidden[inputkeys[i]], eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,inputtype,pc_space=True)\n",
    "        i += 1\n",
    "\n",
    "    # Load rules to hidden FC mappings\n",
    "    fc_logic2hidden, fc_hidden2motorresp, eig_logic2hidden, eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,'Logic',pc_space=True)\n",
    "    fc_sensory2hidden, fc_hidden2motorresp, eig_sensory2hidden, eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,'Sensory',pc_space=True)\n",
    "    fc_motor2hidden, fc_hidden2motorresp, eig_motor2hidden, eig_hidden2motorresp = tools_group.loadSubjActFlowFC(subj,'Motor',pc_space=True)\n",
    "    \n",
    "    #### Run Empirical SRActFlow\n",
    "    obj = esr.EmpiricalActFlow(subj)\n",
    "    # Input\n",
    "    obj.fc_input2hidden = fc_input2hidden\n",
    "    obj.eig_input2hidden = eig_input2hidden\n",
    "    # Rules\n",
    "    obj.fc_logic2hidden = fc_logic2hidden\n",
    "    obj.eig_logic2hidden = eig_logic2hidden\n",
    "    obj.fc_sensory2hidden = fc_sensory2hidden\n",
    "    obj.eig_sensory2hidden = eig_sensory2hidden\n",
    "    obj.fc_motor2hidden = fc_motor2hidden\n",
    "    obj.eig_motor2hidden = eig_motor2hidden\n",
    "    # hidden 2 motor\n",
    "    obj.fc_hidden2motorresp = fc_hidden2motorresp\n",
    "    obj.eig_hidden2motorresp = eig_hidden2motorresp\n",
    "    \n",
    "    obj.extractAllActivations(seed,n_inputs=40)\n",
    "    \n",
    "\n",
    "    actflow = obj.generateActFlowPredictions_PCFC(thresh=None,verbose=False)\n",
    "    del obj\n",
    "    return actflow\n",
    "\n",
    "global fc_input2hidden\n",
    "global fc_logic2hidden\n",
    "global fc_sensory2hidden\n",
    "global fc_motor2hidden\n",
    "\n",
    "inputs = []\n",
    "for i in range(len(subjNums)):\n",
    "    inputs.append((subjNums[i],np.random.randint(1000000)))\n",
    "\n",
    "timestart = time.time()\n",
    "pool = mp.Pool(processes=2)\n",
    "results = pool.map_async(subjSRActFlow_PCFC_ControlNoThresh,inputs).get()\n",
    "pool.close()\n",
    "pool.join()\n",
    "timeend = time.time()\n",
    "print \"time elapsed:\", timeend-timestart\n",
    "\n",
    "actflow_predictions_control = np.asarray(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify target vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set indices for layer-by-layer vertices\n",
    "targetdir = '/projects3/SRActFlow/data/results/GroupfMRI/MotorResponseDecoding/'\n",
    "motor_resp_regions_LH = np.loadtxt(targetdir + 'MotorResponseRegions_LH.csv',delimiter=',')\n",
    "motor_resp_regions_RH = np.loadtxt(targetdir + 'MotorResponseRegions_RH.csv',delimiter=',')\n",
    "targetROIs = np.hstack((motor_resp_regions_LH,motor_resp_regions_RH))\n",
    "\n",
    "target_ind = []\n",
    "for roi in targetROIs:\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    target_ind.extend(roi_ind)\n",
    "target_ind = np.asarray(target_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute average activity for each response, for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scount = 0\n",
    "actflow_rh = np.zeros(data_task_rh.shape)\n",
    "actflow_lh = np.zeros(data_task_lh.shape)\n",
    "for scount in range(len(subjNums)):\n",
    "    # RMID\n",
    "    actflow_rh[target_ind,0,scount] = actflow_predictions_control[scount,:,2]\n",
    "    # RIND\n",
    "    actflow_rh[target_ind,1,scount] = actflow_predictions_control[scount,:,3]\n",
    "    # LMID\n",
    "    actflow_lh[target_ind,0,scount] = actflow_predictions_control[scount,:,0]\n",
    "    # LIND\n",
    "    actflow_lh[target_ind,1,scount] = actflow_predictions_control[scount,:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run across subject decoding on right-hand motor responses -- no threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nproc = 20\n",
    "nResponses = 2\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.asarray([8,52,9])-1\n",
    "# rois = np.asarray([52])-1\n",
    "# rois = np.where(networkdef==networkmappings['smn'])[0]\n",
    "roi_ind = []\n",
    "for roi in rois:\n",
    "    roi_ind.extend(np.where(glasser2==roi+1)[0])\n",
    "\n",
    "# realdata = stats.zscore(data_task_rh[target_ind,:,:],axis=0).copy()\n",
    "# flowdata = stats.zscore(actflow_rh[target_ind,:,:],axis=0).copy()\n",
    "realdata = data_task_rh[roi_ind,:,:].copy()\n",
    "flowdata = actflow_rh[roi_ind,:,:].copy()\n",
    "\n",
    "\n",
    "distances_baseline_rh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_rh[0,:],rmatch,rmismatch = tools_group.actflowDecodings(realdata,\n",
    "                                                          flowdata,effects=True,\n",
    "                                                          ncvs=ncvs, nproc=nproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.46875\n",
      "p = 0.786322705302\n",
      "Matched spatial correlation: -0.0045094293752\n",
      "Mismatched spatial correlation: -0.00260183079112\n"
     ]
    }
   ],
   "source": [
    "statistics_rh = np.zeros((distances_baseline_rh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_rh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_rh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_rh[0,0] = np.mean(distances_baseline_rh[0,:])\n",
    "statistics_rh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_rh[0,0]\n",
    "print 'p =', statistics_rh[0,1]\n",
    "print 'Matched spatial correlation:', np.mean(rmatch)\n",
    "print 'Mismatched spatial correlation:', np.mean(rmismatch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run across subject decoding on left-hand motor responses -- no threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.asarray([188,189,232]) - 1\n",
    "# rois = np.asarray([189]) - 1\n",
    "# rois = np.where(networkdef==networkmappings['smn'])[0]\n",
    "roi_ind = []\n",
    "for roi in rois:\n",
    "    roi_ind.extend(np.where(glasser2==roi+1)[0])\n",
    "    \n",
    "# realdata = stats.zscore(data_task_lh[roi_ind,:,:],axis=0).copy()\n",
    "# flowdata = stats.zscore(actflow_lh[roi_ind,:,:],axis=0).copy()\n",
    "realdata = data_task_lh[roi_ind,:,:].copy()\n",
    "flowdata = actflow_lh[roi_ind,:,:].copy()\n",
    "\n",
    "\n",
    "distances_baseline_lh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_lh[0,:],rmatch,rmismatch = tools_group.actflowDecodings(realdata,\n",
    "                                                          flowdata,effects=True,\n",
    "                                                          ncvs=ncvs, nproc=nproc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.557291666667\n",
      "p = 0.0647094657579\n",
      "Matched spatial correlation: 0.0117624505383\n",
      "Mismatched spatial correlation: 0.00801956404574\n"
     ]
    }
   ],
   "source": [
    "statistics_lh = np.zeros((distances_baseline_lh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_lh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_lh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_lh[0,0] = np.mean(distances_baseline_lh[0,:])\n",
    "statistics_lh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_lh[0,0]\n",
    "print 'p =', statistics_lh[0,1]\n",
    "print 'Matched spatial correlation:', np.mean(rmatch)\n",
    "print 'Mismatched spatial correlation:', np.mean(rmismatch)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
