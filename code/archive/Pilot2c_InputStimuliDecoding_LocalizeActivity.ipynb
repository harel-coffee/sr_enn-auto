{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot 2 -- Compute the baseline decodability of various input stimuli combinations\n",
    "### Ex: Color stims ([red, red] v. [red, blue] v. [blue, red] v. [blue, blue])\n",
    "\n",
    "## Use SVM classifications to input stimuli (both modalities: visual and auditory)\n",
    "## Using Ciric-style postprocessing\n",
    "\n",
    "## Takuya Ito\n",
    "#### 12/06/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nib\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.api as sm\n",
    "import sklearn.svm as svm\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import sklearn\n",
    "from sklearn.feature_selection import f_classif\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "os.sys.path.append('glmScripts/')\n",
    "import taskGLMPipeline as tgp\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Define functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadInputActivity(subj,inputtype):\n",
    "    x = tgp.loadTaskTiming(subj,'ALL')\n",
    "    stimIndex = np.asarray(x['stimIndex'])\n",
    "    ind = np.where(stimIndex==inputtype)[0]\n",
    "    \n",
    "    datadir = basedir + 'data/postProcessing/hcpPostProcCiric/'\n",
    "    h5f = h5py.File(datadir + subj + '_glmOutput_data.h5','r')\n",
    "    data = h5f['taskRegression/ALL_24pXaCompCorXVolterra_taskReg_betas_canonical'][:].copy()\n",
    "    data = data[:,ind].copy()\n",
    "    h5f.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate analyses to identify regions sensitive to stimulus activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulusActivations = np.zeros((len(glasser2),len(subjNums)))\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    stimulusActivations[:,scount] = np.mean(loadInputActivity(subj,'colorStim'),axis=1)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant activations during stimulus presentation: 219\n"
     ]
    }
   ],
   "source": [
    "roiActivity = np.zeros((nParcels,))\n",
    "for roi in range(nParcels):\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    roi_activity = np.mean(stimulusActivations[roi_ind,:],axis=0)\n",
    "    t, p = stats.ttest_1samp(roi_activity,0)\n",
    "    roiActivity[roi] = p\n",
    "\n",
    "\n",
    "h0, q = mc.fdrcorrection0(roiActivity)\n",
    "roiActivity[:] = h0\n",
    "print 'Number of significant activations during stimulus presentation:', np.sum(h0)\n",
    "activeROIs = np.where(h0)[0] + 1\n",
    "\n",
    "activeROIs = np.arange(1,361)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Define functions for input stimuli decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def inputStimuliDecoding(data, inputtype, atlasROIs=np.arange(1,nParcels+1), ncvs=100, nproc=5):\n",
    "    \"\"\"\n",
    "    Run an across-subject classification\n",
    "    Decode input stimuli (4-way decoding) for each sensory rule type\n",
    "    Limit to ROIs within either vis or aud network\n",
    "    \"\"\"\n",
    "        \n",
    "    nstim = 4 # Number of stimuli per stimulus-type\n",
    "    \n",
    "    nSubjs = data.shape[2]\n",
    "    if inputtype in ['colorStim','oriStim']:\n",
    "        # Visual networks\n",
    "        rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "        rois = rois + 1\n",
    "        rois = np.intersect1d(rois,atlasROIs)\n",
    "    elif inputtype in ['constantStim','pitchStim']:\n",
    "        rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "        rois = rois + 1\n",
    "        rois = np.intersect1d(rois,atlasROIs)\n",
    "\n",
    "    netStats = np.zeros((len(rois),nstim*nSubjs))\n",
    "\n",
    "\n",
    "    nsamples = nSubjs * nstim\n",
    "\n",
    "    # Label array for supervised learning\n",
    "    labels = np.tile(range(nstim),nSubjs)\n",
    "    subjarray = np.repeat(range(nSubjs),nstim)\n",
    "\n",
    "    # Run SVM classifications on network-level activation patterns across subjects\n",
    "    roicount = 0\n",
    "    for roi in rois:\n",
    "        print 'Computing SVM classification for input stimuli:', inputtype, 'for ROI', roicount, '/', len(rois)\n",
    "        roi_ind = np.where(glasser2==roi)[0]\n",
    "        nfeatures = len(roi_ind)\n",
    "        roi_ind.shape = (len(roi_ind),1)       \n",
    "\n",
    "        svm_mat = np.zeros((nsamples,roi_ind.shape[0]))\n",
    "        samplecount = 0\n",
    "        scount = 0\n",
    "        for subj in range(len(subjNums)):\n",
    "            roidata = np.squeeze(data[roi_ind,:,scount])\n",
    "            svm_mat[samplecount:(samplecount+nstim),:] = roidata.T\n",
    "\n",
    "            scount += 1\n",
    "            samplecount += nstim\n",
    "\n",
    "            # Spatially demean matrix across features\n",
    "            samplemean = np.mean(svm_mat,axis=1)\n",
    "            samplemean.shape = (len(samplemean),1)\n",
    "            svm_mat = svm_mat - samplemean\n",
    "\n",
    "        scores = randomSplitLOOBaselineCV(ncvs, svm_mat, labels, subjarray, nproc=nproc)\n",
    "        netStats[roicount,:] = scores\n",
    "        roicount += 1\n",
    "\n",
    "\n",
    "    return netStats\n",
    "\n",
    "def randomSplitLOOBaselineCV(ncvs, svm_mat, labels, subjarray, nproc=5):\n",
    "    \"\"\"\n",
    "    Runs cross validation for an across-subject SVM analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    ntasks = len(np.unique(labels))\n",
    "    nsamples = svm_mat.shape[0]\n",
    "    nsubjs = nsamples/ntasks\n",
    "\n",
    "    subjects = np.unique(subjarray)\n",
    "    indices = np.arange(nsamples)\n",
    "    \n",
    "    numsubjs_perfold = 1\n",
    "    if nsubjs%numsubjs_perfold!=0: \n",
    "        raise Exception(\"Error: Folds don't match number of subjects\")\n",
    "        \n",
    "    nfolds = nsubjs/numsubjs_perfold\n",
    "    subj_array_folds = subjarray.copy()\n",
    "    \n",
    "    inputs = [] \n",
    "    \n",
    "    for fold in range(nfolds):\n",
    "        test_subjs = np.random.choice(subj_array_folds,numsubjs_perfold,replace=False)\n",
    "        train_subjs_all = np.delete(subjects,test_subjs)\n",
    "        for cv in range(ncvs):\n",
    "            # Randomly sample half of train set subjects for each cv (CV bootstrapping)\n",
    "            train_subjs = np.random.choice(train_subjs_all,\n",
    "                                         int(np.floor(len(train_subjs_all)*(4.0))),\n",
    "                                         replace=True)\n",
    "\n",
    "            train_ind = []\n",
    "            for subj in train_subjs:\n",
    "                train_ind.extend(np.where(subjarray==subj)[0])\n",
    "\n",
    "            test_ind = []\n",
    "            for subj in test_subjs:\n",
    "                test_ind.extend(np.where(subjarray==subj)[0])\n",
    "            \n",
    "            train_ind = np.asarray(train_ind)\n",
    "            test_ind = np.asarray(test_ind)\n",
    "\n",
    "            trainset = svm_mat[train_ind,:]\n",
    "            testset = svm_mat[test_ind,:]\n",
    "\n",
    "            # Normalize trainset and testset\n",
    "            mean = np.mean(svm_mat[train_ind,:],axis=0)\n",
    "            mean.shape = (1,len(mean))\n",
    "            std = np.std(svm_mat[train_ind,:],axis=0)\n",
    "            std.shape = (1,len(std))\n",
    "\n",
    "            trainset = np.divide((trainset - mean),std)\n",
    "            testset = np.divide((testset - mean),std)\n",
    "            \n",
    "            ## Feature selection and downsampling\n",
    "            trainlabels = labels[train_ind]\n",
    "            testlabels = labels[test_ind]\n",
    "            unique_labels = np.unique(labels)\n",
    "            feat1_labs = np.where(trainlabels==unique_labels[0])[0]\n",
    "            feat2_labs = np.where(trainlabels==unique_labels[1])[0]\n",
    "            # Perform t-test\n",
    "            t, p = stats.ttest_rel(trainset[feat1_labs,:],trainset[feat2_labs,:],axis=0)\n",
    "            h0, qs = mc.fdrcorrection0(p)\n",
    "#             h0 = p<0.1\n",
    "            # Construct feature masks\n",
    "            feat1_mask = np.multiply(t>0,h0).astype(bool)\n",
    "            feat2_mask = np.multiply(t<0,h0).astype(bool)\n",
    "#             feat1_mask = t>0\n",
    "#             feat2_mask = t<0\n",
    "            # Downsample training set into original vertices into 2 ROI signals\n",
    "            trainset_downsampled = np.zeros((trainset.shape[0],2))\n",
    "            trainset_downsampled[:,0] = np.nanmean(trainset[:,feat1_mask],axis=1)\n",
    "            trainset_downsampled[:,1] = np.nanmean(trainset[:,feat2_mask],axis=1)\n",
    "            trainset_downsampled = trainset[:,h0]\n",
    "            # Downsample test set into original vertices\n",
    "            testset_downsampled = np.zeros((testset.shape[0],2))\n",
    "            testset_downsampled[:,0] = np.nanmean(testset[:,feat1_mask],axis=1)\n",
    "            testset_downsampled[:,1] = np.nanmean(testset[:,feat2_mask],axis=1)\n",
    "            testset_downsampled = testset[:,h0]\n",
    "            \n",
    "            if np.sum(feat1_mask)==0 or np.sum(feat2_mask==0):\n",
    "                inputs.append((trainset,testset,trainlabels,testlabels))\n",
    "            else:\n",
    "                inputs.append((trainset_downsampled,testset_downsampled,trainlabels,testlabels))\n",
    "                \n",
    "#             inputs.append((trainset,testset,trainlabels,testlabels))\n",
    "            \n",
    "        \n",
    "        subj_array_folds = np.delete(subj_array_folds,test_subjs)\n",
    "        \n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    scores = pool.map_async(_decoding,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "#     subj_acc = np.zeros((len(subjects),))\n",
    "#     scount = 0\n",
    "#     i = 0\n",
    "#     for subj in subjects:\n",
    "#         subjmean = []\n",
    "#         for cv in range(ncvs):\n",
    "#             subjmean.append(scores[i])\n",
    "#             i += 1\n",
    "        \n",
    "#         subj_acc[scount] = np.mean(subjmean)\n",
    "        \n",
    "#         scount += 1\n",
    "\n",
    "#     return subj_acc\n",
    "    acc = []\n",
    "    for score in scores:\n",
    "        acc.extend(score)\n",
    "    return acc\n",
    "\n",
    "def _decoding((trainset,testset,trainlabels,testlabels)):\n",
    "\n",
    "# #     clf = sklearn.linear_model.LogisticRegression()\n",
    "#     clf = svm.SVC(C=1.0, kernel='linear')\n",
    "\n",
    "#     clf.fit(trainset,trainlabels)\n",
    "#     predictions = clf.predict(testset)\n",
    "#     acc = predictions==testlabels\n",
    "#     score = np.mean(acc)\n",
    "\n",
    "    unique_cond = np.unique(trainlabels)\n",
    "    rdm = np.zeros((len(unique_cond),len(unique_cond)))\n",
    "    acc = []\n",
    "    for cond1 in unique_cond:\n",
    "        mismatches = []\n",
    "        prototype_ind = np.where(trainlabels==cond1)[0]\n",
    "        prototype = np.mean(trainset[prototype_ind,:],axis=0)\n",
    "        for cond2 in unique_cond:\n",
    "            test_ind = np.where(testlabels==cond2)[0]\n",
    "            test = np.mean(testset[test_ind,:],axis=0)\n",
    "            if cond1 == cond2: \n",
    "                correct = stats.spearmanr(prototype,test)[0]\n",
    "            else:\n",
    "                mismatches.append(stats.spearmanr(prototype,test)[0])\n",
    "        \n",
    "        if correct > np.max(mismatches): \n",
    "            acc.append(1.0)\n",
    "        else:\n",
    "            acc.append(0.0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Run across subject decoding on Color Stimuli decoding\n",
    "### 4-way coding for every 4 input stimuli combinations\n",
    "* red, red\n",
    "* red, blue\n",
    "* blue, red\n",
    "* blue, blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data for \"Color\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'colorStim'\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode different stimulus pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SVM classification for input stimuli: colorStim for ROI 0 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 1 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 2 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 3 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 4 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 5 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 6 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 7 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 8 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 9 / 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:703: RuntimeWarning: Mean of empty slice\n",
      "  warnings.warn(\"Mean of empty slice\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SVM classification for input stimuli: colorStim for ROI 10 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 11 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 12 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 13 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 14 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 15 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 16 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 17 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 18 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 19 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 20 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 21 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 22 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 23 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 24 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 25 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 26 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 27 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 28 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 29 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 30 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 31 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 32 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 33 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 34 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 35 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 36 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 37 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 38 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 39 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 40 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 41 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 42 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 43 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 44 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 45 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 46 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 47 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 48 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 49 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 50 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 51 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 52 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 53 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 54 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 55 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 56 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 57 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 58 / 60\n",
      "Computing SVM classification for input stimuli: colorStim for ROI 59 / 60\n"
     ]
    }
   ],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline = inputStimuliDecoding(data_task, inputtype, atlasROIs=activeROIs, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inputtype in ['colorStim','oriStim']:\n",
    "    # Visual networks\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "\n",
    "\n",
    "nStims = 4\n",
    "statistics = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = len(subjNums)*nStims\n",
    "    p = stats.binom_test(np.mean(distances_baseline[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics[roicount,0] = np.mean(distances_baseline[roicount,:])\n",
    "    statistics[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics[roicount,1] = qs[roicount]\n",
    "    statistics[roicount,2] = h0[roicount]*statistics[roicount,0]\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for colorStim Stimuli: 4\n",
      "Accuracies: [ 0.33333333  0.32291667  0.3125      0.31770833]\n"
     ]
    }
   ],
   "source": [
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics[:,1]<0.05)[0]\n",
    "print 'Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0]\n",
    "print 'Accuracies:', statistics[sig_ind,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Map accuracies back to cortical surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi)[0]\n",
    "    inputStim[vertex_ind,0] = statistics[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "    \n",
    "#### \n",
    "# Write file to csv and run wb_command\n",
    "outdir = '/projects3/SRActFlow/data/results/Decoding_' + inputtype + '/'\n",
    "filename = inputtype + 'Decoding'\n",
    "np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "wb_file = filename + '.dscalar.nii'\n",
    "wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "os.system(wb_command)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Run across subject decoding on Orientation Stimuli decoding\n",
    "### 4-way coding for every 4 input stimuli combinations\n",
    "* vertical, vertical\n",
    "* vertical, horizontal\n",
    "* horizontal, vertical\n",
    "* horizontal, horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load data for \"Ori\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsr = True\n",
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'oriStim'\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SVM classification for input stimuli: oriStim for ROI 0 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 1 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 2 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 3 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 4 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 5 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 6 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 7 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 8 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 9 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 10 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 11 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 12 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 13 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 14 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 15 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 16 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 17 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 18 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 19 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 20 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 21 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 22 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 23 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 24 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 25 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 26 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 27 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 28 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 29 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 30 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 31 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 32 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 33 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 34 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 35 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 36 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 37 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 38 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 39 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 40 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 41 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 42 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 43 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 44 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 45 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 46 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 47 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 48 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 49 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 50 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 51 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 52 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 53 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 54 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 55 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 56 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 57 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 58 / 60\n",
      "Computing SVM classification for input stimuli: oriStim for ROI 59 / 60\n"
     ]
    }
   ],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline = inputStimuliDecoding(data_task, inputtype, atlasROIs=activeROIs, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inputtype in ['colorStim','oriStim']:\n",
    "    # Visual networks\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "\n",
    "\n",
    "nStims = 4\n",
    "statistics = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = len(subjNums)*nStims\n",
    "    p = stats.binom_test(np.mean(distances_baseline[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics[roicount,0] = np.mean(distances_baseline[roicount,:])\n",
    "    statistics[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics[roicount,1] = qs[roicount]\n",
    "    statistics[roicount,2] = h0[roicount]*statistics[roicount,0]\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for oriStim Stimuli: 22\n",
      "Accuracies: [ 0.453125    0.47395833  0.36979167  0.41927083  0.30208333  0.31510417\n",
      "  0.3125      0.30989583  0.359375    0.32291667  0.45572917  0.30208333\n",
      "  0.45572917  0.51822917  0.36458333  0.3203125   0.30208333  0.36197917\n",
      "  0.35416667  0.328125    0.29947917  0.31510417]\n"
     ]
    }
   ],
   "source": [
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics[:,1]<0.05)[0]\n",
    "print 'Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0]\n",
    "print 'Accuracies:', statistics[sig_ind,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Map accuracies back to cortical surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi)[0]\n",
    "    inputStim[vertex_ind,0] = statistics[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "    \n",
    "#### \n",
    "# Write file to csv and run wb_command\n",
    "outdir = '/projects3/SRActFlow/data/results/Decoding_' + inputtype + '/'\n",
    "filename = inputtype + 'Decoding'\n",
    "np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "wb_file = filename + '.dscalar.nii'\n",
    "wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "os.system(wb_command)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load data for \"Constant\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsr = True\n",
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'constantStim'\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SVM classification for input stimuli: constantStim for ROI 0 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 1 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 2 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 3 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 4 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 5 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 6 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 7 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 8 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 9 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 10 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 11 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 12 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 13 / 15\n",
      "Computing SVM classification for input stimuli: constantStim for ROI 14 / 15\n"
     ]
    }
   ],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline = inputStimuliDecoding(data_task, inputtype, atlasROIs=activeROIs, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inputtype in ['colorStim','oriStim']:\n",
    "    # Visual networks\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "\n",
    "\n",
    "nStims = 4\n",
    "statistics = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = len(subjNums)*nStims\n",
    "    p = stats.binom_test(np.mean(distances_baseline[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics[roicount,0] = np.mean(distances_baseline[roicount,:])\n",
    "    statistics[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics[roicount,1] = qs[roicount]\n",
    "    statistics[roicount,2] = h0[roicount]*statistics[roicount,0]\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for constantStim Stimuli: 14\n",
      "Accuracies: [ 0.38020833  0.38541667  0.34114583  0.29427083  0.390625    0.36458333\n",
      "  0.3984375   0.35677083  0.3046875   0.32291667  0.36979167  0.34635417\n",
      "  0.31510417  0.32552083]\n"
     ]
    }
   ],
   "source": [
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics[:,1]<0.05)[0]\n",
    "print 'Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0]\n",
    "print 'Accuracies:', statistics[sig_ind,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Map accuracies back to cortical surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi)[0]\n",
    "    inputStim[vertex_ind,0] = statistics[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "    \n",
    "#### \n",
    "# Write file to csv and run wb_command\n",
    "outdir = '/projects3/SRActFlow/data/results/Decoding_' + inputtype + '/'\n",
    "filename = inputtype + 'Decoding'\n",
    "np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "wb_file = filename + '.dscalar.nii'\n",
    "wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "os.system(wb_command)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load data for \"Pitch\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsr = True\n",
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'pitchStim'\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "#     print subj\n",
    "    data_task[:,:,scount] = loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SVM classification for input stimuli: pitchStim for ROI 0 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 1 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 2 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 3 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 4 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 5 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 6 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 7 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 8 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 9 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 10 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 11 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 12 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 13 / 15\n",
      "Computing SVM classification for input stimuli: pitchStim for ROI 14 / 15\n"
     ]
    }
   ],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline = inputStimuliDecoding(data_task, inputtype, atlasROIs=activeROIs, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inputtype in ['colorStim','oriStim']:\n",
    "    # Visual networks\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "    rois = rois + 1\n",
    "    rois = np.intersect1d(rois,activeROIs)\n",
    "\n",
    "\n",
    "nStims = 4\n",
    "statistics = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = len(subjNums)*nStims\n",
    "    p = stats.binom_test(np.mean(distances_baseline[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics[roicount,0] = np.mean(distances_baseline[roicount,:])\n",
    "    statistics[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics[roicount,1] = qs[roicount]\n",
    "    statistics[roicount,2] = h0[roicount]*statistics[roicount,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for pitchStim Stimuli: 15\n",
      "Accuracies: [ 0.484375    0.31770833  0.31510417  0.31510417  0.49479167  0.48697917\n",
      "  0.47916667  0.4453125   0.44270833  0.33854167  0.34635417  0.453125\n",
      "  0.42708333  0.48697917  0.4453125 ]\n"
     ]
    }
   ],
   "source": [
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics[:,1]<0.05)[0]\n",
    "print 'Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0]\n",
    "print 'Accuracies:', statistics[sig_ind,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Map accuracies back to cortical surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi)[0]\n",
    "    inputStim[vertex_ind,0] = statistics[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "    \n",
    "#### \n",
    "# Write file to csv and run wb_command\n",
    "outdir = '/projects3/SRActFlow/data/results/Decoding_' + inputtype + '/'\n",
    "filename = inputtype + 'Decoding'\n",
    "np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "wb_file = filename + '.dscalar.nii'\n",
    "wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "os.system(wb_command)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
