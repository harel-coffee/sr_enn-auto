{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normative 2b -- Compute the baseline decodability of Motor responses (LINDEX v. LMID and RINDEX v. RMID)\n",
    "## Using normative transformations, region-to-region\n",
    "## Use 100 PCs to make transforms more tractable\n",
    "\n",
    "## Use SVM classifications to decode hand-specific responses\n",
    "## Using Ciric-style postprocessing\n",
    "\n",
    "## Takuya Ito\n",
    "#### 12/12/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nib\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.api as sm\n",
    "import sklearn.svm as svm\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import sklearn\n",
    "from sklearn.feature_selection import f_classif\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "os.sys.path.append('glmScripts/')\n",
    "import taskGLMPipeline as tgp\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Define functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMotorResponses(subj,hand='Right'):\n",
    "    \n",
    "    hands = {'Left':[0,1],'Right':[2,3]}\n",
    "\n",
    "    x = tgp.loadTaskTiming(subj,'ALL')\n",
    "    stimIndex = np.asarray(x['stimIndex'])\n",
    "    ind = np.where(stimIndex=='motorResponse')[0]\n",
    "    \n",
    "    datadir = basedir + 'data/postProcessing/hcpPostProcCiric/'\n",
    "    h5f = h5py.File(datadir + subj + '_glmOutput_data.h5','r')\n",
    "    data = h5f['taskRegression/ALL_24pXaCompCorXVolterra_taskReg_betas_canonical'][:].copy()\n",
    "    data = data[:,ind].copy()\n",
    "    h5f.close()\n",
    "    \n",
    "    # Isolate hand responses\n",
    "    hand_ind = hands[hand]\n",
    "    data = data[:,hand_ind]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def loadRSFCMapping(subj,roi):\n",
    "    fcdir = '/projects3/SRActFlow/data/results/ridgeFC/'\n",
    "    filename = fcdir + 'TargetParcel' + str(roi) + '_RidgeFC.h5'\n",
    "    h5f = h5py.File(filename,'r')\n",
    "    fcmapping = h5f[subj]['sourceToTargetMapping'][:].copy()\n",
    "    h5f.close()\n",
    "    return fcmapping\n",
    "\n",
    "def ridgeWrapper((stim,resp,alpha)):\n",
    "#     wt = ridge.ridge.ridge(stim,resp,alpha)\n",
    "    clf = Ridge(alpha=alpha)\n",
    "    clf.fit(stim,resp)\n",
    "    wt = clf.coef_\n",
    "\n",
    "    return wt\n",
    "\n",
    "def pcaFC(stim,resp,n_components=500,nproc=10):\n",
    "#     print '\\tRunning PCA'\n",
    "    os.environ['OMP_NUM_THREADS'] = str(nproc)\n",
    "    if n_components<stim.shape[1]:\n",
    "        pca = PCA(n_components)\n",
    "        reduced_mat = pca.fit_transform(stim) # Time X Features\n",
    "    else:\n",
    "        reduced_mat = stim\n",
    "    \n",
    "    inputs = []\n",
    "    for vert in range(resp.shape[1]):\n",
    "        inputs.append((resp[:,vert],reduced_mat,True))\n",
    "\n",
    "#     print '\\tRunning regression'\n",
    "    os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    results = pool.map_async(_regression2,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    \n",
    "    wt = np.zeros((stim.shape[1],resp.shape[1]))\n",
    "    vert = 0\n",
    "    for result in results:\n",
    "        betas, resid = result\n",
    "        if n_components<stim.shape[1]:\n",
    "            betas = pca.inverse_transform(betas[1:])\n",
    "        else:\n",
    "            betas = betas[1:]\n",
    "        wt[:,vert] = betas\n",
    "        vert += 1\n",
    "\n",
    "    return wt\n",
    "\n",
    "## Load masks\n",
    "def loadMask(roi,dilated=True):\n",
    "    maskdir = basedir + 'data/results/surfaceMasks/'\n",
    "    if dilated:\n",
    "        maskfile = maskdir + 'GlasserParcel' + str(roi) + '_dilated_10mm.dscalar.nii'\n",
    "    else:\n",
    "        maskfile = maskdir + 'GlasserParcel' + str(roi) + '.dscalar.nii'\n",
    "    maskdata = np.squeeze(nib.load(maskfile).get_data())\n",
    "    return maskdata\n",
    "\n",
    "def loadRegularizationTerms(roi):\n",
    "    ridgefcdir = '/projects3/SRActFlow/data/results/ridgeFC/'\n",
    "    filename = ridgefcdir + 'TargetParcel' + str(roi) + '_RidgeFC.h5'\n",
    "    h5f = h5py.File(filename,'r')\n",
    "    alphas = h5f['alphasPerVertex'][:].copy()\n",
    "    return alphas\n",
    "\n",
    "\n",
    "def _regression2((data,regressors,constant)):\n",
    "    \"\"\" \n",
    "    Hand coded OLS regression using closed form equation: betas = (X'X)^(-1) X'y\n",
    "    \"\"\"\n",
    "    # Add 'constant' regressor\n",
    "    if constant:\n",
    "        regressors = sm.add_constant(regressors)\n",
    "    X = regressors.copy()\n",
    "    try:\n",
    "#        #C_ss_inv = np.linalg.inv(np.dot(X.T,X))\n",
    "        C_ss_inv = np.linalg.pinv(np.dot(X.T,X))\n",
    "    except np.linalg.LinAlgError as err:\n",
    "        C_ss_inv = np.linalg.pinv(np.cov(X.T))\n",
    "    betas = np.dot(C_ss_inv,np.dot(X.T,data.T))\n",
    "    resid = data - (betas[0] + np.dot(X[:,1:],betas[1:])).T\n",
    "    return betas, resid\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsr = True\n",
    "nResponses = 2\n",
    "data_task = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = loadMotorResponses(subj, hand='Right')\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Generate normative transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 013 ( 1 / 96 )\n",
      "...Elapsed time: 713.768088102\n",
      "Subject 014 ( 2 / 96 )\n",
      "...Elapsed time: 483.543848991\n",
      "Subject 016 ( 3 / 96 )\n",
      "...Elapsed time: 542.476314068\n",
      "Subject 017 ( 4 / 96 )\n",
      "...Elapsed time: 620.584634066\n",
      "Subject 018 ( 5 / 96 )\n",
      "...Elapsed time: 669.172348022\n",
      "Subject 021 ( 6 / 96 )\n",
      "...Elapsed time: 520.715664864\n",
      "Subject 023 ( 7 / 96 )\n",
      "...Elapsed time: 435.62855792\n",
      "Subject 024 ( 8 / 96 )\n",
      "...Elapsed time: 382.276139021\n",
      "Subject 026 ( 9 / 96 )\n",
      "...Elapsed time: 384.091159821\n",
      "Subject 027 ( 10 / 96 )\n",
      "...Elapsed time: 376.547902107\n",
      "Subject 028 ( 11 / 96 )\n",
      "...Elapsed time: 370.555563927\n",
      "Subject 030 ( 12 / 96 )\n",
      "...Elapsed time: 365.759562016\n",
      "Subject 031 ( 13 / 96 )\n",
      "...Elapsed time: 371.390974998\n",
      "Subject 032 ( 14 / 96 )\n",
      "...Elapsed time: 377.802261114\n",
      "Subject 033 ( 15 / 96 )\n",
      "...Elapsed time: 373.220960855\n",
      "Subject 034 ( 16 / 96 )\n",
      "...Elapsed time: 372.640937805\n",
      "Subject 035 ( 17 / 96 )\n",
      "...Elapsed time: 374.193254948\n",
      "Subject 037 ( 18 / 96 )\n",
      "...Elapsed time: 373.651030064\n",
      "Subject 038 ( 19 / 96 )\n",
      "...Elapsed time: 373.245228052\n",
      "Subject 039 ( 20 / 96 )\n",
      "...Elapsed time: 371.654757023\n",
      "Subject 040 ( 21 / 96 )\n",
      "...Elapsed time: 372.01592803\n",
      "Subject 041 ( 22 / 96 )\n",
      "...Elapsed time: 373.411507845\n",
      "Subject 042 ( 23 / 96 )\n",
      "...Elapsed time: 371.643815041\n",
      "Subject 043 ( 24 / 96 )\n",
      "...Elapsed time: 374.61293292\n",
      "Subject 045 ( 25 / 96 )\n",
      "...Elapsed time: 376.050813913\n",
      "Subject 046 ( 26 / 96 )\n",
      "...Elapsed time: 375.000830889\n",
      "Subject 047 ( 27 / 96 )\n",
      "...Elapsed time: 375.629803896\n",
      "Subject 048 ( 28 / 96 )\n",
      "...Elapsed time: 375.796908855\n",
      "Subject 049 ( 29 / 96 )\n",
      "...Elapsed time: 374.829887867\n",
      "Subject 050 ( 30 / 96 )\n",
      "...Elapsed time: 374.835139036\n",
      "Subject 053 ( 31 / 96 )\n",
      "...Elapsed time: 378.002887964\n",
      "Subject 055 ( 32 / 96 )\n",
      "...Elapsed time: 375.864389896\n",
      "Subject 056 ( 33 / 96 )\n",
      "...Elapsed time: 375.448204994\n",
      "Subject 057 ( 34 / 96 )\n",
      "...Elapsed time: 376.828922987\n",
      "Subject 058 ( 35 / 96 )\n",
      "...Elapsed time: 380.901375055\n",
      "Subject 062 ( 36 / 96 )\n",
      "...Elapsed time: 381.042231083\n",
      "Subject 063 ( 37 / 96 )\n",
      "...Elapsed time: 380.281057835\n",
      "Subject 066 ( 38 / 96 )\n",
      "...Elapsed time: 377.758410931\n",
      "Subject 067 ( 39 / 96 )\n",
      "...Elapsed time: 378.888663054\n",
      "Subject 068 ( 40 / 96 )\n",
      "...Elapsed time: 391.468904018\n",
      "Subject 069 ( 41 / 96 )\n",
      "...Elapsed time: 399.680767059\n",
      "Subject 070 ( 42 / 96 )\n",
      "...Elapsed time: 380.361932039\n",
      "Subject 072 ( 43 / 96 )\n",
      "...Elapsed time: 382.849753857\n",
      "Subject 074 ( 44 / 96 )\n",
      "...Elapsed time: 390.303756952\n",
      "Subject 075 ( 45 / 96 )\n",
      "...Elapsed time: 387.093389034\n",
      "Subject 076 ( 46 / 96 )\n",
      "...Elapsed time: 382.111174822\n",
      "Subject 077 ( 47 / 96 )\n",
      "...Elapsed time: 386.549880028\n",
      "Subject 081 ( 48 / 96 )\n",
      "...Elapsed time: 394.367878914\n",
      "Subject 085 ( 49 / 96 )\n",
      "...Elapsed time: 383.436373949\n",
      "Subject 086 ( 50 / 96 )\n",
      "...Elapsed time: 380.258360147\n",
      "Subject 087 ( 51 / 96 )\n",
      "...Elapsed time: 385.960359097\n",
      "Subject 088 ( 52 / 96 )\n",
      "...Elapsed time: 393.228643894\n",
      "Subject 090 ( 53 / 96 )\n",
      "...Elapsed time: 383.123831987\n",
      "Subject 092 ( 54 / 96 )\n",
      "...Elapsed time: 400.028079033\n",
      "Subject 093 ( 55 / 96 )\n",
      "...Elapsed time: 393.056410074\n",
      "Subject 094 ( 56 / 96 )\n",
      "...Elapsed time: 388.211297989\n",
      "Subject 095 ( 57 / 96 )\n",
      "...Elapsed time: 394.217268944\n",
      "Subject 097 ( 58 / 96 )\n",
      "...Elapsed time: 388.37838006\n",
      "Subject 098 ( 59 / 96 )\n",
      "...Elapsed time: 384.309127092\n",
      "Subject 099 ( 60 / 96 )\n",
      "...Elapsed time: 385.05023694\n",
      "Subject 101 ( 61 / 96 )\n",
      "...Elapsed time: 384.156382084\n",
      "Subject 102 ( 62 / 96 )\n",
      "...Elapsed time: 388.705573082\n",
      "Subject 103 ( 63 / 96 )\n",
      "...Elapsed time: 393.4147048\n",
      "Subject 104 ( 64 / 96 )\n",
      "...Elapsed time: 402.764966011\n",
      "Subject 105 ( 65 / 96 )\n",
      "...Elapsed time: 401.130928993\n",
      "Subject 106 ( 66 / 96 )\n",
      "...Elapsed time: 390.328088999\n",
      "Subject 108 ( 67 / 96 )\n",
      "...Elapsed time: 399.517707109\n",
      "Subject 109 ( 68 / 96 )\n",
      "...Elapsed time: 402.424815893\n",
      "Subject 110 ( 69 / 96 )\n",
      "...Elapsed time: 400.707444191\n",
      "Subject 111 ( 70 / 96 )\n",
      "...Elapsed time: 409.223412991\n",
      "Subject 112 ( 71 / 96 )\n",
      "...Elapsed time: 386.107347965\n",
      "Subject 114 ( 72 / 96 )\n",
      "...Elapsed time: 392.260545969\n",
      "Subject 115 ( 73 / 96 )\n",
      "...Elapsed time: 392.422394991\n",
      "Subject 117 ( 74 / 96 )\n",
      "...Elapsed time: 393.401783943\n",
      "Subject 119 ( 75 / 96 )\n",
      "...Elapsed time: 391.717226028\n",
      "Subject 120 ( 76 / 96 )\n",
      "...Elapsed time: 389.449829102\n",
      "Subject 121 ( 77 / 96 )\n",
      "...Elapsed time: 393.249204874\n",
      "Subject 122 ( 78 / 96 )\n",
      "...Elapsed time: 393.218542814\n",
      "Subject 123 ( 79 / 96 )\n",
      "...Elapsed time: 392.452054024\n",
      "Subject 124 ( 80 / 96 )\n",
      "...Elapsed time: 392.034329176\n",
      "Subject 125 ( 81 / 96 )\n",
      "...Elapsed time: 393.809453964\n",
      "Subject 126 ( 82 / 96 )\n",
      "...Elapsed time: 392.149646997\n",
      "Subject 127 ( 83 / 96 )\n",
      "...Elapsed time: 402.998240948\n",
      "Subject 128 ( 84 / 96 )\n",
      "...Elapsed time: 418.815666914\n",
      "Subject 129 ( 85 / 96 )\n",
      "...Elapsed time: 427.00799799\n",
      "Subject 130 ( 86 / 96 )\n",
      "...Elapsed time: 426.905904055\n",
      "Subject 131 ( 87 / 96 )\n",
      "...Elapsed time: 429.255284071\n",
      "Subject 132 ( 88 / 96 )\n",
      "...Elapsed time: 432.076908112\n",
      "Subject 134 ( 89 / 96 )\n",
      "...Elapsed time: 433.81328702\n",
      "Subject 135 ( 90 / 96 )\n",
      "...Elapsed time: 435.755432844\n",
      "Subject 136 ( 91 / 96 )\n",
      "...Elapsed time: 432.873265028\n",
      "Subject 137 ( 92 / 96 )\n",
      "...Elapsed time: 477.981718063\n",
      "Subject 138 ( 93 / 96 )\n",
      "...Elapsed time: 447.863600969\n",
      "Subject 139 ( 94 / 96 )\n",
      "...Elapsed time: 569.839212894\n",
      "Subject 140 ( 95 / 96 )\n",
      "...Elapsed time: 549.503174067\n",
      "Subject 141 ( 96 / 96 )\n",
      "...Elapsed time: 548.639862061\n"
     ]
    }
   ],
   "source": [
    "os.environ['OMP_NUM_THREADS'] = str(20)\n",
    "\n",
    "roi_rh = 9\n",
    "roi_lh = 189\n",
    "actflow_data = np.zeros((len(glasser2),nResponses,len(subjNums),nParcels))\n",
    "\n",
    "dilateLH = loadMask(roi_lh,dilated=True)\n",
    "dilateRH = loadMask(roi_rh,dilated=True)\n",
    "combinedDilated = dilateLH + dilateRH\n",
    "source_space = np.where(combinedDilated==0)[0]\n",
    "\n",
    "target_ind = np.where(glasser2==roi_rh)[0]\n",
    "normativedir = '/projects3/SRActFlow/data/results/normativeFC/'\n",
    "h5f = h5py.File(normativedir + 'TargetParcel' + str(roi_rh) + '_NormativePCA_FC.h5','a')\n",
    "\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    print 'Subject', subj, '(', scount+1, '/', len(subjNums), ')'\n",
    "    training_subjs = np.delete(np.arange(len(subjNums)),scount)\n",
    "    before = time.time()\n",
    "    \n",
    "    bad_rois = []\n",
    "    for roi in range(nParcels):\n",
    "#         print '\\tROI number', roi+1\n",
    "        source_ind = np.where(glasser2==roi+1)[0]\n",
    "        source_ind = np.intersect1d(source_ind,source_space) # Make sure no vertices are within 10mm of the target\n",
    "        if source_ind.shape[0]==0:\n",
    "            bad_rois.append(roi)\n",
    "            continue\n",
    "\n",
    "        targetTrain = data_task[:,:,training_subjs].T.reshape(len(training_subjs)*2,len(glasser2))[:,target_ind]\n",
    "        sourceTrain = data_task[:,:,training_subjs].T.reshape(len(training_subjs)*2,len(glasser2))[:,source_ind]\n",
    "#         normativeMapping = pcaFC(sourceTrain,targetTrain,n_components=50,nproc=20)\n",
    "#         try:\n",
    "#             h5f.create_dataset(subj + '/' + 'Source' + str(roi+1), data=normativeMapping)\n",
    "#         except:\n",
    "# #             del h5f[subj + '/' + 'Source' + str(roi+1)]\n",
    "#             h5f.create_dataset(subj + '/' + 'Source' + str(roi+1), data=normativeMapping)\n",
    "      \n",
    "        # Right Finger 1\n",
    "        actflow_data[target_ind,0,scount,roi] = np.dot(stats.zscore(data_task[source_ind,0,scount],axis=0),normativeMapping[:,:])\n",
    "        # Right Finger 2\n",
    "        actflow_data[target_ind,1,scount,roi] = np.dot(stats.zscore(data_task[source_ind,1,scount],axis=0),normativeMapping[:,:])\n",
    "        \n",
    "    after = time.time()\n",
    "    print '...Elapsed time:', after-before\n",
    "    \n",
    "    scount += 1\n",
    "    \n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Define functions for motor response decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def motorResponseDecodings(data, actflow_data, rois=[9], ncvs=1, nproc=5):\n",
    "    \"\"\"\n",
    "    Run an across-subject classification\n",
    "    Decode responses on each hand separately from CPRO data\n",
    "    \"\"\"\n",
    "\n",
    "    nSubjs = data.shape[2]\n",
    "    stats = np.zeros((len(rois),nSubjs*2))\n",
    "    \n",
    "    nfing = data.shape[1]\n",
    "\n",
    "    nsamples = nSubjs * nfing\n",
    "\n",
    "    # Label array for supervised learning\n",
    "    labels = np.tile(range(nfing),nSubjs)\n",
    "    subjarray = np.repeat(range(nSubjs),nfing)\n",
    "\n",
    "    # Run SVM classifications on network-level activation patterns across subjects\n",
    "    roicount = 0\n",
    "    for roi in rois:\n",
    "        roi_ind = np.where(glasser2==roi)[0]\n",
    "        nfeatures = len(roi_ind)\n",
    "        roi_ind.shape = (len(roi_ind),1)       \n",
    "\n",
    "        svm_mat = np.zeros((nsamples,roi_ind.shape[0]))\n",
    "        actflow_svm_mat = np.zeros((nsamples,roi_ind.shape[0]))\n",
    "        samplecount = 0\n",
    "        scount = 0\n",
    "        for subj in range(len(subjNums)):\n",
    "            roidata = np.squeeze(data[roi_ind,:,scount])\n",
    "            actflow_roidata = np.squeeze(actflow_data[roi_ind,:,scount])\n",
    "            svm_mat[samplecount:(samplecount+nfing),:] = roidata.T\n",
    "            actflow_svm_mat[samplecount:(samplecount+nfing),:] = actflow_roidata.T\n",
    "\n",
    "            scount += 1\n",
    "            samplecount += nfing\n",
    "\n",
    "#             # Spatially demean matrix across features\n",
    "#             samplemean = np.mean(svm_mat,axis=1)\n",
    "#             samplemean.shape = (len(samplemean),1)\n",
    "#             svm_mat = svm_mat - samplemean\n",
    "\n",
    "        scores = randomSplitLOOBaselineCV(ncvs, svm_mat, actflow_svm_mat, labels, subjarray, nproc=nproc)\n",
    "        stats[roicount,:] = scores\n",
    "        roicount += 1\n",
    "        \n",
    "    return stats\n",
    "\n",
    "def randomSplitLOOBaselineCV(ncvs, svm_mat, actflow_svm_mat, labels, subjarray, nproc=5):\n",
    "    \"\"\"\n",
    "    Runs cross validation for an across-subject SVM analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    ntasks = len(np.unique(labels))\n",
    "    nsamples = svm_mat.shape[0]\n",
    "    nsubjs = nsamples/ntasks\n",
    "\n",
    "    subjects = np.unique(subjarray)\n",
    "    indices = np.arange(nsamples)\n",
    "    \n",
    "    numsubjs_perfold = 4\n",
    "    if nsubjs%numsubjs_perfold!=0: \n",
    "        raise Exception(\"Error: Folds don't match number of subjects\")\n",
    "        \n",
    "    nfolds = nsubjs/numsubjs_perfold\n",
    "    subj_array_folds = subjarray.copy()\n",
    "    \n",
    "    inputs = [] \n",
    "    \n",
    "    for fold in range(nfolds):\n",
    "        test_subjs = np.random.choice(subj_array_folds,numsubjs_perfold,replace=False)\n",
    "        train_subjs_all = np.delete(subjects,test_subjs)\n",
    "        for cv in range(ncvs):\n",
    "            # Randomly sample half of train set subjects for each cv (CV bootstrapping)\n",
    "            train_subjs = np.random.choice(train_subjs_all,\n",
    "                                         int(np.floor(len(train_subjs_all)*(2.0))),\n",
    "                                         replace=True)\n",
    "\n",
    "            train_ind = []\n",
    "            for subj in train_subjs:\n",
    "                train_ind.extend(np.where(subjarray==subj)[0])\n",
    "\n",
    "            test_ind = []\n",
    "            for subj in test_subjs:\n",
    "                test_ind.extend(np.where(subjarray==subj)[0])\n",
    "            \n",
    "            train_ind = np.asarray(train_ind)\n",
    "            test_ind = np.asarray(test_ind)\n",
    "\n",
    "            trainset = actflow_svm_mat[train_ind,:]\n",
    "            testset = svm_mat[test_ind,:]\n",
    "\n",
    "            # Normalize trainset and testset\n",
    "            trainmean = np.mean(actflow_svm_mat[train_ind,:],axis=0)\n",
    "            trainmean.shape = (1,len(trainmean))\n",
    "            trainstd = np.std(actflow_svm_mat[train_ind,:],axis=0)\n",
    "            trainstd.shape = (1,len(trainstd))\n",
    "            \n",
    "            # Normalize trainset and testset\n",
    "            testmean = np.mean(svm_mat[train_ind,:],axis=0)\n",
    "            testmean.shape = (1,len(testmean))\n",
    "            teststd = np.std(svm_mat[train_ind,:],axis=0)\n",
    "            teststd.shape = (1,len(teststd))\n",
    "\n",
    "            trainset = np.divide((trainset - trainmean),trainstd)\n",
    "            testset = np.divide((testset - testmean),teststd)\n",
    "\n",
    "            inputs.append((trainset,testset,labels[train_ind],labels[test_ind]))\n",
    "        \n",
    "        subj_array_folds = np.delete(subj_array_folds,test_subjs)\n",
    "        \n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    scores = pool.map_async(_decoding,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "#     subj_acc = np.zeros((len(subjects),))\n",
    "#     scount = 0\n",
    "#     i = 0\n",
    "#     for subj in subjects:\n",
    "#         subjmean = []\n",
    "#         for cv in range(ncvs):\n",
    "#             subjmean.append(scores[i])\n",
    "#             i += 1\n",
    "        \n",
    "#         subj_acc[scount] = np.mean(subjmean)\n",
    "        \n",
    "#         scount += 1\n",
    "\n",
    "#     return subj_acc\n",
    "\n",
    "    acc = []\n",
    "    for score in scores:\n",
    "        acc.extend(score)\n",
    "    return acc\n",
    "\n",
    "def _decoding((trainset,testset,trainlabels,testlabels)):\n",
    "\n",
    "#     clf = sklearn.linear_model.LogisticRegression()\n",
    "    clf = svm.SVC(C=1.0, kernel='linear')\n",
    "\n",
    "    clf.fit(trainset,trainlabels)\n",
    "    predictions = clf.predict(testset)\n",
    "    acc = predictions==testlabels\n",
    "    \n",
    "#     unique_cond = np.unique(trainlabels)\n",
    "#     rdm = np.zeros((len(unique_cond),len(unique_cond)))\n",
    "#     acc = []\n",
    "#     for cond1 in unique_cond:\n",
    "#         mismatches = []\n",
    "#         prototype_ind = np.where(trainlabels==cond1)[0]\n",
    "#         prototype = np.mean(trainset[prototype_ind,:],axis=0)\n",
    "#         for cond2 in unique_cond:\n",
    "#             test_ind = np.where(testlabels==cond2)[0]\n",
    "#             test = np.mean(testset[test_ind,:],axis=0)\n",
    "#             if cond1 == cond2: \n",
    "#                 correct = stats.pearsonr(prototype,test)[0]\n",
    "#             else:\n",
    "#                 mismatches.append(stats.pearsonr(prototype,test)[0])\n",
    "        \n",
    "#         if correct > np.max(mismatches): \n",
    "#             acc.append(1.0)\n",
    "#         else:\n",
    "#             acc.append(0.0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on right-hand motor responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding roi 0\n",
      "Decoding roi 1\n",
      "Decoding roi 2\n",
      "Decoding roi 3\n",
      "Decoding roi 4\n",
      "Decoding roi 5\n",
      "Decoding roi 6\n",
      "Decoding roi 7\n",
      "Decoding roi 8\n",
      "Decoding roi 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usr/local/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding roi 10\n",
      "Decoding roi 11\n",
      "Decoding roi 12\n",
      "Decoding roi 13\n",
      "Decoding roi 14\n",
      "Decoding roi 15\n",
      "Decoding roi 16\n",
      "Decoding roi 17\n",
      "Decoding roi 18\n",
      "Decoding roi 19\n",
      "Decoding roi 20\n",
      "Decoding roi 21\n",
      "Decoding roi 22\n",
      "Decoding roi 23\n",
      "Decoding roi 24\n",
      "Decoding roi 25\n",
      "Decoding roi 26\n",
      "Decoding roi 27\n",
      "Decoding roi 28\n",
      "Decoding roi 29\n",
      "Decoding roi 30\n",
      "Decoding roi 31\n",
      "Decoding roi 32\n",
      "Decoding roi 33\n",
      "Decoding roi 34\n",
      "Decoding roi 35\n",
      "Decoding roi 36\n",
      "Decoding roi 37\n",
      "Decoding roi 38\n",
      "Decoding roi 39\n",
      "Decoding roi 40\n",
      "Decoding roi 41\n",
      "Decoding roi 42\n",
      "Decoding roi 43\n",
      "Decoding roi 44\n",
      "Decoding roi 45\n",
      "Decoding roi 46\n",
      "Decoding roi 47\n",
      "Decoding roi 48\n",
      "Decoding roi 49\n",
      "Decoding roi 50\n",
      "Decoding roi 51\n",
      "Decoding roi 52\n",
      "Decoding roi 53\n",
      "Decoding roi 54\n",
      "Decoding roi 55\n",
      "Decoding roi 56\n",
      "Decoding roi 57\n",
      "Decoding roi 58\n",
      "Decoding roi 59\n",
      "Decoding roi 60\n",
      "Decoding roi 61\n",
      "Decoding roi 62\n",
      "Decoding roi 63\n",
      "Decoding roi 64\n",
      "Decoding roi 65\n",
      "Decoding roi 66\n",
      "Decoding roi 67\n",
      "Decoding roi 68\n",
      "Decoding roi 69\n",
      "Decoding roi 70\n",
      "Decoding roi 71\n",
      "Decoding roi 72\n",
      "Decoding roi 73\n",
      "Decoding roi 74\n",
      "Decoding roi 75\n",
      "Decoding roi 76\n",
      "Decoding roi 77\n",
      "Decoding roi 78\n",
      "Decoding roi 79\n",
      "Decoding roi 80\n",
      "Decoding roi 81\n",
      "Decoding roi 82\n",
      "Decoding roi 83\n",
      "Decoding roi 84\n",
      "Decoding roi 85\n",
      "Decoding roi 86\n",
      "Decoding roi 87\n",
      "Decoding roi 88\n",
      "Decoding roi 89\n",
      "Decoding roi 90\n",
      "Decoding roi 91\n",
      "Decoding roi 92\n",
      "Decoding roi 93\n",
      "Decoding roi 94\n",
      "Decoding roi 95\n",
      "Decoding roi 96\n",
      "Decoding roi 97\n",
      "Decoding roi 98\n",
      "Decoding roi 99\n",
      "Decoding roi 100\n",
      "Decoding roi 101\n",
      "Decoding roi 102\n",
      "Decoding roi 103\n",
      "Decoding roi 104\n",
      "Decoding roi 105\n",
      "Decoding roi 106\n",
      "Decoding roi 107\n",
      "Decoding roi 108\n",
      "Decoding roi 109\n",
      "Decoding roi 110\n",
      "Decoding roi 111\n",
      "Decoding roi 112\n",
      "Decoding roi 113\n",
      "Decoding roi 114\n",
      "Decoding roi 115\n",
      "Decoding roi 116\n",
      "Decoding roi 117\n",
      "Decoding roi 118\n",
      "Decoding roi 119\n",
      "Decoding roi 120\n",
      "Decoding roi 121\n",
      "Decoding roi 122\n",
      "Decoding roi 123\n",
      "Decoding roi 124\n",
      "Decoding roi 125\n",
      "Decoding roi 126\n",
      "Decoding roi 127\n",
      "Decoding roi 128\n",
      "Decoding roi 129\n",
      "Decoding roi 130\n",
      "Decoding roi 131\n",
      "Decoding roi 132\n",
      "Decoding roi 133\n",
      "Decoding roi 134\n",
      "Decoding roi 135\n",
      "Decoding roi 136\n",
      "Decoding roi 137\n",
      "Decoding roi 138\n",
      "Decoding roi 139\n",
      "Decoding roi 140\n",
      "Decoding roi 141\n",
      "Decoding roi 142\n",
      "Decoding roi 143\n",
      "Decoding roi 144\n",
      "Decoding roi 145\n",
      "Decoding roi 146\n",
      "Decoding roi 147\n",
      "Decoding roi 148\n",
      "Decoding roi 149\n",
      "Decoding roi 150\n",
      "Decoding roi 151\n",
      "Decoding roi 152\n",
      "Decoding roi 153\n",
      "Decoding roi 154\n",
      "Decoding roi 155\n",
      "Decoding roi 156\n",
      "Decoding roi 157\n",
      "Decoding roi 158\n",
      "Decoding roi 159\n",
      "Decoding roi 160\n",
      "Decoding roi 161\n",
      "Decoding roi 162\n",
      "Decoding roi 163\n",
      "Decoding roi 164\n",
      "Decoding roi 165\n",
      "Decoding roi 166\n",
      "Decoding roi 167\n",
      "Decoding roi 168\n",
      "Decoding roi 169\n",
      "Decoding roi 170\n",
      "Decoding roi 171\n",
      "Decoding roi 172\n",
      "Decoding roi 173\n",
      "Decoding roi 174\n",
      "Decoding roi 175\n",
      "Decoding roi 176\n",
      "Decoding roi 177\n",
      "Decoding roi 178\n",
      "Decoding roi 179\n",
      "Decoding roi 180\n",
      "Decoding roi 181\n",
      "Decoding roi 182\n",
      "Decoding roi 183\n",
      "Decoding roi 184\n",
      "Decoding roi 185\n",
      "Decoding roi 186\n",
      "Decoding roi 187\n",
      "Decoding roi 188\n",
      "Decoding roi 189\n",
      "Decoding roi 190\n",
      "Decoding roi 191\n",
      "Decoding roi 192\n",
      "Decoding roi 193\n",
      "Decoding roi 194\n",
      "Decoding roi 195\n",
      "Decoding roi 196\n",
      "Decoding roi 197\n",
      "Decoding roi 198\n",
      "Decoding roi 199\n",
      "Decoding roi 200\n",
      "Decoding roi 201\n",
      "Decoding roi 202\n",
      "Decoding roi 203\n",
      "Decoding roi 204\n",
      "Decoding roi 205\n",
      "Decoding roi 206\n",
      "Decoding roi 207\n",
      "Decoding roi 208\n",
      "Decoding roi 209\n",
      "Decoding roi 210\n",
      "Decoding roi 211\n",
      "Decoding roi 212\n",
      "Decoding roi 213\n",
      "Decoding roi 214\n",
      "Decoding roi 215\n",
      "Decoding roi 216\n",
      "Decoding roi 217\n",
      "Decoding roi 218\n",
      "Decoding roi 219\n",
      "Decoding roi 220\n",
      "Decoding roi 221\n",
      "Decoding roi 222\n",
      "Decoding roi 223\n",
      "Decoding roi 224\n",
      "Decoding roi 225\n",
      "Decoding roi 226\n",
      "Decoding roi 227\n",
      "Decoding roi 228\n",
      "Decoding roi 229\n",
      "Decoding roi 230\n",
      "Decoding roi 231\n",
      "Decoding roi 232\n",
      "Decoding roi 233\n",
      "Decoding roi 234\n",
      "Decoding roi 235\n",
      "Decoding roi 236\n",
      "Decoding roi 237\n",
      "Decoding roi 238\n",
      "Decoding roi 239\n",
      "Decoding roi 240\n",
      "Decoding roi 241\n",
      "Decoding roi 242\n",
      "Decoding roi 243\n",
      "Decoding roi 244\n",
      "Decoding roi 245\n",
      "Decoding roi 246\n",
      "Decoding roi 247\n",
      "Decoding roi 248\n",
      "Decoding roi 249\n",
      "Decoding roi 250\n",
      "Decoding roi 251\n",
      "Decoding roi 252\n",
      "Decoding roi 253\n",
      "Decoding roi 254\n",
      "Decoding roi 255\n",
      "Decoding roi 256\n",
      "Decoding roi 257\n",
      "Decoding roi 258\n",
      "Decoding roi 259\n",
      "Decoding roi 260\n",
      "Decoding roi 261\n",
      "Decoding roi 262\n",
      "Decoding roi 263\n",
      "Decoding roi 264\n",
      "Decoding roi 265\n",
      "Decoding roi 266\n",
      "Decoding roi 267\n",
      "Decoding roi 268\n",
      "Decoding roi 269\n",
      "Decoding roi 270\n",
      "Decoding roi 271\n",
      "Decoding roi 272\n",
      "Decoding roi 273\n",
      "Decoding roi 274\n",
      "Decoding roi 275\n",
      "Decoding roi 276\n",
      "Decoding roi 277\n",
      "Decoding roi 278\n",
      "Decoding roi 279\n",
      "Decoding roi 280\n",
      "Decoding roi 281\n",
      "Decoding roi 282\n",
      "Decoding roi 283\n",
      "Decoding roi 284\n",
      "Decoding roi 285\n",
      "Decoding roi 286\n",
      "Decoding roi 287\n",
      "Decoding roi 288\n",
      "Decoding roi 289\n",
      "Decoding roi 290\n",
      "Decoding roi 291\n",
      "Decoding roi 292\n",
      "Decoding roi 293\n",
      "Decoding roi 294\n",
      "Decoding roi 295\n",
      "Decoding roi 296\n",
      "Decoding roi 297\n",
      "Decoding roi 298\n",
      "Decoding roi 299\n",
      "Decoding roi 300\n",
      "Decoding roi 301\n",
      "Decoding roi 302\n",
      "Decoding roi 303\n",
      "Decoding roi 304\n",
      "Decoding roi 305\n",
      "Decoding roi 306\n",
      "Decoding roi 307\n",
      "Decoding roi 308\n",
      "Decoding roi 309\n",
      "Decoding roi 310\n",
      "Decoding roi 311\n",
      "Decoding roi 312\n",
      "Decoding roi 313\n",
      "Decoding roi 314\n",
      "Decoding roi 315\n",
      "Decoding roi 316\n",
      "Decoding roi 317\n",
      "Decoding roi 318\n",
      "Decoding roi 319\n",
      "Decoding roi 320\n",
      "Decoding roi 321\n",
      "Decoding roi 322\n",
      "Decoding roi 323\n",
      "Decoding roi 324\n",
      "Decoding roi 325\n",
      "Decoding roi 326\n",
      "Decoding roi 327\n",
      "Decoding roi 328\n",
      "Decoding roi 329\n",
      "Decoding roi 330\n",
      "Decoding roi 331\n",
      "Decoding roi 332\n",
      "Decoding roi 333\n",
      "Decoding roi 334\n",
      "Decoding roi 335\n",
      "Decoding roi 336\n",
      "Decoding roi 337\n",
      "Decoding roi 338\n",
      "Decoding roi 339\n",
      "Decoding roi 340\n",
      "Decoding roi 341\n",
      "Decoding roi 342\n",
      "Decoding roi 343\n",
      "Decoding roi 344\n",
      "Decoding roi 345\n",
      "Decoding roi 346\n",
      "Decoding roi 347\n",
      "Decoding roi 348\n",
      "Decoding roi 349\n",
      "Decoding roi 350\n",
      "Decoding roi 351\n",
      "Decoding roi 352\n",
      "Decoding roi 353\n",
      "Decoding roi 354\n",
      "Decoding roi 355\n",
      "Decoding roi 356\n",
      "Decoding roi 357\n",
      "Decoding roi 358\n",
      "Decoding roi 359\n"
     ]
    }
   ],
   "source": [
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.where(networkdef==networkmappings['smn'])[0] + 1\n",
    "rois = [9] # Left S1\n",
    "\n",
    "\n",
    "distances_baseline_rh = []\n",
    "for roi in range(nParcels):\n",
    "    print 'Decoding roi', roi\n",
    "    if roi in bad_rois: \n",
    "        distances_baseline_rh.append(np.zeros((1,len(subjNums)*2.0)))\n",
    "        continue\n",
    "\n",
    "    distances_baseline_rh.append(motorResponseDecodings(stats.zscore(data_task,axis=0), \n",
    "                                                     stats.zscore(actflow_data[:,:,:,roi],axis=0),\n",
    "                                                     rois=rois, ncvs=ncvs, nproc=nproc))\n",
    "    \n",
    "distances_baseline_rh = np.squeeze(np.asarray(distances_baseline_rh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant transfers: 15\n",
      "\tSignificant parcel: 54\n",
      "\tAccuracy: 0.572916666667\n",
      "\tNetwork: 3.0\n",
      "\tSignificant parcel: 79\n",
      "\tAccuracy: 0.5625\n",
      "\tNetwork: 6.0\n",
      "\tSignificant parcel: 103\n",
      "\tAccuracy: 0.578125\n",
      "\tNetwork: 8.0\n",
      "\tSignificant parcel: 142\n",
      "\tAccuracy: 0.572916666667\n",
      "\tNetwork: 1.0\n",
      "\tSignificant parcel: 173\n",
      "\tAccuracy: 0.5625\n",
      "\tNetwork: 8.0\n",
      "\tSignificant parcel: 182\n",
      "\tAccuracy: 0.567708333333\n",
      "\tNetwork: 2.0\n",
      "\tSignificant parcel: 192\n",
      "\tAccuracy: 0.5625\n",
      "\tNetwork: 6.0\n",
      "\tSignificant parcel: 214\n",
      "\tAccuracy: 0.5625\n",
      "\tNetwork: 9.0\n",
      "\tSignificant parcel: 217\n",
      "\tAccuracy: 0.567708333333\n",
      "\tNetwork: 4.0\n",
      "\tSignificant parcel: 237\n",
      "\tAccuracy: 0.583333333333\n",
      "\tNetwork: 4.0\n",
      "\tSignificant parcel: 252\n",
      "\tAccuracy: 0.5625\n",
      "\tNetwork: 9.0\n",
      "\tSignificant parcel: 270\n",
      "\tAccuracy: 0.567708333333\n",
      "\tNetwork: 9.0\n",
      "\tSignificant parcel: 276\n",
      "\tAccuracy: 0.567708333333\n",
      "\tNetwork: 5.0\n",
      "\tSignificant parcel: 335\n",
      "\tAccuracy: 0.567708333333\n",
      "\tNetwork: 9.0\n",
      "\tSignificant parcel: 356\n",
      "\tAccuracy: 0.567708333333\n",
      "\tNetwork: 9.0\n",
      "Network mappings: {'vis2': 2, 'lan': 6, 'vis1': 1, 'none2': 12, 'none1': 11, 'dan': 5, 'aud': 8, 'pmulti': 10, 'fpn': 7, 'dmn': 9, 'smn': 3, 'con': 4}\n"
     ]
    }
   ],
   "source": [
    "statistics_rh = np.zeros((distances_baseline_rh.shape[0],3))\n",
    "for roicount in range(distances_baseline_rh.shape[0]):\n",
    "    ntrials = len(subjNums)*2\n",
    "    p = stats.binom_test(np.mean(distances_baseline_rh[roicount,:])*ntrials,n=ntrials,p=0.5)\n",
    "    if np.mean(distances_baseline_rh[roicount,:])>0.5:\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "\n",
    "    statistics_rh[roicount,0] = np.mean(distances_baseline_rh[roicount,:])\n",
    "    statistics_rh[roicount,1] = p\n",
    "\n",
    "rois_testing = []\n",
    "rois_testing.extend(np.where(networkdef==networkmappings['fpn'])[0])\n",
    "rois_testing.extend(np.where(networkdef==networkmappings['con'])[0])\n",
    "rois_testing.extend(np.where(networkdef==networkmappings['dan'])[0])\n",
    "# rois_notSMN = np.where(networkdef!=networkmappings['smn'])[0]\n",
    "h0, qs = mc.fdrcorrection0(statistics_rh[rois_testing,1])\n",
    "statistics_rh[:,1] = 1.0\n",
    "i = 0\n",
    "for roi in rois_testing:\n",
    "    statistics_rh[roi,1] = qs[i]\n",
    "    statistics_rh[roi,2] = h0[i]*statistics_rh[roi,0]\n",
    "    i += 1\n",
    "        \n",
    "nSignificant = np.sum(statistics_rh[:,1] < 0.05)\n",
    "print 'Number of significant transfers:', nSignificant\n",
    "\n",
    "if nSignificant>0:\n",
    "    sig_ind = np.where(statistics_rh[:,1]<0.05)[0]\n",
    "    for ind in sig_ind:\n",
    "        print '\\tSignificant parcel:', ind+1\n",
    "        print '\\tAccuracy:', statistics_rh[ind,0]\n",
    "        print '\\tNetwork:', networkdef[ind]\n",
    "print 'Network mappings:', networkmappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on left-hand motor responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding roi 0\n",
      "Decoding roi 1\n",
      "Decoding roi 2\n",
      "Decoding roi 3\n"
     ]
    }
   ],
   "source": [
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.where(networkdef==networkmappings['smn'])[0] + 1\n",
    "rois = [189] # Right S1\n",
    "\n",
    "\n",
    "distances_baseline_lh = []\n",
    "for roi in range(nParcels):\n",
    "    print 'Decoding roi', roi\n",
    "    if roi in bad_rois: \n",
    "        distances_baseline_lh.append(np.zeros((1,len(subjNums)*2.0)))\n",
    "        continue\n",
    "\n",
    "    distances_baseline_lh.append(motorResponseDecodings(stats.zscore(data_task_rh,axis=0), \n",
    "                                                     stats.zscore(actflow_data_rh[:,:,:,roi],axis=0),\n",
    "                                                     rois=rois, ncvs=ncvs, nproc=nproc))\n",
    "    \n",
    "distances_baseline_lh = np.squeeze(np.asarray(distances_baseline_lh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant transfers: 0\n",
      "Network mappings: {'vis2': 2, 'lan': 6, 'vis1': 1, 'none2': 12, 'none1': 11, 'dan': 5, 'aud': 8, 'pmulti': 10, 'fpn': 7, 'dmn': 9, 'smn': 3, 'con': 4}\n"
     ]
    }
   ],
   "source": [
    "statistics_rh = np.zeros((distances_baseline.shape[0],3))\n",
    "for roicount in range(distances_baseline.shape[0]):\n",
    "    ntrials = len(subjNums)*2\n",
    "    p = stats.binom_test(np.mean(distances_baseline[roicount,:])*ntrials,n=ntrials,p=0.5)\n",
    "    if np.mean(distances_baseline[roicount,:])>0.5:\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "\n",
    "    statistics_rh[roicount,0] = np.mean(distances_baseline[roicount,:])\n",
    "    statistics_rh[roicount,1] = p\n",
    "\n",
    "rois_notSMN = np.where(networkdef!=networkmappings['smn'])[0]\n",
    "h0, qs = mc.fdrcorrection0(statistics_rh[rois_notSMN,1])\n",
    "statistics_rh[:,1] = 1.0\n",
    "i = 0\n",
    "for roi in rois_notSMN:\n",
    "    statistics_rh[roi,1] = qs[i]\n",
    "    statistics_rh[roi,2] = h0[i]*statistics_rh[roi,0]\n",
    "    i += 1\n",
    "        \n",
    "nSignificant = np.sum(statistics_rh[:,1] < 0.05)\n",
    "print 'Number of significant transfers:', nSignificant\n",
    "\n",
    "if nSignificant>0:\n",
    "    sig_ind = np.where(statistics_rh[:,1]<0.05)[0]\n",
    "    for ind in sig_ind:\n",
    "        print '\\tSignificant parcel:', ind+1\n",
    "        print '\\tAccuracy:', statistics_rh[ind,0]\n",
    "        print '\\tNetwork:', networkdef[ind]\n",
    "print 'Network mappings:', networkmappings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
