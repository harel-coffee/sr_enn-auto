{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taku Ito\n",
    "## 12/12/2018\n",
    "\n",
    "## Compute pairwise PCA FC (500 components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tito/miniconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "os.sys.path.append('utils/')\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load resting-state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRestActivity(subj,model='24pXaCompCorXVolterra',zscore=False):\n",
    "    \n",
    "    datadir = basedir + 'data/postProcessing/hcpPostProcCiric/'\n",
    "    h5f = h5py.File(datadir + subj + '_glmOutput_data.h5','r')\n",
    "    data = h5f['Rest1/nuisanceReg_resid_24pXaCompCorXVolterra'][:].copy()\n",
    "    h5f.close()\n",
    "    \n",
    "    if zscore:\n",
    "        data = stats.zscore(data,axis=1)\n",
    "    return data\n",
    "\n",
    "def loadMask(roi,dilated=True):\n",
    "    maskdir = basedir + 'data/results/surfaceMasks/'\n",
    "    if dilated:\n",
    "        maskfile = maskdir + 'GlasserParcel' + str(roi) + '_dilated_10mm.dscalar.nii'\n",
    "    else:\n",
    "        maskfile = maskdir + 'GlasserParcel' + str(roi) + '.dscalar.nii'\n",
    "    maskdata = np.squeeze(nib.load(maskfile).get_data())\n",
    "    return maskdata\n",
    "\n",
    "\n",
    "def pcaFC(stim,resp,n_components=500,nproc=10):\n",
    "#     print '\\tRunning PCA'\n",
    "    os.environ['OMP_NUM_THREADS'] = str(nproc)\n",
    "    pca = PCA(n_components)\n",
    "    reduced_mat = pca.fit_transform(stim) # Time X Features\n",
    "    \n",
    "    inputs = []\n",
    "    for vert in range(resp.shape[1]):\n",
    "        inputs.append((resp[:,vert],reduced_mat,True))\n",
    "\n",
    "#     print '\\tRunning regression'\n",
    "    os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    results = pool.map_async(_regression2,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    \n",
    "    wt = np.zeros((stim.shape[1],resp.shape[1]))\n",
    "    vert = 0\n",
    "    for result in results:\n",
    "        betas, resid = result\n",
    "        betas = pca.inverse_transform(betas[1:])\n",
    "        wt[:,vert] = betas\n",
    "        vert += 1\n",
    "\n",
    "    return wt\n",
    "\n",
    "def multRegFC(stim,resp,nproc=10):\n",
    "    \n",
    "    inputs = []\n",
    "    for vert in range(resp.shape[1]):\n",
    "        inputs.append((resp[:,vert],stim,True))\n",
    "\n",
    "#     print '\\tRunning regression'\n",
    "    os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    results = pool.map_async(_regression2,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    \n",
    "    wt = np.zeros((stim.shape[1],resp.shape[1]))\n",
    "    vert = 0\n",
    "    for result in results:\n",
    "        betas, resid = result\n",
    "        betas = betas[1:]\n",
    "        wt[:,vert] = betas\n",
    "        vert += 1\n",
    "\n",
    "    return wt\n",
    "\n",
    "\n",
    "def _regression2((data,regressors,constant)):\n",
    "    \"\"\" \n",
    "    Hand coded OLS regression using closed form equation: betas = (X'X)^(-1) X'y\n",
    "    \"\"\"\n",
    "    # Add 'constant' regressor\n",
    "    if constant:\n",
    "        regressors = sm.add_constant(regressors)\n",
    "    X = regressors.copy()\n",
    "    try:\n",
    "#        #C_ss_inv = np.linalg.inv(np.dot(X.T,X))\n",
    "        C_ss_inv = np.linalg.pinv(np.dot(X.T,X))\n",
    "    except np.linalg.LinAlgError as err:\n",
    "        C_ss_inv = np.linalg.pinv(np.cov(X.T))\n",
    "    betas = np.dot(C_ss_inv,np.dot(X.T,data.T))\n",
    "    resid = data - (betas[0] + np.dot(X[:,1:],betas[1:])).T\n",
    "    return betas, resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for each subject fit the regression model using the optimized penalty term (alpha), and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pairwise PC regression for target region 9\n",
      "Subject 10 / 96 time elapsed... 427.708504915 seconds\n",
      "Subject 20 / 96 time elapsed... 440.251296043 seconds\n",
      "Subject 30 / 96 time elapsed... 471.877815962 seconds\n",
      "Subject 40 / 96 time elapsed... 444.693813801 seconds\n",
      "Subject 50 / 96 time elapsed... 529.85731411 seconds\n",
      "Subject 60 / 96 time elapsed... 770.920521975 seconds\n",
      "Subject 70 / 96 time elapsed... 749.860127926 seconds\n",
      "Subject 80 / 96 time elapsed... 716.69156599 seconds\n",
      "Subject 90 / 96 time elapsed... 790.216306925 seconds\n",
      "Running pairwise PC regression for target region 189\n",
      "Subject 10 / 96 time elapsed... 723.680526972 seconds\n",
      "Subject 20 / 96 time elapsed... 589.446938038 seconds\n",
      "Subject 30 / 96 time elapsed... 476.93251586 seconds\n",
      "Subject 40 / 96 time elapsed... 752.841898918 seconds\n",
      "Subject 50 / 96 time elapsed... 471.984141827 seconds\n",
      "Subject 60 / 96 time elapsed... 406.215167999 seconds\n",
      "Subject 70 / 96 time elapsed... 405.478977919 seconds\n",
      "Subject 80 / 96 time elapsed... 407.812108994 seconds\n",
      "Subject 90 / 96 time elapsed... 402.887691021 seconds\n",
      "Running pairwise PC regression for target region 8\n",
      "Subject 10 / 96 time elapsed... 522.119513988 seconds\n",
      "Subject 20 / 96 time elapsed... 537.345340967 seconds\n",
      "Subject 30 / 96 time elapsed... 524.387707949 seconds\n",
      "Subject 40 / 96 time elapsed... 518.439991951 seconds\n",
      "Subject 50 / 96 time elapsed... 560.121901989 seconds\n",
      "Subject 60 / 96 time elapsed... 581.379407883 seconds\n",
      "Subject 70 / 96 time elapsed... 606.183969021 seconds\n",
      "Subject 80 / 96 time elapsed... 520.27451396 seconds\n",
      "Subject 90 / 96 time elapsed... 579.881257057 seconds\n",
      "Running pairwise PC regression for target region 188\n",
      "Subject 10 / 96 time elapsed... 584.527864933 seconds\n",
      "Subject 20 / 96 time elapsed... 604.078098059 seconds\n",
      "Subject 30 / 96 time elapsed... 531.137763977 seconds\n",
      "Subject 40 / 96 time elapsed... 548.182233095 seconds\n",
      "Subject 50 / 96 time elapsed... 541.632232904 seconds\n",
      "Subject 60 / 96 time elapsed... 513.857191801 seconds\n",
      "Subject 70 / 96 time elapsed... 547.972255945 seconds\n",
      "Subject 80 / 96 time elapsed... 549.915359974 seconds\n",
      "Subject 90 / 96 time elapsed... 539.043282032 seconds\n"
     ]
    }
   ],
   "source": [
    "# ROI to compute FC to\n",
    "target_rois = [9,189,8,188] \n",
    "# Number of parallel processes\n",
    "nproc = 10\n",
    "# Number of PCs to use\n",
    "nPCs = 500\n",
    "\n",
    "pcafcdir = '/projects3/SRActFlow/data/results/pcaFC/pairwiseFC/'\n",
    "\n",
    "for target_roi in target_rois:\n",
    "    \n",
    "    print 'Running pairwise PC regression for target region', target_roi\n",
    "    # Now load regular mask to identify responses/activities we want to predict (target data)\n",
    "    mask = loadMask(target_roi,dilated=False)\n",
    "    target_ind = np.where(mask)[0]\n",
    "\n",
    "    scount = 1\n",
    "    for subj in subjNums:\n",
    "        if scount%10==0:\n",
    "            print 'Subject', scount, '/', len(subjNums), 'time elapsed...', (timeend-timestart), 'seconds'\n",
    "        subjData = loadRestActivity(subj,zscore=False)\n",
    "\n",
    "        targetMask = loadMask(target_roi,dilated=True)\n",
    "        targetMask_ind = np.where(targetMask==1)[0]\n",
    "        \n",
    "        timestart = time.time()\n",
    "        for source_roi in range(1,nParcels+1):\n",
    "            if source_roi==target_roi: continue\n",
    "#             print 'Running source ROI', source_roi\n",
    "\n",
    "            source_ind = np.where(glasser2==source_roi)[0]\n",
    "            # Make sure it doesn't overlap with the dilated mask\n",
    "    #         source_ind = np.intersect1d(np.where(targetMask==0)[0],source_ind)\n",
    "            adjacent_vertices = np.intersect1d(targetMask_ind,source_ind)\n",
    "\n",
    "            tmp_data = subjData.copy()\n",
    "            # Make sure to 0 out any adjacent vertices\n",
    "            if len(adjacent_vertices)>0:\n",
    "                tmp_data[adjacent_vertices,:] = 0\n",
    "            # Gather source and target data for pc regression\n",
    "            sourceData = tmp_data[source_ind,:].copy()\n",
    "            targetData = tmp_data[target_ind,:].copy()\n",
    "\n",
    "#             print '\\tRunning source to target PCA regression using', nproc, 'processes'\n",
    "            if len(source_ind)<nPCs:\n",
    "                sourceToTargetMappings = multRegFC(sourceData.T,targetData.T,nproc=nproc)\n",
    "            else:\n",
    "                sourceToTargetMappings = pcaFC(sourceData.T,targetData.T,n_components=nPCs,nproc=nproc)\n",
    "\n",
    "            # All vertices to target indices (makes it easier for comparison)\n",
    "            sourceToTargetMappings2 = sourceToTargetMappings\n",
    "\n",
    "            # Save out to file\n",
    "#             print '\\tSaving out to disk'\n",
    "            h5f = h5py.File(pcafcdir + 'SourceParcel' + str(source_roi) + 'TargetParcel' + str(target_roi) + '_pcaPairwiseFC_nozscore.h5','a')\n",
    "            try:\n",
    "                h5f.create_dataset(subj + '/sourceToTargetMapping',data=sourceToTargetMappings2)\n",
    "            except:\n",
    "                del h5f[subj+'/sourceToTargetMapping']\n",
    "                h5f.create_dataset(subj + '/sourceToTargetMapping',data=sourceToTargetMappings2)\n",
    "            h5f.close()\n",
    "\n",
    "            del sourceToTargetMappings2, sourceToTargetMappings\n",
    "            \n",
    "        scount += 1\n",
    "        timeend = time.time()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
