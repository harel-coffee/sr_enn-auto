{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupfMRI14a - Automated SRActFlow using ANN-inspired representations\n",
    "# Testing compositional RITL - train model on held-out 60 tasks. Test model on held-out 4 task contexts.\n",
    "#### Using ActFlow\n",
    "\n",
    "#### Takuya Ito\n",
    "#### 06/03/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import tools_group_rsa as tools_group\n",
    "import nibabel as nib\n",
    "import EmpiricalSRActFlow_ANN_RSA_v2 as esr\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load real motor response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tools_group_rsa.py:95: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,0] = data[:,2]\n",
      "tools_group_rsa.py:96: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,1] = data[:,3]\n",
      "tools_group_rsa.py:98: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,0] = data[:,0] #lmid\n",
      "tools_group_rsa.py:99: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tmpdat[:,1] = data[:,1] #lind\n"
     ]
    }
   ],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nResponses = 2\n",
    "data_task_rh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "data_task_lh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task_rh[:,:,scount] = np.real(tools_group.loadMotorResponses(subj,hand='Right'))\n",
    "    data_task_lh[:,:,scount] = np.real(tools_group.loadMotorResponses(subj,hand='Left'))\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify target vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set indices for layer-by-layer vertices\n",
    "targetdir = '/projects3/SRActFlow/data/results/GroupfMRI/MotorResponseDecoding/'\n",
    "motor_resp_regions_LH = np.loadtxt(targetdir + 'MotorResponseRegions_LH.csv',delimiter=',')\n",
    "motor_resp_regions_RH = np.loadtxt(targetdir + 'MotorResponseRegions_RH.csv',delimiter=',')\n",
    "targetROIs = np.hstack((motor_resp_regions_LH,motor_resp_regions_RH))\n",
    "\n",
    "target_ind = []\n",
    "for roi in targetROIs:\n",
    "    roi_ind = np.where(glasser2==roi+1)[0]\n",
    "    target_ind.extend(roi_ind)\n",
    "target_ind = np.asarray(target_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions for motor response decodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in FC mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)\n",
    "inputtypes = ['color','ori','pitch','constant']\n",
    "inputkeys = ['RED','VERTICAL','HIGH','CONSTANT']\n",
    "fc_input2hidden = {}\n",
    "eig_input2hidden = {}\n",
    "i = 0\n",
    "for inputtype in inputtypes:\n",
    "    fc_input2hidden[inputkeys[i]], eig_input2hidden[inputkeys[i]] = tools_group.loadGroupActFlowFC(inputtype,pc_space=True)\n",
    "    i += 1\n",
    "    \n",
    "# Load rules to hidden FC mappings\n",
    "fc_logic2hidden, eig_logic2hidden = tools_group.loadGroupActFlowFC('Logic',pc_space=True)\n",
    "fc_sensory2hidden, eig_sensory2hidden = tools_group.loadGroupActFlowFC('Sensory',pc_space=True)\n",
    "fc_motor2hidden, eig_motor2hidden = tools_group.loadGroupActFlowFC('Motor',pc_space=True)\n",
    "\n",
    "# Load hidden to motor resp mappings\n",
    "fc_hidden2motorresp, eig_hidden2motorresp = tools_group.loadGroupActFlowFC('hidden2out',pc_space=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate trials to simulate empirical brain computational models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define wrapper function for SRActFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "esr = reload(esr)\n",
    "filename_training='/projects3/SRActFlow/data/results/GroupfMRI/RSA/GroupfMRI14a_Trainset_60PracticeTasks_50stims_v1.csv'\n",
    "filename_testing='/projects3/SRActFlow/data/results/GroupfMRI/RSA/GroupfMRI14a_Testset_4NovelTasks_50stims_v1.csv'\n",
    "# Create training set (60 stimului per task)\n",
    "esr.constructTasksForRITLGeneralization(n_stims=12,filename_training=filename_training,filename_testing=filename_testing)\n",
    "# Create testing set (900 stimuli per task)\n",
    "# esr.constructTasksForRITLGeneralization(n_stims=20,filename_training='tmp.txt',filename_testing=filename_testing)\n",
    "# This ensures practice and novel tasks have the same number of trials\n",
    "\n",
    "trial_practice_metadata = pd.read_csv(filename_training)\n",
    "trial_novel_metadata = pd.read_csv(filename_testing)\n",
    "full_metadata = trial_practice_metadata.append(trial_novel_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "96\n",
      "96\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print np.sum((trial_novel_metadata.motorResp.values=='LMID'))\n",
    "print np.sum((trial_novel_metadata.motorResp.values=='LIND'))\n",
    "print np.sum((trial_novel_metadata.motorResp.values=='RMID'))\n",
    "print np.sum((trial_novel_metadata.motorResp.values=='RIND'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "96\n",
      "96\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print np.sum((trial_novel_metadata.motorResp.values=='LMID'))\n",
    "print np.sum((trial_novel_metadata.motorResp.values=='LIND'))\n",
    "print np.sum((trial_novel_metadata.motorResp.values=='RMID'))\n",
    "print np.sum((trial_novel_metadata.motorResp.values=='RIND'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMID 144\n",
      "RMID 144\n",
      "RIND 144\n",
      "RIND 144\n",
      "LMID 144\n",
      "LMID 144\n",
      "LIND 144\n",
      "LIND 144\n"
     ]
    }
   ],
   "source": [
    "tmp = ['LMID','LIND','RMID','RIND']\n",
    "print 'RMID', np.sum((trial_practice_metadata.motorResp.values=='RMID') | (trial_practice_metadata.motorRule.values=='RMID'))\n",
    "print 'RMID', np.sum((trial_practice_metadata.motorResp.values=='RMID') | (trial_practice_metadata.motorRule.values=='RIND'))\n",
    "\n",
    "print 'RIND', np.sum((trial_practice_metadata.motorResp.values=='RIND') | (trial_practice_metadata.motorRule.values=='RMID'))\n",
    "print 'RIND', np.sum((trial_practice_metadata.motorResp.values=='RIND') | (trial_practice_metadata.motorRule.values=='RIND'))\n",
    "\n",
    "print 'LMID', np.sum((trial_practice_metadata.motorResp.values=='LMID') | (trial_practice_metadata.motorRule.values=='LMID'))\n",
    "print 'LMID', np.sum((trial_practice_metadata.motorResp.values=='LMID') | (trial_practice_metadata.motorRule.values=='LIND'))\n",
    "\n",
    "print 'LIND', np.sum((trial_practice_metadata.motorResp.values=='LIND') | (trial_practice_metadata.motorRule.values=='LMID'))\n",
    "print 'LIND', np.sum((trial_practice_metadata.motorResp.values=='LIND') | (trial_practice_metadata.motorRule.values=='LIND'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 013... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 017... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 023... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 027... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 031... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 034... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 038... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 041... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 024... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 014... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 032... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 018... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 035... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 028... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 039... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 042... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 021... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 026... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 016... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 037... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 033... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 030... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 043... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 040... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 045... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 048... Simulating 384 Practiced Trials | 384 Novel Trials\n",
      "Subject 053... Simulating 384 Practiced Trials | 384 Novel Trials\n"
     ]
    }
   ],
   "source": [
    "esr = reload(esr)\n",
    "def subjSRActFlow_PCFC((subj,trial_practiced_metadata,trial_novel_metadata)):\n",
    "    print('Subject ' + subj + '... Simulating ' + str(len(trial_practiced_metadata)) + ' Practiced Trials | ' + str(len(trial_novel_metadata)) + ' Novel Trials')\n",
    "    obj = esr.EmpiricalActFlow(subj)\n",
    "    # Input\n",
    "    obj.fc_input2hidden = fc_input2hidden\n",
    "    obj.eig_input2hidden = eig_input2hidden\n",
    "    # Rules\n",
    "    obj.fc_logic2hidden = fc_logic2hidden\n",
    "    obj.eig_logic2hidden = eig_logic2hidden\n",
    "    obj.fc_sensory2hidden = fc_sensory2hidden\n",
    "    obj.eig_sensory2hidden = eig_sensory2hidden\n",
    "    obj.fc_motor2hidden = fc_motor2hidden\n",
    "    obj.eig_motor2hidden = eig_motor2hidden\n",
    "    # hidden 2 motor\n",
    "    obj.fc_hidden2motorresp = fc_hidden2motorresp\n",
    "    obj.eig_hidden2motorresp = eig_hidden2motorresp\n",
    "    \n",
    "    # Generate actflow predictions for practiced tasks\n",
    "    obj.extractAllActivations(trial_practiced_metadata)\n",
    "    actflow_practiced = obj.generateActFlowPredictions_PCFC(thresh=0,verbose=False)\n",
    "    del obj\n",
    "    \n",
    "    #### Run for novel tasks\n",
    "    obj = esr.EmpiricalActFlow(subj)\n",
    "    # Input\n",
    "    obj.fc_input2hidden = fc_input2hidden\n",
    "    obj.eig_input2hidden = eig_input2hidden\n",
    "    # Rules\n",
    "    obj.fc_logic2hidden = fc_logic2hidden\n",
    "    obj.eig_logic2hidden = eig_logic2hidden\n",
    "    obj.fc_sensory2hidden = fc_sensory2hidden\n",
    "    obj.eig_sensory2hidden = eig_sensory2hidden\n",
    "    obj.fc_motor2hidden = fc_motor2hidden\n",
    "    obj.eig_motor2hidden = eig_motor2hidden\n",
    "    # hidden 2 motor\n",
    "    obj.fc_hidden2motorresp = fc_hidden2motorresp\n",
    "    obj.eig_hidden2motorresp = eig_hidden2motorresp\n",
    "    # Generate actflow predictions for novel tasks\n",
    "    obj.extractAllActivations(trial_novel_metadata)\n",
    "    actflow_novel = obj.generateActFlowPredictions_PCFC(thresh=0,verbose=False)\n",
    "    del obj\n",
    "    \n",
    "    return actflow_practiced, actflow_novel\n",
    "\n",
    "global fc_input2hidden\n",
    "global fc_logic2hidden\n",
    "global fc_sensory2hidden\n",
    "global fc_motor2hidden\n",
    "\n",
    "inputs = []\n",
    "for i in range(len(subjNums)):\n",
    "    inputs.append((subjNums[i],trial_practice_metadata,trial_novel_metadata))\n",
    "\n",
    "timestart = time.time()\n",
    "pool = mp.Pool(processes=16)\n",
    "results = pool.map_async(subjSRActFlow_PCFC,inputs).get()\n",
    "pool.close()\n",
    "pool.join()\n",
    "timeend = time.time()\n",
    "print \"time elapsed:\", timeend-timestart\n",
    "\n",
    "actflow_predictions_practiced = np.zeros((len(subjNums),len(target_ind),4))\n",
    "actflow_predictions_novel = np.zeros((len(subjNums),len(target_ind),4))\n",
    "scount = 0\n",
    "for result in results:\n",
    "    actflow_predictions_practiced[scount,:,:] = result[0]\n",
    "    actflow_predictions_novel[scount,:,:] = result[1]\n",
    "    scount += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute average activity for each response, for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "nResponses = 2\n",
    "actflow_rh_practice = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "actflow_lh_practice = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "actflow_rh_novel = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "actflow_lh_novel = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "for scount in range(len(subjNums)):\n",
    "    # RMID\n",
    "    actflow_rh_practice[target_ind,0,scount] = actflow_predictions_practiced[scount,:,2]\n",
    "    # RIND\n",
    "    actflow_rh_practice[target_ind,1,scount] = actflow_predictions_practiced[scount,:,3]\n",
    "    # LMID\n",
    "    actflow_lh_practice[target_ind,0,scount] = actflow_predictions_practiced[scount,:,0]\n",
    "    # LIND\n",
    "    actflow_lh_practice[target_ind,1,scount] = actflow_predictions_practiced[scount,:,1]\n",
    "    \n",
    "    # RMID\n",
    "    actflow_rh_novel[target_ind,0,scount] = actflow_predictions_novel[scount,:,2]\n",
    "    # RIND\n",
    "    actflow_rh_novel[target_ind,1,scount] = actflow_predictions_novel[scount,:,3]\n",
    "    # LMID\n",
    "    actflow_lh_novel[target_ind,0,scount] = actflow_predictions_novel[scount,:,0]\n",
    "    # LIND\n",
    "    actflow_lh_novel[target_ind,1,scount] = actflow_predictions_novel[scount,:,1]\n",
    "    \n",
    "thresh = 0\n",
    "if thresh!=None:\n",
    "    actflow_rh_practice = np.multiply(actflow_rh_practice,actflow_rh_practice>thresh)\n",
    "    actflow_lh_practice = np.multiply(actflow_lh_practice,actflow_lh_practice>thresh)\n",
    "    actflow_rh_novel = np.multiply(actflow_rh_novel,actflow_rh_novel>thresh)\n",
    "    actflow_lh_novel = np.multiply(actflow_lh_novel,actflow_lh_novel>thresh)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run across subject decoding on right-hand motor responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run recurrent actflow on motor cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrence = 0\n",
    "h5f = h5py.File('/projects3/SRActFlow/data/results/GroupfMRI/RecurrentMotorFC/group_weightsrh.h5','r')\n",
    "smnweights = h5f['weights'][:].copy()\n",
    "\n",
    "\n",
    "rois = np.asarray([7,8,52])\n",
    "roi_ind = []\n",
    "for roi in rois:\n",
    "    roi_ind.extend(np.where(glasser2==roi+1)[0])\n",
    "\n",
    "data_orig = data_task_rh[roi_ind,:,:,].copy()\n",
    "noveldata = actflow_rh_novel[roi_ind,:,:].copy()\n",
    "practicedata = actflow_rh_practice[roi_ind,:,:].copy()\n",
    "# data_orig = stats.zscore(data_orig,axis=0).copy()\n",
    "noveldata = stats.zscore(noveldata,axis=0).copy()\n",
    "practicedata = stats.zscore(practicedata,axis=0).copy()\n",
    "\n",
    "for i in range(recurrence):\n",
    "    for scount in range(len(subjNums)):\n",
    "        for cond in range(data_task_rh.shape[1]):\n",
    "            noveldata[:,cond,scount] = noveldata[:,cond,scount] + np.matmul(noveldata[:,cond,scount],smnweights[1:,:])\n",
    "            practicedata[:,cond,scount] = practicedata[:,cond,scount] + np.matmul(practicedata[:,cond,scount],smnweights[1:,:])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nproc = 20\n",
    "nResponses = 2\n",
    "ncvs = 1\n",
    "\n",
    "\n",
    "\n",
    "distances_baseline_rh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_rh[0,:],rmatch,rmismatch = tools_group.compositionalActflowDecodings(data_orig,noveldata,\n",
    "                                                        \n",
    "                                                                                        practicedata,effects=True,\n",
    "                                                          ncvs=ncvs, featsel=True, nproc=nproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.208333333333\n",
      "p = 1.0\n",
      "Matched spatial correlation: -0.0164061615059\n",
      "Mismatched spatial correlation: 0.0164061615059\n"
     ]
    }
   ],
   "source": [
    "statistics_rh = np.zeros((distances_baseline_rh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_rh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_rh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_rh[0,0] = np.mean(distances_baseline_rh[0,:])\n",
    "statistics_rh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_rh[0,0]\n",
    "print 'p =', statistics_rh[0,1]\n",
    "print 'Matched spatial correlation:', np.mean(rmatch)\n",
    "print 'Mismatched spatial correlation:', np.mean(rmismatch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run across subject decoding on left-hand motor responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run recurrent actflow on motor cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrence = 0\n",
    "h5f = h5py.File('/projects3/SRActFlow/data/results/GroupfMRI/RecurrentMotorFC/group_weightslh.h5','r')\n",
    "smnweights = h5f['weights'][:].copy()\n",
    "\n",
    "\n",
    "rois = np.asarray([187,188,232])\n",
    "roi_ind = []\n",
    "for roi in rois:\n",
    "    roi_ind.extend(np.where(glasser2==roi+1)[0])\n",
    "    \n",
    "data_orig = data_task_lh[roi_ind,:,:,].copy()\n",
    "noveldata = actflow_lh_novel[roi_ind,:,:].copy()\n",
    "practicedata = actflow_lh_practice[roi_ind,:,:].copy()\n",
    "# data_orig = stats.zscore(data_orig,axis=0).copy()\n",
    "noveldata = stats.zscore(noveldata,axis=0).copy()\n",
    "practicedata = stats.zscore(practicedata,axis=0).copy()\n",
    "\n",
    "for i in range(recurrence):\n",
    "    for scount in range(len(subjNums)):\n",
    "        for cond in range(data_task_lh.shape[1]):\n",
    "            noveldata[:,cond,scount] = noveldata[:,cond,scount] + np.matmul(noveldata[:,cond,scount],smnweights[1:,:])\n",
    "            practicedata[:,cond,scount] = practicedata[:,cond,scount] + np.matmul(practicedata[:,cond,scount],smnweights[1:,:])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_group = reload(tools_group)\n",
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "\n",
    "distances_baseline_lh = np.zeros((1,len(subjNums)*nResponses))\n",
    "distances_baseline_lh[0,:],rmatch,rmismatch = tools_group.compositionalActflowDecodings(data_orig,noveldata,\n",
    "                                                          practicedata,effects=True, featsel=True,\n",
    "                                                          ncvs=ncvs, nproc=nproc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity flow accuracy = 0.395833333333\n",
      "p = 0.997622381257\n",
      "Matched spatial correlation: -0.00641757214721\n",
      "Mismatched spatial correlation: 0.00641757214721\n"
     ]
    }
   ],
   "source": [
    "statistics_lh = np.zeros((distances_baseline_lh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(np.mean(distances_baseline_lh[0,:])*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_lh[0,:])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "    \n",
    "statistics_lh[0,0] = np.mean(distances_baseline_lh[0,:])\n",
    "statistics_lh[0,1] = p\n",
    "\n",
    "print 'Activity flow accuracy =', statistics_lh[0,0]\n",
    "print 'p =', statistics_lh[0,1]\n",
    "print 'Matched spatial correlation:', np.mean(rmatch)\n",
    "print 'Mismatched spatial correlation:', np.mean(rmismatch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
