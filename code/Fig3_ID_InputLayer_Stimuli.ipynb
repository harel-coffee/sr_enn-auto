{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-subject decoding input stimuli \n",
    "### Ex: Color stims ([red, red] v. [red, blue] v. [blue, red] v. [blue, blue])\n",
    "\n",
    "#### Takuya Ito\n",
    "#### 8/18/20\n",
    "\n",
    "#### Note (8/18/20): Results will not be 'stochastic' if run with a leave-one-out subject CV (and no resampling in trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import tools as tools\n",
    "from importlib import reload\n",
    "import nibabel as nib\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "projectdir = '/home/ti61/f_mc1689_1/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt(projectdir + 'data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = projectdir + 'data/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(list(xticks.keys()))\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Define functions for input stimuli decodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Run across subject decoding on Color Stimuli decoding\n",
    "### 4-way coding for every 4 input stimuli combinations\n",
    "* red, red\n",
    "* red, blue\n",
    "* blue, red\n",
    "* blue, blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data for \"Color\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/f_mc1689_1/AnalysisTools/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'colorStim'\n",
    "\n",
    "if inputtype in ['colorStim','oriStim']:\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = tools.loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode different stimulus pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline_color = tools.conditionDecodings(data_task, rois, motorOutput=False, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for colorStim Stimuli: 7\n",
      "Accuracies: [0.34114583 0.30989583 0.33333333 0.34375    0.33072917 0.34635417\n",
      " 0.33072917]\n"
     ]
    }
   ],
   "source": [
    "inputtype = 'colorStim'\n",
    "statistics_color = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = distances_baseline_color.shape[1]\n",
    "    p = stats.binom_test(np.mean(distances_baseline_color[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline_color[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics_color[roicount,0] = np.mean(distances_baseline_color[roicount,:])\n",
    "    statistics_color[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics_color[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics_color[roicount,1] = qs[roicount]\n",
    "    statistics_color[roicount,2] = h0[roicount]*statistics_color[roicount,0]\n",
    "    \n",
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics_color[:,1]<0.05)[0]\n",
    "print('Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0])\n",
    "print('Accuracies:', statistics_color[sig_ind,0])\n",
    "\n",
    "#### Map back to surface\n",
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi+1)[0]\n",
    "    inputStim[vertex_ind,0] = statistics_color[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics_color[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics_color[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "# np.savetxt(projectdir + 'data/results/GroupfMRI/InputStimuliDecoding/InputStimuliRegions_COLOR2.csv', rois[np.where(statistics_color[:,1]<0.05)[0]], delimiter=',')\n",
    "    \n",
    "# #### \n",
    "# # Write file to csv and run wb_command\n",
    "# outdir = '/projects3/SRActFlow/data/results/GroupfMRI/InputStimuliDecoding/'\n",
    "# filename = inputtype + 'Decoding2'\n",
    "# np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "# wb_file = filename + '.dscalar.nii'\n",
    "# wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "# os.system(wb_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Run across subject decoding on Orientation Stimuli decoding\n",
    "### 4-way coding for every 4 input stimuli combinations\n",
    "* vertical, vertical\n",
    "* vertical, horizontal\n",
    "* horizontal, vertical\n",
    "* horizontal, horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load data for \"Orientation\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/f_mc1689_1/AnalysisTools/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'oriStim'\n",
    "\n",
    "if inputtype in ['colorStim','oriStim']:\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = tools.loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode different stimulus pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline_ori = tools.conditionDecodings(data_task, rois, motorOutput=False, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for oriStim Stimuli: 13\n",
      "Accuracies: [0.54427083 0.47135417 0.51041667 0.48177083 0.328125   0.30729167\n",
      " 0.31510417 0.30989583 0.5546875  0.56770833 0.52864583 0.421875\n",
      " 0.3125    ]\n"
     ]
    }
   ],
   "source": [
    "inputtype = 'oriStim'\n",
    "statistics_ori = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = distances_baseline_ori.shape[1]\n",
    "    p = stats.binom_test(np.mean(distances_baseline_ori[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline_ori[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics_ori[roicount,0] = np.mean(distances_baseline_ori[roicount,:])\n",
    "    statistics_ori[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics_ori[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics_ori[roicount,1] = qs[roicount]\n",
    "    statistics_ori[roicount,2] = h0[roicount]*statistics_ori[roicount,0]\n",
    "    \n",
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics_ori[:,1]<0.05)[0]\n",
    "print('Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0])\n",
    "print('Accuracies:', statistics_ori[sig_ind,0])\n",
    "\n",
    "#### Map back to surface\n",
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi+1)[0]\n",
    "    inputStim[vertex_ind,0] = statistics_ori[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics_ori[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics_ori[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "# np.savetxt('/projects3/SRActFlow/data/results/GroupfMRI/InputStimuliDecoding/InputStimuliRegions_ORI2.csv', rois[np.where(statistics_ori[:,1]<0.05)[0]], delimiter=',')\n",
    "    \n",
    "# #### \n",
    "# # Write file to csv and run wb_command\n",
    "# outdir = '/projects3/SRActFlow/data/results/GroupfMRI/InputStimuliDecoding/'\n",
    "# filename = inputtype + 'Decoding2'\n",
    "# np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "# wb_file = filename + '.dscalar.nii'\n",
    "# wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "# os.system(wb_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Run across subject decoding on Pitch Stimuli decoding\n",
    "### 4-way coding for every 4 input stimuli combinations\n",
    "* high, high\n",
    "* high, low\n",
    "* low, high\n",
    "* low, low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load data for \"Pitch\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/f_mc1689_1/AnalysisTools/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'pitchStim'\n",
    "\n",
    "if inputtype in ['colorStim','oriStim']:\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = tools.loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode different stimulus pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline_pitch = tools.conditionDecodings(data_task, rois, motorOutput=False, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for pitchStim Stimuli: 15\n",
      "Accuracies: [0.5078125  0.3046875  0.31510417 0.30729167 0.47395833 0.5234375\n",
      " 0.453125   0.40885417 0.47135417 0.30729167 0.42447917 0.4375\n",
      " 0.48177083 0.484375   0.41666667]\n"
     ]
    }
   ],
   "source": [
    "inputtype = 'pitchStim'\n",
    "statistics_pitch = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = distances_baseline_pitch.shape[1]\n",
    "    p = stats.binom_test(np.mean(distances_baseline_pitch[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline_pitch[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics_pitch[roicount,0] = np.mean(distances_baseline_pitch[roicount,:])\n",
    "    statistics_pitch[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics_pitch[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics_pitch[roicount,1] = qs[roicount]\n",
    "    statistics_pitch[roicount,2] = h0[roicount]*statistics_pitch[roicount,0]\n",
    "    \n",
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics_pitch[:,1]<0.05)[0]\n",
    "print('Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0])\n",
    "print('Accuracies:', statistics_pitch[sig_ind,0])\n",
    "\n",
    "#### Map back to surface\n",
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi+1)[0]\n",
    "    inputStim[vertex_ind,0] = statistics_pitch[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics_pitch[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics_pitch[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "# np.savetxt('/projects3/SRActFlow/data/results/GroupfMRI/InputStimuliDecoding/InputStimuliRegions_PITCH2.csv', rois[np.where(statistics_pitch[:,1]<0.05)[0]], delimiter=',')\n",
    "    \n",
    "# #### \n",
    "# # Write file to csv and run wb_command\n",
    "# outdir = '/projects3/SRActFlow/data/results/GroupfMRI/InputStimuliDecoding/'\n",
    "# filename = inputtype + 'Decoding2'\n",
    "# np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "# wb_file = filename + '.dscalar.nii'\n",
    "# wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "# os.system(wb_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Run across subject decoding on Constant Stimuli decoding\n",
    "### 4-way coding for every 4 input stimuli combinations\n",
    "* constant, constant\n",
    "* constant, beep\n",
    "* beep, constant\n",
    "* beep, beep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data for \"Constant\" stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/f_mc1689_1/AnalysisTools/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "nStims = 4\n",
    "data_task = np.zeros((len(glasser2),nStims,len(subjNums)))\n",
    "inputtype = 'constantStim'\n",
    "\n",
    "if inputtype in ['colorStim','oriStim']:\n",
    "    rois = np.where((networkdef==networkmappings['vis1']) | (networkdef==networkmappings['vis2']))[0] \n",
    "elif inputtype in ['constantStim','pitchStim']:\n",
    "    rois = np.where(networkdef==networkmappings['aud'])[0]\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task[:,:,scount] = tools.loadInputActivity(subj,inputtype)\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode different stimulus pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 30\n",
    "ncvs = 1\n",
    "\n",
    "distances_baseline_constant = tools.conditionDecodings(data_task, rois, motorOutput=False, ncvs=ncvs, nproc=nproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs significant for constantStim Stimuli: 12\n",
      "Accuracies: [0.39583333 0.34635417 0.328125   0.3203125  0.37239583 0.3828125\n",
      " 0.33854167 0.3203125  0.328125   0.34114583 0.34895833 0.359375  ]\n"
     ]
    }
   ],
   "source": [
    "inputtype = 'constantStim'\n",
    "statistics_constant = np.zeros((len(rois),3)) # acc, q, acc_thresh\n",
    "for roicount in range(len(rois)):\n",
    "    ntrials = distances_baseline_constant.shape[1]\n",
    "    p = stats.binom_test(np.mean(distances_baseline_constant[roicount,:])*ntrials,n=ntrials,p=1/float(nStims))\n",
    "    if np.mean(distances_baseline_constant[roicount,:])>1/float(nStims):\n",
    "        p = p/2.0\n",
    "    else:\n",
    "        p = 1.0-p/2.0\n",
    "        \n",
    "\n",
    "    statistics_constant[roicount,0] = np.mean(distances_baseline_constant[roicount,:])\n",
    "    statistics_constant[roicount,1] = p\n",
    "\n",
    "h0, qs = mc.fdrcorrection0(statistics_constant[:,1])\n",
    "for roicount in range(len(rois)):\n",
    "    statistics_constant[roicount,1] = qs[roicount]\n",
    "    statistics_constant[roicount,2] = h0[roicount]*statistics_constant[roicount,0]\n",
    "    \n",
    "# Count number of significant ROIs for LH decoding\n",
    "sig_ind = np.where(statistics_constant[:,1]<0.05)[0]\n",
    "print('Number of ROIs significant for', inputtype, 'Stimuli:', sig_ind.shape[0])\n",
    "print('Accuracies:', statistics_constant[sig_ind,0])\n",
    "\n",
    "#### Map back to surface\n",
    "# Put all data into a single matrix (since we only run a single classification)\n",
    "inputStim = np.zeros((glasser2.shape[0],3))\n",
    "\n",
    "roicount = 0\n",
    "for roi in rois:\n",
    "    vertex_ind = np.where(glasser2==roi+1)[0]\n",
    "    inputStim[vertex_ind,0] = statistics_constant[roicount,0]\n",
    "    inputStim[vertex_ind,1] = statistics_constant[roicount,1]\n",
    "    inputStim[vertex_ind,2] = statistics_constant[roicount,2]\n",
    "\n",
    "    roicount += 1\n",
    "\n",
    "# np.savetxt('/projects3/SRActFlow/data/results/GroupfMRI/InputStimuliDecoding/InputStimuliRegions_CONSTANT2.csv', rois[np.where(statistics_constant[:,1]<0.05)[0]], delimiter=',')\n",
    "    \n",
    "# #### \n",
    "# # Write file to csv and run wb_command\n",
    "# outdir = '/projects3/SRActFlow/data/results/GroupfMRI/InputStimuliDecoding/'\n",
    "# filename = inputtype + 'Decoding2'\n",
    "# np.savetxt(outdir + filename + '.csv', inputStim,fmt='%s')\n",
    "# wb_file = filename + '.dscalar.nii'\n",
    "# wb_command = 'wb_command -cifti-convert -from-text ' + outdir + filename + '.csv ' + glasserfile2 + ' ' + outdir + wb_file + ' -reset-scalars'\n",
    "# os.system(wb_command)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
