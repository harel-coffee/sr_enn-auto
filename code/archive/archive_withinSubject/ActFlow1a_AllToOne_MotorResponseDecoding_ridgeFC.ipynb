{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ActFlow 1b -- Compute the baseline decodability of Motor responses (LINDEX v. LMID and RINDEX v. RMID)\n",
    "## Using ActFlow, All to one, via PCA-FC\n",
    "\n",
    "## Use SVM classifications to decode hand-specific responses\n",
    "## Using Ciric-style postprocessing\n",
    "\n",
    "## Takuya Ito\n",
    "#### 12/12/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tito/miniconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nib\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = str(1)\n",
    "import statsmodels.api as sm\n",
    "import sklearn.svm as svm\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import sklearn\n",
    "from sklearn.feature_selection import f_classif\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "os.sys.path.append('glmScripts/')\n",
    "import taskGLMPipeline as tgp\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"FreeSans\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding 084\n",
    "subjNums = ['013','014','016','017','018','021','023','024','026','027','028','030','031','032','033',\n",
    "            '034','035','037','038','039','040','041','042','043','045','046','047','048','049','050',\n",
    "            '053','055','056','057','058','062','063','066','067','068','069','070','072','074','075',\n",
    "            '076','077','081','085','086','087','088','090','092','093','094','095','097','098','099',\n",
    "            '101','102','103','104','105','106','108','109','110','111','112','114','115','117','119',\n",
    "            '120','121','122','123','124','125','126','127','128','129','130','131','132','134','135',\n",
    "            '136','137','138','139','140','141']\n",
    "\n",
    "\n",
    "\n",
    "basedir = '/projects3/SRActFlow/'\n",
    "\n",
    "# Using final partition\n",
    "networkdef = np.loadtxt('/projects3/NetworkDiversity/data/network_partition.txt')\n",
    "networkorder = np.asarray(sorted(range(len(networkdef)), key=lambda k: networkdef[k]))\n",
    "networkorder.shape = (len(networkorder),1)\n",
    "# network mappings for final partition set\n",
    "networkmappings = {'fpn':7, 'vis1':1, 'vis2':2, 'smn':3, 'aud':8, 'lan':6, 'dan':5, 'con':4, 'dmn':9, \n",
    "                   'pmulti':10, 'none1':11, 'none2':12}\n",
    "networks = networkmappings.keys()\n",
    "\n",
    "xticks = {}\n",
    "reorderednetworkaffil = networkdef[networkorder]\n",
    "for net in networks:\n",
    "    netNum = networkmappings[net]\n",
    "    netind = np.where(reorderednetworkaffil==netNum)[0]\n",
    "    tick = np.max(netind)\n",
    "    xticks[tick] = net\n",
    "\n",
    "## General parameters/variables\n",
    "nParcels = 360\n",
    "nSubjs = len(subjNums)\n",
    "\n",
    "glasserfile2 = '/projects/AnalysisTools/ParcelsGlasser2016/Q1-Q6_RelatedParcellation210.LR.CorticalAreas_dil_Colors.32k_fs_RL.dlabel.nii'\n",
    "glasser2 = nib.load(glasserfile2).get_data()\n",
    "glasser2 = np.squeeze(glasser2)\n",
    "\n",
    "sortednets = np.sort(xticks.keys())\n",
    "orderednetworks = []\n",
    "for net in sortednets: orderednetworks.append(xticks[net])\n",
    "    \n",
    "networkpalette = ['royalblue','slateblue','paleturquoise','darkorchid','limegreen',\n",
    "                  'lightseagreen','yellow','orchid','r','peru','orange','olivedrab']\n",
    "networkpalette = np.asarray(networkpalette)\n",
    "\n",
    "OrderedNetworks = ['VIS1','VIS2','SMN','CON','DAN','LAN','FPN','AUD','DMN','PMM','VMM','ORA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Define functions for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMotorResponses(subj,hand='Right'):\n",
    "    \n",
    "    hands = {'Left':[0,1],'Right':[2,3]}\n",
    "\n",
    "    x = tgp.loadTaskTiming(subj,'ALL')\n",
    "    stimIndex = np.asarray(x['stimIndex'])\n",
    "    ind = np.where(stimIndex=='motorResponse')[0]\n",
    "    \n",
    "    datadir = basedir + 'data/postProcessing/hcpPostProcCiric/'\n",
    "    h5f = h5py.File(datadir + subj + '_glmOutput_data.h5','r')\n",
    "    data = h5f['taskRegression/ALL_24pXaCompCorXVolterra_taskReg_betas_canonical'][:].copy()\n",
    "    data = data[:,ind].copy()\n",
    "    h5f.close()\n",
    "    \n",
    "    # Isolate hand responses\n",
    "    hand_ind = hands[hand]\n",
    "    tmpdat = np.zeros((data.shape[0],2))\n",
    "    if hand=='Right':\n",
    "        tmpdat[:,0] = data[:,3]\n",
    "        tmpdat[:,1] = data[:,2]\n",
    "    elif hand=='Left':\n",
    "        tmpdat[:,0] = data[:,0]\n",
    "        tmpdat[:,1] = data[:,1]\n",
    "    data = tmpdat.copy()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def loadRSFCMapping(subj,roi):\n",
    "    fcdir = '/projects3/SRActFlow/data/results/ridgeFC/'\n",
    "#     filename = fcdir + 'TargetParcel' + str(roi) + '_RidgeFC.h5'\n",
    "    filename = fcdir + 'TargetParcel' + str(roi) + '_RidgeFC.h5'\n",
    "    h5f = h5py.File(filename,'r')\n",
    "    fcmapping = h5f[subj]['sourceToTargetMapping'][:].copy()\n",
    "    h5f.close()\n",
    "    return fcmapping\n",
    "\n",
    "\n",
    "## Load masks\n",
    "def loadMask(roi,dilated=True):\n",
    "    maskdir = basedir + 'data/results/surfaceMasks/'\n",
    "    if dilated:\n",
    "        maskfile = maskdir + 'GlasserParcel' + str(roi) + '_dilated_10mm.dscalar.nii'\n",
    "    else:\n",
    "        maskfile = maskdir + 'GlasserParcel' + str(roi) + '.dscalar.nii'\n",
    "    maskdata = np.squeeze(nib.load(maskfile).get_data())\n",
    "    \n",
    "    return maskdata\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Define functions for motor response decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def motorResponseDecodings(data, actflow_data, rois, ncvs=1, nproc=5):\n",
    "    \"\"\"\n",
    "    Run an across-subject classification\n",
    "    Decode responses on each hand separately from CPRO data\n",
    "    \"\"\"\n",
    "\n",
    "    nSubjs = data.shape[2]\n",
    "    stats = np.zeros((len(rois),))\n",
    "    \n",
    "    nfing = data.shape[1]\n",
    "\n",
    "    nsamples = nSubjs * nfing\n",
    "\n",
    "    # Label array for supervised learning\n",
    "    labels = np.tile(range(nfing),nSubjs)\n",
    "    subjarray = np.repeat(range(nSubjs),nfing)\n",
    "\n",
    "    # Run SVM classifications on network-level activation patterns across subjects\n",
    "    roicount = 0\n",
    "    for roi in rois:\n",
    "        roi_ind = np.where(glasser2==roi)[0]\n",
    "        nfeatures = len(roi_ind)\n",
    "        roi_ind.shape = (len(roi_ind),1)       \n",
    "\n",
    "        svm_mat = np.zeros((nsamples,roi_ind.shape[0]))\n",
    "        actflow_svm_mat = np.zeros((nsamples,roi_ind.shape[0]))\n",
    "        samplecount = 0\n",
    "        scount = 0\n",
    "        for subj in range(len(subjNums)):\n",
    "            roidata = np.squeeze(data[roi_ind,:,scount])\n",
    "            actflow_roidata = np.squeeze(actflow_data[roi_ind,:,scount])\n",
    "            svm_mat[samplecount:(samplecount+nfing),:] = roidata.T\n",
    "            actflow_svm_mat[samplecount:(samplecount+nfing),:] = actflow_roidata.T\n",
    "\n",
    "            scount += 1\n",
    "            samplecount += nfing\n",
    "\n",
    "            # Spatially demean matrix across features\n",
    "            samplemean = np.mean(svm_mat,axis=1)\n",
    "            samplemean.shape = (len(samplemean),1)\n",
    "            svm_mat = svm_mat - samplemean\n",
    "            \n",
    "            samplemean = np.mean(actflow_svm_mat,axis=1)\n",
    "            samplemean.shape = (len(samplemean),1)\n",
    "            actflow_svm_mat = actflow_svm_mat - samplemean\n",
    "\n",
    "        scores = randomSplitLOOBaselineCV(ncvs, svm_mat, actflow_svm_mat, labels, subjarray, nproc=nproc)\n",
    "        stats[roicount] = np.mean(scores)\n",
    "        roicount += 1\n",
    "        \n",
    "    return stats\n",
    "\n",
    "def randomSplitLOOBaselineCV(ncvs, svm_mat, actflow_svm_mat, labels, subjarray, nproc=5):\n",
    "    \"\"\"\n",
    "    Runs cross validation for an across-subject SVM analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    ntasks = len(np.unique(labels))\n",
    "    nsamples = svm_mat.shape[0]\n",
    "    nsubjs = nsamples/ntasks\n",
    "\n",
    "    subjects = np.unique(subjarray)\n",
    "    indices = np.arange(nsamples)\n",
    "    \n",
    "    numsubjs_perfold = 1\n",
    "    if nsubjs%numsubjs_perfold!=0: \n",
    "        raise Exception(\"Error: Folds don't match number of subjects\")\n",
    "        \n",
    "    nfolds = nsubjs/numsubjs_perfold\n",
    "    subj_array_folds = subjarray.copy()\n",
    "    \n",
    "    inputs = [] \n",
    "    \n",
    "    for fold in range(nfolds):\n",
    "        test_subjs = np.random.choice(subj_array_folds,numsubjs_perfold,replace=False)\n",
    "        train_subjs_all = np.delete(subjects,test_subjs)\n",
    "        for cv in range(ncvs):\n",
    "            # Randomly sample half of train set subjects for each cv (CV bootstrapping)\n",
    "            train_subjs = np.random.choice(train_subjs_all,\n",
    "                                         int(np.floor(len(train_subjs_all)*(4.0))),\n",
    "                                         replace=True)\n",
    "\n",
    "            train_ind = []\n",
    "            for subj in train_subjs:\n",
    "                train_ind.extend(np.where(subjarray==subj)[0])\n",
    "\n",
    "            test_ind = []\n",
    "            for subj in test_subjs:\n",
    "                test_ind.extend(np.where(subjarray==subj)[0])\n",
    "            \n",
    "            train_ind = np.asarray(train_ind)\n",
    "            test_ind = np.asarray(test_ind)\n",
    "\n",
    "            trainset = actflow_svm_mat[train_ind,:]\n",
    "            testset = svm_mat[test_ind,:]\n",
    "            orig_training = svm_mat[train_ind,:]\n",
    "\n",
    "            # Normalize trainset and testset\n",
    "            trainmean = np.mean(actflow_svm_mat[train_ind,:],axis=0)\n",
    "            trainmean.shape = (1,len(trainmean))\n",
    "            trainstd = np.std(actflow_svm_mat[train_ind,:],axis=0)\n",
    "            trainstd.shape = (1,len(trainstd))\n",
    "            \n",
    "            # Normalize trainset and testset\n",
    "            testmean = np.mean(svm_mat[train_ind,:],axis=0)\n",
    "            testmean.shape = (1,len(testmean))\n",
    "            teststd = np.std(svm_mat[train_ind,:],axis=0)\n",
    "            teststd.shape = (1,len(teststd))\n",
    "\n",
    "            trainset = np.divide((trainset - trainmean),trainstd)\n",
    "            testset = np.divide((testset - testmean),teststd)\n",
    "\n",
    "            ######## FEATURE SELECTION & REDUCTION\n",
    "            ## Feature selection and downsampling\n",
    "            trainlabels = labels[train_ind]\n",
    "            testlabels = labels[test_ind]\n",
    "            unique_labels = np.unique(labels)\n",
    "            feat1_labs = np.where(trainlabels==0)[0]\n",
    "            feat2_labs = np.where(trainlabels==1)[0]\n",
    "            # Perform t-test\n",
    "            t, p = stats.ttest_rel(orig_training[feat1_labs,:],orig_training[feat2_labs,:],axis=0)\n",
    "            h0, qs = mc.fdrcorrection0(p)\n",
    "            # Construct feature masks\n",
    "            feat1_mask = np.multiply(t<0,h0)\n",
    "            feat2_mask = np.multiply(t>0,h0)\n",
    "#             feat1_mask = t>0\n",
    "#             feat2_mask = t<0\n",
    "            # Downsample training set into original vertices into 2 ROI signals\n",
    "            trainset_downsampled = np.zeros((trainset.shape[0],2))\n",
    "            trainset_downsampled[:,0] = np.nanmean(trainset[:,feat1_mask],axis=1)\n",
    "            trainset_downsampled[:,1] = np.nanmean(trainset[:,feat2_mask],axis=1)\n",
    "            trainset_downsampled = trainset[:,h0]\n",
    "            # Downsample test set into original vertices\n",
    "            testset_downsampled = np.zeros((testset.shape[0],2))\n",
    "            testset_downsampled[:,0] = np.nanmean(testset[:,feat1_mask],axis=1)\n",
    "            testset_downsampled[:,1] = np.nanmean(testset[:,feat2_mask],axis=1)\n",
    "            testset_downsampled = testset[:,h0]\n",
    "#             print 'feat1_mask', np.sum(feat1_mask), '| feat2_mask', np.sum(feat2_mask)\n",
    "\n",
    "            if np.sum(feat1_mask)==0 or np.sum(feat2_mask)==0:\n",
    "                print 'not running feature selection'\n",
    "                inputs.append((trainset,testset,labels[train_ind],labels[test_ind]))\n",
    "            else:\n",
    "                inputs.append((trainset_downsampled,testset_downsampled,labels[train_ind],labels[test_ind]))\n",
    "\n",
    "#             inputs.append((trainset,testset,labels[train_ind],labels[test_ind]))         \n",
    "    \n",
    "        subj_array_folds = np.delete(subj_array_folds,test_subjs)\n",
    "        \n",
    "    pool = mp.Pool(processes=nproc)\n",
    "    scores = pool.map_async(_decoding,inputs).get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    acc = []\n",
    "    for score in scores:\n",
    "        acc.extend(score)\n",
    "    return acc\n",
    "\n",
    "def _decoding((trainset,testset,trainlabels,testlabels)):\n",
    "\n",
    "#     clf = sklearn.linear_model.LogisticRegression()\n",
    "#     clf = svm.SVC(C=1.0, kernel='linear')\n",
    "\n",
    "#     clf.fit(trainset,trainlabels)\n",
    "#     predictions = clf.predict(testset)\n",
    "#     acc = predictions==testlabels\n",
    "    \n",
    "    unique_cond = np.unique(trainlabels)\n",
    "    acc = []\n",
    "    for cond1 in unique_cond:\n",
    "        mismatches = []\n",
    "        prototype_ind = np.where(trainlabels==cond1)[0]\n",
    "        prototype = np.mean(trainset[prototype_ind,:],axis=0)\n",
    "        for cond2 in unique_cond:\n",
    "            test_ind = np.where(testlabels==cond2)[0]\n",
    "            test = np.mean(testset[test_ind,:],axis=0)\n",
    "            if cond1 == cond2: \n",
    "                correct = stats.spearmanr(prototype,test)[0]\n",
    "            else:\n",
    "                mismatches.append(stats.spearmanr(prototype,test)[0])\n",
    "#         print correct, mismatches\n",
    "        if correct > np.max(mismatches): \n",
    "            acc.append(1.0)\n",
    "        else:\n",
    "            acc.append(0.0)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.01 Load data for RH responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsr = True\n",
    "nResponses = 2\n",
    "data_task_rh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task_rh[:,:,scount] = loadMotorResponses(subj,hand='Right')\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.02 Generate actflow data for RH responses (Left S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_rh = 9 #left S1\n",
    "target_rh_ind = np.where(glasser2==roi_rh)[0]\n",
    "fcmapping_rh = np.zeros((len(glasser2),len(target_rh_ind)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    fcmapping_rh[:,:] = fcmapping_rh[:,:] + loadRSFCMapping(subj,roi_rh)\n",
    "    scount += 1\n",
    "\n",
    "fcmapping_rh = np.divide(fcmapping_rh,len(subjNums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 013 ( 1 / 96 )\n",
      "Subject 014 ( 2 / 96 )\n",
      "Subject 016 ( 3 / 96 )\n",
      "Subject 017 ( 4 / 96 )\n",
      "Subject 018 ( 5 / 96 )\n",
      "Subject 021 ( 6 / 96 )\n",
      "Subject 023 ( 7 / 96 )\n",
      "Subject 024 ( 8 / 96 )\n",
      "Subject 026 ( 9 / 96 )\n",
      "Subject 027 ( 10 / 96 )\n",
      "Subject 028 ( 11 / 96 )\n",
      "Subject 030 ( 12 / 96 )\n",
      "Subject 031 ( 13 / 96 )\n",
      "Subject 032 ( 14 / 96 )\n",
      "Subject 033 ( 15 / 96 )\n",
      "Subject 034 ( 16 / 96 )\n",
      "Subject 035 ( 17 / 96 )\n",
      "Subject 037 ( 18 / 96 )\n",
      "Subject 038 ( 19 / 96 )\n",
      "Subject 039 ( 20 / 96 )\n",
      "Subject 040 ( 21 / 96 )\n",
      "Subject 041 ( 22 / 96 )\n",
      "Subject 042 ( 23 / 96 )\n",
      "Subject 043 ( 24 / 96 )\n",
      "Subject 045 ( 25 / 96 )\n",
      "Subject 046 ( 26 / 96 )\n",
      "Subject 047 ( 27 / 96 )\n",
      "Subject 048 ( 28 / 96 )\n",
      "Subject 049 ( 29 / 96 )\n",
      "Subject 050 ( 30 / 96 )\n",
      "Subject 053 ( 31 / 96 )\n",
      "Subject 055 ( 32 / 96 )\n",
      "Subject 056 ( 33 / 96 )\n",
      "Subject 057 ( 34 / 96 )\n",
      "Subject 058 ( 35 / 96 )\n",
      "Subject 062 ( 36 / 96 )\n",
      "Subject 063 ( 37 / 96 )\n",
      "Subject 066 ( 38 / 96 )\n",
      "Subject 067 ( 39 / 96 )\n",
      "Subject 068 ( 40 / 96 )\n",
      "Subject 069 ( 41 / 96 )\n",
      "Subject 070 ( 42 / 96 )\n",
      "Subject 072 ( 43 / 96 )\n",
      "Subject 074 ( 44 / 96 )\n",
      "Subject 075 ( 45 / 96 )\n",
      "Subject 076 ( 46 / 96 )\n",
      "Subject 077 ( 47 / 96 )\n",
      "Subject 081 ( 48 / 96 )\n",
      "Subject 085 ( 49 / 96 )\n",
      "Subject 086 ( 50 / 96 )\n",
      "Subject 087 ( 51 / 96 )\n",
      "Subject 088 ( 52 / 96 )\n",
      "Subject 090 ( 53 / 96 )\n",
      "Subject 092 ( 54 / 96 )\n",
      "Subject 093 ( 55 / 96 )\n",
      "Subject 094 ( 56 / 96 )\n",
      "Subject 095 ( 57 / 96 )\n",
      "Subject 097 ( 58 / 96 )\n",
      "Subject 098 ( 59 / 96 )\n",
      "Subject 099 ( 60 / 96 )\n",
      "Subject 101 ( 61 / 96 )\n",
      "Subject 102 ( 62 / 96 )\n",
      "Subject 103 ( 63 / 96 )\n",
      "Subject 104 ( 64 / 96 )\n",
      "Subject 105 ( 65 / 96 )\n",
      "Subject 106 ( 66 / 96 )\n",
      "Subject 108 ( 67 / 96 )\n",
      "Subject 109 ( 68 / 96 )\n",
      "Subject 110 ( 69 / 96 )\n",
      "Subject 111 ( 70 / 96 )\n",
      "Subject 112 ( 71 / 96 )\n",
      "Subject 114 ( 72 / 96 )\n",
      "Subject 115 ( 73 / 96 )\n",
      "Subject 117 ( 74 / 96 )\n",
      "Subject 119 ( 75 / 96 )\n",
      "Subject 120 ( 76 / 96 )\n",
      "Subject 121 ( 77 / 96 )\n",
      "Subject 122 ( 78 / 96 )\n",
      "Subject 123 ( 79 / 96 )\n",
      "Subject 124 ( 80 / 96 )\n",
      "Subject 125 ( 81 / 96 )\n",
      "Subject 126 ( 82 / 96 )\n",
      "Subject 127 ( 83 / 96 )\n",
      "Subject 128 ( 84 / 96 )\n",
      "Subject 129 ( 85 / 96 )\n",
      "Subject 130 ( 86 / 96 )\n",
      "Subject 131 ( 87 / 96 )\n",
      "Subject 132 ( 88 / 96 )\n",
      "Subject 134 ( 89 / 96 )\n",
      "Subject 135 ( 90 / 96 )\n",
      "Subject 136 ( 91 / 96 )\n",
      "Subject 137 ( 92 / 96 )\n",
      "Subject 138 ( 93 / 96 )\n",
      "Subject 139 ( 94 / 96 )\n",
      "Subject 140 ( 95 / 96 )\n",
      "Subject 141 ( 96 / 96 )\n"
     ]
    }
   ],
   "source": [
    "roi_rh = 9\n",
    "roi_lh = 189\n",
    "actflow_data_rh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "\n",
    "dilateLH = loadMask(roi_lh,dilated=True)\n",
    "dilateRH = loadMask(roi_rh,dilated=True)\n",
    "combinedDilated = dilateLH + dilateRH\n",
    "# Exclude all SMN regions\n",
    "smn_rois = np.where(networkdef==networkmappings['smn'])[0]\n",
    "for x in smn_rois:\n",
    "    roi_ind = np.where(glasser2==x)[0]\n",
    "    combinedDilated[roi_ind]=1\n",
    "source_ind = np.where(combinedDilated==0)[0]\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    print 'Subject', subj, '(', scount+1, '/', len(subjNums), ')'\n",
    "       \n",
    "#     fcmapping_rh[:,:] = loadRSFCMapping(subj,roi_rh)\n",
    "#     tmp = np.multiply(fcmapping_rh>0,fcmapping_rh)\n",
    "    \n",
    "    target_ind = np.where(glasser2==roi_rh)[0]\n",
    "    # Right Finger 1\n",
    "    actflow_data_rh[target_ind,0,scount] = np.dot(stats.zscore(data_task_rh[source_ind,0,scount],axis=0),fcmapping_rh[source_ind,:])\n",
    "    # Right Finger 2\n",
    "    actflow_data_rh[target_ind,1,scount] = np.dot(stats.zscore(data_task_rh[source_ind,1,scount],axis=0),fcmapping_rh[source_ind,:])\n",
    "\n",
    "    scount += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on right-hand motor responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.where(networkdef==networkmappings['smn'])[0] + 1\n",
    "rois = [roi_rh] # Left S1\n",
    "\n",
    "distances_baseline_rh = motorResponseDecodings(stats.zscore(data_task_rh,axis=0), \n",
    "                                               actflow_data_rh,\n",
    "                                               rois, ncvs=ncvs, nproc=nproc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.677083333333\n",
      "P-value: 5.18506143485e-07\n"
     ]
    }
   ],
   "source": [
    "statistics_rh = np.zeros((distances_baseline_rh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(distances_baseline_rh[0]*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_rh[0])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "statistics_rh[0,0] = np.mean(distances_baseline_rh[0])\n",
    "statistics_rh[0,1] = p\n",
    "\n",
    "\n",
    "\n",
    "print 'Accuracy:', statistics_rh[0,0]\n",
    "print 'P-value:', statistics_rh[0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.01 Load data for LH responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsr = True\n",
    "nResponses = 2\n",
    "data_task_lh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    data_task_lh[:,:,scount] = loadMotorResponses(subj,hand='Left')\n",
    "    scount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.02 Generate actflow data for RH responses (Left S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_lh = 189 #left S1\n",
    "target_lh_ind = np.where(glasser2==roi_lh)[0]\n",
    "fcmapping_lh = np.zeros((len(glasser2),len(target_lh_ind)))\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    fcmapping_lh[:,:] = fcmapping_lh[:,:] + loadRSFCMapping(subj,roi_lh)\n",
    "    scount += 1\n",
    "\n",
    "fcmapping_lh = np.divide(fcmapping_lh,len(subjNums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 013 ( 1 / 96 )\n",
      "Subject 014 ( 2 / 96 )\n",
      "Subject 016 ( 3 / 96 )\n",
      "Subject 017 ( 4 / 96 )\n",
      "Subject 018 ( 5 / 96 )\n",
      "Subject 021 ( 6 / 96 )\n",
      "Subject 023 ( 7 / 96 )\n",
      "Subject 024 ( 8 / 96 )\n",
      "Subject 026 ( 9 / 96 )\n",
      "Subject 027 ( 10 / 96 )\n",
      "Subject 028 ( 11 / 96 )\n",
      "Subject 030 ( 12 / 96 )\n",
      "Subject 031 ( 13 / 96 )\n",
      "Subject 032 ( 14 / 96 )\n",
      "Subject 033 ( 15 / 96 )\n",
      "Subject 034 ( 16 / 96 )\n",
      "Subject 035 ( 17 / 96 )\n",
      "Subject 037 ( 18 / 96 )\n",
      "Subject 038 ( 19 / 96 )\n",
      "Subject 039 ( 20 / 96 )\n",
      "Subject 040 ( 21 / 96 )\n",
      "Subject 041 ( 22 / 96 )\n",
      "Subject 042 ( 23 / 96 )\n",
      "Subject 043 ( 24 / 96 )\n",
      "Subject 045 ( 25 / 96 )\n",
      "Subject 046 ( 26 / 96 )\n",
      "Subject 047 ( 27 / 96 )\n",
      "Subject 048 ( 28 / 96 )\n",
      "Subject 049 ( 29 / 96 )\n",
      "Subject 050 ( 30 / 96 )\n",
      "Subject 053 ( 31 / 96 )\n",
      "Subject 055 ( 32 / 96 )\n",
      "Subject 056 ( 33 / 96 )\n",
      "Subject 057 ( 34 / 96 )\n",
      "Subject 058 ( 35 / 96 )\n",
      "Subject 062 ( 36 / 96 )\n",
      "Subject 063 ( 37 / 96 )\n",
      "Subject 066 ( 38 / 96 )\n",
      "Subject 067 ( 39 / 96 )\n",
      "Subject 068 ( 40 / 96 )\n",
      "Subject 069 ( 41 / 96 )\n",
      "Subject 070 ( 42 / 96 )\n",
      "Subject 072 ( 43 / 96 )\n",
      "Subject 074 ( 44 / 96 )\n",
      "Subject 075 ( 45 / 96 )\n",
      "Subject 076 ( 46 / 96 )\n",
      "Subject 077 ( 47 / 96 )\n",
      "Subject 081 ( 48 / 96 )\n",
      "Subject 085 ( 49 / 96 )\n",
      "Subject 086 ( 50 / 96 )\n",
      "Subject 087 ( 51 / 96 )\n",
      "Subject 088 ( 52 / 96 )\n",
      "Subject 090 ( 53 / 96 )\n",
      "Subject 092 ( 54 / 96 )\n",
      "Subject 093 ( 55 / 96 )\n",
      "Subject 094 ( 56 / 96 )\n",
      "Subject 095 ( 57 / 96 )\n",
      "Subject 097 ( 58 / 96 )\n",
      "Subject 098 ( 59 / 96 )\n",
      "Subject 099 ( 60 / 96 )\n",
      "Subject 101 ( 61 / 96 )\n",
      "Subject 102 ( 62 / 96 )\n",
      "Subject 103 ( 63 / 96 )\n",
      "Subject 104 ( 64 / 96 )\n",
      "Subject 105 ( 65 / 96 )\n",
      "Subject 106 ( 66 / 96 )\n",
      "Subject 108 ( 67 / 96 )\n",
      "Subject 109 ( 68 / 96 )\n",
      "Subject 110 ( 69 / 96 )\n",
      "Subject 111 ( 70 / 96 )\n",
      "Subject 112 ( 71 / 96 )\n",
      "Subject 114 ( 72 / 96 )\n",
      "Subject 115 ( 73 / 96 )\n",
      "Subject 117 ( 74 / 96 )\n",
      "Subject 119 ( 75 / 96 )\n",
      "Subject 120 ( 76 / 96 )\n",
      "Subject 121 ( 77 / 96 )\n",
      "Subject 122 ( 78 / 96 )\n",
      "Subject 123 ( 79 / 96 )\n",
      "Subject 124 ( 80 / 96 )\n",
      "Subject 125 ( 81 / 96 )\n",
      "Subject 126 ( 82 / 96 )\n",
      "Subject 127 ( 83 / 96 )\n",
      "Subject 128 ( 84 / 96 )\n",
      "Subject 129 ( 85 / 96 )\n",
      "Subject 130 ( 86 / 96 )\n",
      "Subject 131 ( 87 / 96 )\n",
      "Subject 132 ( 88 / 96 )\n",
      "Subject 134 ( 89 / 96 )\n",
      "Subject 135 ( 90 / 96 )\n",
      "Subject 136 ( 91 / 96 )\n",
      "Subject 137 ( 92 / 96 )\n",
      "Subject 138 ( 93 / 96 )\n",
      "Subject 139 ( 94 / 96 )\n",
      "Subject 140 ( 95 / 96 )\n",
      "Subject 141 ( 96 / 96 )\n"
     ]
    }
   ],
   "source": [
    "roi_rh = 9\n",
    "roi_lh = 189\n",
    "actflow_data_lh = np.zeros((len(glasser2),nResponses,len(subjNums)))\n",
    "\n",
    "dilateLH = loadMask(roi_lh,dilated=True)\n",
    "dilateRH = loadMask(roi_rh,dilated=True)\n",
    "combinedDilated = dilateLH + dilateRH \n",
    "# Exclude all SMN regions\n",
    "smn_rois = np.where(networkdef==networkmappings['smn'])[0]\n",
    "for x in smn_rois:\n",
    "    roi_ind = np.where(glasser2==x)[0]\n",
    "    combinedDilated[roi_ind]=1\n",
    "source_ind = np.where(combinedDilated==0)[0]\n",
    "# source_ind = np.where(glasser2==351)[0]\n",
    "\n",
    "scount = 0\n",
    "for subj in subjNums:\n",
    "    print 'Subject', subj, '(', scount+1, '/', len(subjNums), ')'\n",
    "       \n",
    "#     fcmapping_lh[:,:] = loadRSFCMapping(subj,roi_lh)\n",
    "#     tmp = np.multiply(fcmapping_lh>0,fcmapping_lh)\n",
    "\n",
    "\n",
    "    target_ind = np.where(glasser2==roi_lh)[0]\n",
    "#     Right Finger 1\n",
    "    actflow_data_lh[target_ind,0,scount] = np.dot(stats.zscore(data_task_lh[source_ind,0,scount],axis=0),fcmapping_lh[source_ind,:])\n",
    "    # Right Finger 2\n",
    "    actflow_data_lh[target_ind,1,scount] = np.dot(stats.zscore(data_task_lh[source_ind,1,scount],axis=0),fcmapping_lh[source_ind,:])\n",
    "\n",
    "    scount += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Run across subject decoding on right-hand motor responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 20\n",
    "ncvs = 1\n",
    "\n",
    "rois = np.where(networkdef==networkmappings['smn'])[0] + 1\n",
    "rois = [roi_lh] # Left S1\n",
    "\n",
    "distances_baseline_lh = motorResponseDecodings(stats.zscore(data_task_lh,axis=0), \n",
    "                                               actflow_data_lh,\n",
    "                                               rois, ncvs=ncvs, nproc=nproc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.302083333333\n",
      "P-value: 0.999999979105\n"
     ]
    }
   ],
   "source": [
    "statistics_lh = np.zeros((distances_baseline_lh.shape[0],2))\n",
    "ntrials = len(subjNums)*2\n",
    "p = stats.binom_test(distances_baseline_lh[0]*ntrials,n=ntrials,p=0.5)\n",
    "if np.mean(distances_baseline_lh[0])>0.5:\n",
    "    p = p/2.0\n",
    "else:\n",
    "    p = 1.0-p/2.0\n",
    "\n",
    "statistics_lh[0,0] = np.mean(distances_baseline_lh[0])\n",
    "statistics_lh[0,1] = p\n",
    "\n",
    "\n",
    "\n",
    "print 'Accuracy:', statistics_lh[0,0]\n",
    "print 'P-value:', statistics_lh[0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576200978517 4.10743115796e-51\n",
      "0.268180486127 9.93124376242e-11\n",
      "-0.443935678792 1.74909748338e-27\n",
      "-0.363476859965 2.61220815369e-18\n",
      "Average predicted-to-actual similarity: 0.00924223147183\n"
     ]
    }
   ],
   "source": [
    "roi_ind_rh = np.where(glasser2==roi_rh)[0]\n",
    "roi_ind_lh = np.where(glasser2==roi_lh)[0]\n",
    "\n",
    "predicted_to_actual_rh1, p1 = stats.spearmanr(np.mean(data_task_rh[roi_ind_rh,0,:],axis=1),np.mean(actflow_data_rh[roi_ind_rh,0,:],axis=1))\n",
    "predicted_to_actual_rh2, p2 = stats.spearmanr(np.mean(data_task_rh[roi_ind_rh,1,:],axis=1),np.mean(actflow_data_rh[roi_ind_rh,1,:],axis=1))\n",
    "\n",
    "predicted_to_actual_lh1, p3 = stats.spearmanr(np.mean(data_task_lh[roi_ind_lh,0,:],axis=1),np.mean(actflow_data_lh[roi_ind_lh,0,:],axis=1))\n",
    "predicted_to_actual_lh2, p4 = stats.spearmanr(np.mean(data_task_lh[roi_ind_lh,1,:],axis=1),np.mean(actflow_data_lh[roi_ind_lh,1,:],axis=1))\n",
    "\n",
    "print predicted_to_actual_rh1, p1\n",
    "print predicted_to_actual_rh2, p2\n",
    "print predicted_to_actual_lh1, p3\n",
    "print predicted_to_actual_lh2, p4\n",
    "print 'Average predicted-to-actual similarity:', np.mean([predicted_to_actual_rh1,predicted_to_actual_rh2,predicted_to_actual_lh1,predicted_to_actual_lh2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
